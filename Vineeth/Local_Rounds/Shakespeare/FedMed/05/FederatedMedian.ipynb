{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tushar-semwal/fedperf/blob/main/Vineeth/Local_Rounds/Shakesphere/FedMed/FederatedMedian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WQ6Rq0UiG6ev"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummaryX in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: unidecode in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: pandas in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (0.24.2)\n",
      "Requirement already satisfied: numpy in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (1.19.1)\n",
      "Requirement already satisfied: torch in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (1.7.1+cu101)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from pandas->torchsummaryX) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from pandas->torchsummaryX) (2021.1)\n",
      "Requirement already satisfied: typing-extensions in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torch->torchsummaryX) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas->torchsummaryX) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummaryX unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yKcpjZLrQQJV"
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    import os\n",
    "    path = '/content/drive/MyDrive/Colab Notebooks/OpenMined/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "except:\n",
    "    path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0_nKpfq2h1R"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DLLNM9X2JbQ8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 27 11:43:00 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 24%   42C    P2    61W / 250W |   1101MiB / 11178MiB |     11%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 32%   55C    P2   120W / 250W |   1564MiB / 11178MiB |     52%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    163076      C   ...3/envs/QSGD-PT/bin/python     1099MiB |\n",
      "|    1   N/A  N/A     77229      C   ...3/envs/QSGD-PT/bin/python      781MiB |\n",
      "|    1   N/A  N/A    171474      C   ...3/envs/QSGD-PT/bin/python      781MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import copy\n",
    "from functools import reduce\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchsummaryX import summary as summaryx\n",
    "from torchvision import transforms, utils, datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Check assigned GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "# set manual seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# general reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# gpu training specific\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY4eWzGiL6Mj"
   },
   "source": [
    "## Load the Shakespeare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hf03LRxof7Zj"
   },
   "outputs": [],
   "source": [
    "!rm -Rf data\n",
    "!mkdir -p data scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ngygA4-Fgobx"
   },
   "outputs": [],
   "source": [
    "GENERATE_DATASET = False  # If False, download the dataset provided by the q-FFL paper\n",
    "DATA_DIR = 'data/'\n",
    "# Dataset generation params\n",
    "SAMPLES_FRACTION = 1.  # If using an already generated dataset\n",
    "# SAMPLES_FRACTION = 0.2  # Fraction of total samples in the dataset - FedProx default script\n",
    "# SAMPLES_FRACTION = 0.05  # Fraction of total samples in the dataset - qFFL\n",
    "TRAIN_FRACTION = 0.8  # Train set size\n",
    "MIN_SAMPLES = 0  # Min samples per client (for filtering purposes) - FedProx\n",
    "# MIN_SAMPLES = 64  # Min samples per client (for filtering purposes) - qFFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nUmwJgJygoYD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-27 11:43:00--  http://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5757108 (5.5M) [text/plain]\n",
      "Saving to: ‘data/shakespeare.txt’\n",
      "\n",
      "data/shakespeare.tx 100%[===================>]   5.49M   296KB/s    in 19s     \n",
      "\n",
      "2021-04-27 11:43:20 (293 KB/s) - ‘data/shakespeare.txt’ saved [5757108/5757108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download raw dataset\n",
    "# !wget https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt -O data/shakespeare.txt\n",
    "!wget --adjust-extension http://www.gutenberg.org/files/100/100-0.txt -O data/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dCvx80BgoVr"
   },
   "outputs": [],
   "source": [
    "if not GENERATE_DATASET:\n",
    "    !rm -Rf data/train data/test\n",
    "    !gdown --id 1n46Mftp3_ahRi1Z6jYhEriyLtdRDS1tD  # Download Shakespeare dataset used by the FedProx paper\n",
    "    !unzip shakespeare.zip\n",
    "    !mv -f shakespeare_paper/train data/\n",
    "    !mv -f shakespeare_paper/test data/\n",
    "    !rm -R shakespeare_paper/ shakespeare.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4pzFvPvhQhq"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "with open('data/shakespeare.txt', 'r') as f:\n",
    "    data = list(unidecode(f.read()))\n",
    "    corpus = list(set(list(data)))\n",
    "print('Corpus Length:', len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cce_-qnxhD4n"
   },
   "source": [
    "#### Dataset Preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rt13M4IcgoTV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if GENERATE_DATASET:\n",
    "    # Download dataset generation scripts\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/preprocess_shakespeare.py -O scripts/preprocess_shakespeare.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/shake_utils.py -O scripts/shake_utils.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/gen_all_data.py -O scripts/gen_all_data.py\n",
    "\n",
    "    # Download data preprocessing scripts\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/utils/sample.py -O scripts/sample.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/utils/remove_users.py -O scripts/remove_users.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIEyRW27goPo"
   },
   "outputs": [],
   "source": [
    "# Running scripts\n",
    "if GENERATE_DATASET:\n",
    "    !mkdir -p data/raw_data data/all_data data/train data/test\n",
    "    !python scripts/preprocess_shakespeare.py data/shakespeare.txt data/raw_data\n",
    "    !python scripts/gen_all_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mq8V6v_4hhhD"
   },
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2SjEBKoWDxv"
   },
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, x, y, corpus, seq_length):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.corpus = corpus\n",
    "        self.corpus_size = len(self.corpus)\n",
    "        super(ShakespeareDataset, self).__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__} - (length: {self.__len__()})'\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        input_seq = self.x[i]\n",
    "        next_char = self.y[i]\n",
    "        # print('\\tgetitem', i, input_seq, next_char)\n",
    "        input_value = self.text2charindxs(input_seq).long()\n",
    "        target_value = self.get_label_from_char(next_char)\n",
    "        return input_value, target_value\n",
    "\n",
    "    def text2charindxs(self, text):\n",
    "        tensor = torch.zeros(len(text), dtype=torch.int32)\n",
    "        for i, c in enumerate(text):\n",
    "            tensor[i] = self.get_label_from_char(c)\n",
    "        return tensor\n",
    "\n",
    "    def get_label_from_char(self, c):\n",
    "        return self.corpus.index(c)\n",
    "\n",
    "    def get_char_from_label(self, l):\n",
    "        return self.corpus[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fgJtS62lYAN"
   },
   "source": [
    "##### Federated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DqL5pTmgn5X"
   },
   "outputs": [],
   "source": [
    "class ShakespeareFedDataset(ShakespeareDataset):\n",
    "    def __init__(self, x, y, corpus, seq_length):\n",
    "        super(ShakespeareFedDataset, self).__init__(x, y, corpus, seq_length)\n",
    "\n",
    "    def dataloader(self, batch_size, shuffle=True):\n",
    "        return DataLoader(self,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XelbyPsDlfgb"
   },
   "source": [
    "## Partitioning & Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOBblyFGlwlU"
   },
   "source": [
    "### IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSZFWKmsgn1p"
   },
   "outputs": [],
   "source": [
    "def iid_partition_(dataset, clients):\n",
    "  \"\"\"\n",
    "  I.I.D paritioning of data over clients\n",
    "  Shuffle the data\n",
    "  Split it between clients\n",
    "  \n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "\n",
    "  num_items_per_client = int(len(dataset)/clients)\n",
    "  client_dict = {}\n",
    "  image_idxs = [i for i in range(len(dataset))]\n",
    "\n",
    "  for i in range(clients):\n",
    "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
    "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
    "\n",
    "  return client_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lGwDyhSll9h"
   },
   "outputs": [],
   "source": [
    "def iid_partition(corpus, seq_length=80, val_split=False):\n",
    "\n",
    "    train_file = [os.path.join(DATA_DIR, 'train', f) for f in os.listdir(f'{DATA_DIR}/train') if f.endswith('.json')][0]\n",
    "    test_file = [os.path.join(DATA_DIR, 'test', f) for f in os.listdir(f'{DATA_DIR}/test') if f.endswith('.json')][0]\n",
    "\n",
    "    with open(train_file, 'r') as file:\n",
    "        data_train = json.loads(unidecode(file.read()))\n",
    "\n",
    "    with open(test_file, 'r') as file:\n",
    "        data_test = json.loads(unidecode(file.read()))\n",
    "\n",
    "    \n",
    "    total_samples_train = sum(data_train['num_samples'])\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_test, y_test = [], []\n",
    "    # x_val, y_val = [], []\n",
    "\n",
    "    users = list(zip(data_train['users'], data_train['num_samples']))\n",
    "    # random.shuffle(users)\n",
    "\n",
    "\n",
    "\n",
    "    total_samples = int(sum(data_train['num_samples']) * SAMPLES_FRACTION)\n",
    "    print('Objective', total_samples, '/', sum(data_train['num_samples']))\n",
    "    sample_count = 0\n",
    "    \n",
    "    for i, (author_id, samples) in enumerate(users):\n",
    "\n",
    "        if sample_count >= total_samples:\n",
    "            print('Max samples reached', sample_count, '/', total_samples)\n",
    "            break\n",
    "\n",
    "        if samples < MIN_SAMPLES: # or data_train['num_samples'][i] > 10000:\n",
    "            print('SKIP', author_id, samples)\n",
    "            continue\n",
    "        else:\n",
    "            udata_train = data_train['user_data'][author_id]\n",
    "            max_samples = samples if (sample_count + samples) <= total_samples else (sample_count + samples - total_samples) \n",
    "            \n",
    "            sample_count += max_samples\n",
    "            # print('sample_count', sample_count)\n",
    "\n",
    "            x_train.extend(data_train['user_data'][author_id]['x'][:max_samples])\n",
    "            y_train.extend(data_train['user_data'][author_id]['y'][:max_samples])\n",
    "\n",
    "            author_data = data_test['user_data'][author_id]\n",
    "            test_size = int(len(author_data['x']) * SAMPLES_FRACTION)\n",
    "\n",
    "            if val_split:\n",
    "                x_test.extend(author_data['x'][:int(test_size / 2)])\n",
    "                y_test.extend(author_data['y'][:int(test_size / 2)])\n",
    "                # x_val.extend(author_data['x'][int(test_size / 2):])\n",
    "                # y_val.extend(author_data['y'][int(test_size / 2):int(test_size)])\n",
    "\n",
    "            else:\n",
    "                x_test.extend(author_data['x'][:int(test_size)])\n",
    "                y_test.extend(author_data['y'][:int(test_size)])\n",
    "\n",
    "    train_ds = ShakespeareDataset(x_train, y_train, corpus, seq_length)\n",
    "    test_ds = ShakespeareDataset(x_test, y_test, corpus, seq_length)\n",
    "    # val_ds = ShakespeareDataset(x_val, y_val, corpus, seq_length)\n",
    "\n",
    "    data_dict = iid_partition_(train_ds, clients=len(users))\n",
    "\n",
    "    return train_ds, data_dict, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFvc8mLoouKa"
   },
   "source": [
    "### Non-IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZ76WsCZot9s"
   },
   "outputs": [],
   "source": [
    "def noniid_partition(corpus, seq_length=80, val_split=False):\n",
    "\n",
    "    train_file = [os.path.join(DATA_DIR, 'train', f) for f in os.listdir(f'{DATA_DIR}/train') if f.endswith('.json')][0]\n",
    "    test_file = [os.path.join(DATA_DIR, 'test', f) for f in os.listdir(f'{DATA_DIR}/test') if f.endswith('.json')][0]\n",
    "\n",
    "    with open(train_file, 'r') as file:\n",
    "        data_train = json.loads(unidecode(file.read()))\n",
    "\n",
    "    with open(test_file, 'r') as file:\n",
    "        data_test = json.loads(unidecode(file.read()))\n",
    "\n",
    "    \n",
    "    total_samples_train = sum(data_train['num_samples'])\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    x_test, y_test = [], []\n",
    "\n",
    "    users = list(zip(data_train['users'], data_train['num_samples']))\n",
    "    # random.shuffle(users)\n",
    "\n",
    "    total_samples = int(sum(data_train['num_samples']) * SAMPLES_FRACTION)\n",
    "    print('Objective', total_samples, '/', sum(data_train['num_samples']))\n",
    "    sample_count = 0\n",
    "    \n",
    "    for i, (author_id, samples) in enumerate(users):\n",
    "\n",
    "        if sample_count >= total_samples:\n",
    "            print('Max samples reached', sample_count, '/', total_samples)\n",
    "            break\n",
    "\n",
    "        if samples < MIN_SAMPLES: # or data_train['num_samples'][i] > 10000:\n",
    "            print('SKIP', author_id, samples)\n",
    "            continue\n",
    "        else:\n",
    "            udata_train = data_train['user_data'][author_id]\n",
    "            max_samples = samples if (sample_count + samples) <= total_samples else (sample_count + samples - total_samples) \n",
    "            \n",
    "            sample_count += max_samples\n",
    "            # print('sample_count', sample_count)\n",
    "\n",
    "            x_train = data_train['user_data'][author_id]['x'][:max_samples]\n",
    "            y_train = data_train['user_data'][author_id]['y'][:max_samples]\n",
    "\n",
    "            train_ds = ShakespeareFedDataset(x_train, y_train, corpus, seq_length)\n",
    "\n",
    "            x_val, y_val = None, None\n",
    "            val_ds = None\n",
    "            author_data = data_test['user_data'][author_id]\n",
    "            test_size = int(len(author_data['x']) * SAMPLES_FRACTION)\n",
    "            if val_split:\n",
    "                x_test += author_data['x'][:int(test_size / 2)]\n",
    "                y_test += author_data['y'][:int(test_size / 2)]\n",
    "                x_val = author_data['x'][int(test_size / 2):]\n",
    "                y_val = author_data['y'][int(test_size / 2):int(test_size)]\n",
    "\n",
    "                val_ds = ShakespeareFedDataset(x_val, y_val, corpus, seq_length)\n",
    "\n",
    "            else:\n",
    "                x_test += author_data['x'][:int(test_size)]\n",
    "                y_test += author_data['y'][:int(test_size)]\n",
    "\n",
    "            data_dict[author_id] = {\n",
    "                'train_ds': train_ds,\n",
    "                'val_ds': val_ds\n",
    "            }\n",
    "\n",
    "    test_ds = ShakespeareFedDataset(x_test, y_test, corpus, seq_length)\n",
    "\n",
    "    return data_dict, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWVOxcAao2_t"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQQQ2mLeo6EA"
   },
   "source": [
    "### Shakespeare LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mGXTrXRot7R"
   },
   "outputs": [],
   "source": [
    "class ShakespeareLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, classes, lstm_layers=2, dropout=0.1, batch_first=True):\n",
    "        super(ShakespeareLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.classes = classes\n",
    "        self.no_layers = lstm_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=self.classes,\n",
    "                                      embedding_dim=self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim,\n",
    "                            num_layers=self.no_layers,\n",
    "                            batch_first=batch_first, \n",
    "                            dropout=dropout if self.no_layers > 1 else 0.)\n",
    "        self.fc = nn.Linear(hidden_dim, self.classes)\n",
    "\n",
    "    def forward(self, x, hc=None):\n",
    "        batch_size = x.size(0)\n",
    "        x_emb = self.embedding(x)\n",
    "        self.lstm.flatten_parameters()\n",
    "        out, (ht, ct) = self.lstm(x_emb.view(batch_size, -1, self.embedding_dim), hc)\n",
    "        dense = self.fc(ht[-1])\n",
    "        return dense\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (Variable(torch.zeros(self.no_layers, batch_size, self.hidden_dim)),\n",
    "                Variable(torch.zeros(self.no_layers, batch_size, self.hidden_dim)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QsuJlVipMc8"
   },
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_Vb0BYpot5I"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "seq_length = 80 # mcmahan17a, fedprox, qFFL\n",
    "\n",
    "shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,  \n",
    "                                   embedding_dim=8,  # mcmahan17a, fedprox, qFFL\n",
    "                                   hidden_dim=256,  # mcmahan17a, fedprox impl\n",
    "                                   # hidden_dim=100,  # fedprox paper\n",
    "                                   classes=len(corpus),\n",
    "                                   lstm_layers=2,\n",
    "                                   dropout=0.1,\n",
    "                                   batch_first=True\n",
    "                                   )\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  shakespeare_lstm.cuda()\n",
    "\n",
    "hc = shakespeare_lstm.init_hidden(batch_size)\n",
    "\n",
    "x_sample = torch.zeros((batch_size, seq_length),\n",
    "                       dtype=torch.long,\n",
    "                       device=(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')))\n",
    "\n",
    "x_sample[0][0] = 1\n",
    "x_sample\n",
    "\n",
    "print(\"\\nShakespeare LSTM SUMMARY\")\n",
    "print(summaryx(shakespeare_lstm, x_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn7egnzTpeks"
   },
   "source": [
    "## FedMed Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFFAfTOwpk4j"
   },
   "source": [
    "### Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyYjWa6IpnTY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "367THsiTpo-C"
   },
   "outputs": [],
   "source": [
    "def plot_scores(history, exp_id, title, suffix):\n",
    "    accuracies = [x['accuracy'] for x in history]\n",
    "    f1_macro = [x['f1_macro'] for x in history]\n",
    "    f1_weighted = [x['f1_weighted'] for x in history]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(accuracies, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test Accuracy', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_Accuracy_{suffix}.jpg', format='jpg', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(f1_macro, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test F1 (macro)', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_F1_Macro_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(f1_weighted, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test F1 (weighted)', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_F1_Weighted_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_losses(history, exp_id, title, suffix):\n",
    "    val_losses = [x['loss'] for x in history]\n",
    "    train_losses = [x['train_loss'] for x in history]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_losses, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Train Loss', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Train_Loss_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(val_losses, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test Loss', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_Loss_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ9PZM0Gp9ve"
   },
   "source": [
    "### Local Training (Client Update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDJFltwdotzZ"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, dataset, idxs):\n",
    "      self.dataset = dataset\n",
    "      self.idxs = list(idxs)\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.idxs)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "      data, label = self.dataset[self.idxs[item]]\n",
    "      return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtRzU5Yepddq"
   },
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "  def __init__(self, dataset, batchSize, learning_rate, epochs, idxs):\n",
    "    # self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batchSize, shuffle=True)\n",
    "    if hasattr(dataset, 'dataloader'):\n",
    "        self.train_loader = dataset.dataloader(batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epochs = epochs\n",
    "\n",
    "  def train(self, model):\n",
    "    # print(\"Client training for {} epochs.\".format(self.epochs))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.5)\n",
    "\n",
    "    # use the weights of global model for proximal term calculation\n",
    "    global_model = copy.deepcopy(model)\n",
    "\n",
    "    # calculate local training time\n",
    "    start_time = time.time()\n",
    "\n",
    "    e_loss = []\n",
    "    for epoch in range(1, self.epochs+1):\n",
    "\n",
    "      train_loss = 0.0\n",
    "      model.train()\n",
    "      for data, labels in self.train_loader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "          data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # make a forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        # do a backwards pass\n",
    "        loss.backward()\n",
    "        # perform a single optimization step\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "      # average losses\n",
    "      train_loss = train_loss/len(self.train_loader.dataset)\n",
    "      e_loss.append(train_loss)\n",
    "\n",
    "    total_loss = sum(e_loss)/len(e_loss)\n",
    "\n",
    "    return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3crFDN0xqGu6"
   },
   "source": [
    "### Server Side Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c085xSOoqEHk"
   },
   "outputs": [],
   "source": [
    "def training(model, rounds, batch_size, lr, ds, data_dict, test_ds, C, K, E, M, plt_title, plt_color, classes, eval_every=1, tb_logger=None):\n",
    "  \"\"\"\n",
    "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
    "  Specifically, this function is used for the server side training and weight update\n",
    "\n",
    "  Params:\n",
    "    - model:           PyTorch model to train\n",
    "    - rounds:          Number of communication rounds for the client update\n",
    "    - batch_size:      Batch size for client update training\n",
    "    - lr:              Learning rate used for client update training\n",
    "    - ds:              Dataset used for training\n",
    "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
    "    - test_data_dict:  Data used for testing the model\n",
    "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
    "    - K:               Total number of clients\n",
    "    - E:               Number of training passes each client makes over its local dataset per round\n",
    "    - mu:              proximal term constant\n",
    "    - percentage:      percentage of selected client to have fewer than E epochs\n",
    "  Returns:\n",
    "    - model:           Trained model on the server\n",
    "  \"\"\"\n",
    "\n",
    "  # global model weights\n",
    "  global_weights = model.state_dict()\n",
    "\n",
    "  # training loss\n",
    "  train_loss = []\n",
    "\n",
    "  # test accuracy\n",
    "  test_accuracy = []\n",
    "\n",
    "  # test loss\n",
    "  test_loss = []\n",
    "\n",
    "  # history\n",
    "  history=[]\n",
    "\n",
    "  # store last loss for convergence\n",
    "  last_loss = 0.0\n",
    "\n",
    "  # total time taken \n",
    "  total_time = 0\n",
    "  start = time.time()\n",
    "\n",
    "\n",
    "  users_id = list(data_dict.keys())\n",
    "\n",
    "  for curr_round in range(1, rounds+1):\n",
    "    w, local_loss = [], []\n",
    "\n",
    "    m = max(int(C*K), 1)\n",
    "    newM = max(int(M*m), 1)\n",
    "\n",
    "    c = 0\n",
    "    S_t = np.random.choice(range(K), m, replace=False)\n",
    "    print('Clients: {}/{} -> {}'.format(len(S_t), K, S_t))\n",
    "\n",
    "    # for i in tqdm(range(len(S_t))):\n",
    "    for i in range(len(S_t)):\n",
    "      if c == newM:\n",
    "        break\n",
    "      c += 1\n",
    "\n",
    "      k = S_t[i]\n",
    "      key = users_id[k]\n",
    "      ds_ = ds if ds else data_dict[key]['train_ds']\n",
    "      idxs = data_dict[key] if ds else None\n",
    "      # print(f'Client {k}: {len(idxs) if idxs else len(ds_)} samples')\n",
    "      local_update = ClientUpdate(dataset=ds_, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=idxs)\n",
    "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
    "\n",
    "      for k in weights.keys():\n",
    "        t = torch.Tensor(weights[k].shape).cuda()\n",
    "        t.fill_(0.1)\n",
    "        weights[k] = t\n",
    "\n",
    "      w.append(copy.deepcopy(weights))\n",
    "      local_loss.append(copy.deepcopy(loss))\n",
    "\n",
    "    for i in tqdm(range(newM, len(S_t))):\n",
    "      k = S_t[i]\n",
    "      key = users_id[k]\n",
    "      ds_ = ds if ds else data_dict[key]['train_ds']\n",
    "      idxs = data_dict[key] if ds else None\n",
    "      # print(f'Client {k}: {len(idxs) if idxs else len(ds_)} samples')\n",
    "      local_update = ClientUpdate(dataset=ds_, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=idxs)\n",
    "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
    "      \n",
    "      w.append(copy.deepcopy(weights))\n",
    "      local_loss.append(copy.deepcopy(loss))\n",
    "      \n",
    "    # calculate time to update the global weights\n",
    "    global_start_time = time.time()\n",
    "\n",
    "    # updating the global weights\n",
    "    target = copy.deepcopy(w[0]);\n",
    "    weights_med = copy.deepcopy(w[0]);\n",
    "    for k in weights_med.keys():\n",
    "      tmp = copy.deepcopy(torch.median(torch.stack([w[i][k].data for i in range(0, len(w))]), dim=0))[0]\n",
    "      target[k].data = tmp\n",
    "\n",
    "    global_weights = target\n",
    "    global_end_time = time.time()\n",
    "\n",
    "    # move the updated weights to our model state dict\n",
    "    model.load_state_dict(global_weights)\n",
    "\n",
    "    # loss\n",
    "    loss_avg = sum(local_loss) / len(local_loss)\n",
    "    print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)))\n",
    "    train_loss.append(loss_avg)\n",
    "    if tb_logger:\n",
    "        tb_logger.add_scalar(f'Train/Loss', loss_avg, curr_round)\n",
    "\n",
    "    # testing\n",
    "    # if curr_round % eval_every == 0:\n",
    "    test_scores = testing(model, test_ds, batch_size * 2, nn.CrossEntropyLoss(), len(classes), classes)\n",
    "    test_scores['train_loss'] = loss_avg\n",
    "    test_loss_current, test_accuracy_current = test_scores['loss'], test_scores['accuracy']\n",
    "\n",
    "    history.append(test_scores)\n",
    "    test_accuracy.append(test_accuracy_current)\n",
    "    test_loss.append(test_loss_current)\n",
    "    \n",
    "    # print('Round: {}... \\tAverage Loss: {} \\tTest Loss: {} \\tTest Acc: {}'.format(curr_round, round(loss_avg, 3), round(test_loss, 3), round(test_accuracy, 3)))\n",
    "\n",
    "    if tb_logger:\n",
    "        tb_logger.add_scalar(f'Test/Loss', test_scores['loss'], curr_round)\n",
    "        tb_logger.add_scalars(f'Test/Scores', {\n",
    "            'accuracy': test_scores['accuracy'], 'f1_macro': test_scores['f1_macro'], 'f1_weighted': test_scores['f1_weighted']\n",
    "        }, curr_round)\n",
    "    \n",
    "    # update the last loss\n",
    "    last_loss = loss_avg\n",
    "\n",
    "  end = time.time()\n",
    "  \n",
    "  # plot train loss\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(train_loss)\n",
    "  ax.plot(x_axis, y_axis)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Train Loss', title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Train_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_loss)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Loss',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  # plot test accuracy\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_accuracy)\n",
    "  ax.plot(x_axis, y_axis)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Accuracy', title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_Accuracy.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  print(\"Training Done! Total time taken to Train: {}\".format(end-start))\n",
    "\n",
    "  return model, train_loss, test_accuracy, test_loss, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXtGLkoAqLIW"
   },
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQJIJno4qKvc"
   },
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion, num_classes, classes, print_all=False):\n",
    "  #test loss \n",
    "  test_loss = 0.0\n",
    "  correct_class = list(0. for i in range(num_classes))\n",
    "  total_class = list(0. for i in range(num_classes))\n",
    "\n",
    "  test_loader = DataLoader(dataset, batch_size=bs)\n",
    "  l = len(test_loader)\n",
    "  model.eval()\n",
    "  print('running validation...')\n",
    "  for i, (data, labels) in enumerate(tqdm(test_loader)):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "      data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    output = model(data)\n",
    "    loss = criterion(output, labels)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "\n",
    "    # For F1Score\n",
    "    y_true = np.append(y_true, labels.data.view_as(pred).cpu().numpy()) if i != 0 else labels.data.view_as(pred).cpu().numpy()\n",
    "    y_hat = np.append(y_hat, pred.cpu().numpy()) if i != 0 else pred.cpu().numpy()\n",
    "\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "    for i, lbl in enumerate(labels.data):\n",
    "    #   print('lbl', i, lbl)\n",
    "      correct_class[lbl] += correct.data[i]\n",
    "      total_class[lbl] += 1\n",
    "    \n",
    "  # avg test loss\n",
    "  test_loss = test_loss/len(test_loader.dataset)\n",
    "  print(\"Test Loss: {:.6f}\\n\".format(test_loss))\n",
    "\n",
    "  # Avg F1 Score\n",
    "  f1_macro = f1_score(y_true, y_hat, average='macro')\n",
    "  # F1-Score -> weigthed to consider class imbalance\n",
    "  f1_weighted =  f1_score(y_true, y_hat, average='weighted')\n",
    "  print(\"F1 Score: {:.6f} (macro) {:.6f} (weighted) %\\n\".format(f1_macro, f1_weighted))\n",
    "\n",
    "  # print test accuracy\n",
    "  if print_all:\n",
    "    for i in range(num_classes):\n",
    "        if total_class[i]>0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % \n",
    "                    (classes[i], 100 * correct_class[i] / total_class[i],\n",
    "                    np.sum(correct_class[i]), np.sum(total_class[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "  overall_accuracy = np.sum(correct_class) / np.sum(total_class)\n",
    "\n",
    "  print('\\nFinal Test  Accuracy: {:.3f} ({}/{})'.format(overall_accuracy, np.sum(correct_class), np.sum(total_class)))\n",
    "\n",
    "  return {'loss': test_loss, 'accuracy': overall_accuracy, 'f1_macro': f1_macro, 'f1_weighted': f1_weighted}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxqXLBd8qbC2"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8gl5P3SMq4a"
   },
   "outputs": [],
   "source": [
    "log_dict = {}\n",
    "NUM_REPEAT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2CfSkNVqKtL"
   },
   "outputs": [],
   "source": [
    "seq_length = 80  # mcmahan17a, fedprox, qFFL\n",
    "embedding_dim = 8  # mcmahan17a, fedprox, qFFL\n",
    "# hidden_dim = 100  # fedprox paper\n",
    "hidden_dim = 256  # mcmahan17a, fedprox impl\n",
    "num_classes = len(corpus)\n",
    "classes = list(range(num_classes))\n",
    "lstm_layers = 2  # mcmahan17a, fedprox, qFFL\n",
    "dropout = 0.1  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPIpStyNJ-63"
   },
   "source": [
    "## LSTM FedMed on IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpS1gyJ_H_MA"
   },
   "outputs": [],
   "source": [
    "train_ds, data_dict, test_ds = iid_partition(corpus, seq_length, val_split=True)  # Not using val_ds but makes train eval periods faster\n",
    "\n",
    "total_clients = len(data_dict.keys())\n",
    "'Total users:', total_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYoGsy05H_RC"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # partition data\n",
    "  train_ds, data_dict, test_ds = iid_partition(corpus, seq_length, val_split=True)  # Not using val_ds but makes train eval periods faster\n",
    "  total_clients = len(data_dict.keys())\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.07  # 10 clients\n",
    "  # number of clients\n",
    "  K = total_clients\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 5\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr = 0.8\n",
    "  # proximal term constant\n",
    "  M = 0.01\n",
    "\n",
    "  shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,  \n",
    "                                    embedding_dim=embedding_dim,  \n",
    "                                    hidden_dim=hidden_dim,\n",
    "                                    classes=num_classes,\n",
    "                                    lstm_layers=lstm_layers,\n",
    "                                    dropout=dropout,\n",
    "                                    batch_first=True\n",
    "                                    )\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      shakespeare_lstm.cuda()\n",
    "\n",
    "  lstm_iid_trained, train_loss, test_accuracy, test_loss, history = training(shakespeare_lstm,\n",
    "                                          rounds, batch_size, lr,\n",
    "                                          train_ds,\n",
    "                                          data_dict,\n",
    "                                          test_ds,\n",
    "                                          C, K, E, M,\n",
    "                                          'Shakespeare LSTM on IID', \"green\",\n",
    "                                          corpus, # classes\n",
    "                                          )\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss\n",
    "\n",
    "  del lstm_iid_trained\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-irvQHuNNTtB"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               'M': M,\n",
    "               }\n",
    "\n",
    "log_dict['Shakespeare LSTM on IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'history': history,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QO0GkVyKEgu"
   },
   "source": [
    "## LSTM FedMed on Non IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wsHRfwmKGdS"
   },
   "outputs": [],
   "source": [
    "data_dict, test_ds = noniid_partition(corpus, seq_length=seq_length, val_split=False)\n",
    " \n",
    "total_clients = len(data_dict.keys())  \n",
    "'Total users:', total_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNJZG5tvKGgd"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "  # partition dataset\n",
    "  data_dict, test_ds = noniid_partition(corpus, seq_length=seq_length, val_split=False)\n",
    "  total_clients = len(data_dict.keys())  \n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.07  # 10 clients\n",
    "  # number of clients\n",
    "  K = total_clients\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 5\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr = 0.8\n",
    "  # proximal term constant\n",
    "  M = 0.01\n",
    "\n",
    "  shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,\n",
    "                                        embedding_dim=embedding_dim,\n",
    "                                        hidden_dim=hidden_dim,\n",
    "                                        classes=num_classes,\n",
    "                                        lstm_layers=lstm_layers,\n",
    "                                        dropout=dropout,\n",
    "                                        batch_first=True\n",
    "                                        )\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      shakespeare_lstm.cuda()\n",
    "\n",
    "  lstm_non_iid_trained, train_loss, test_accuracy, test_loss, history = training(shakespeare_lstm,\n",
    "                                                rounds, batch_size, lr,\n",
    "                                                None, #  ds empty as it is included in data_dict\n",
    "                                                data_dict,\n",
    "                                                test_ds,\n",
    "                                                C, K, E, M,\n",
    "                                                'Shakespeare LSTM on Non IID', \"green\",\n",
    "                                                corpus, # classes,\n",
    "                                                )\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss\n",
    "\n",
    "  del lstm_non_iid_trained\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uANkBpTRKGkv"
   },
   "outputs": [],
   "source": [
    " hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               'M': M,\n",
    "               }\n",
    "\n",
    "log_dict['Shakespeare LSTM on Non IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'history': history,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShdScPNuQzUQ"
   },
   "source": [
    "## Pickle Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwHt7jviQ1AV"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(path + 'Local_Round_FedMed_5.pkl', 'wb') as file:\n",
    "  pickle.dump(log_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qNkwXxO8Q3Ei"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shakespeare LSTM on IID': {'history': [{'accuracy': 0.30049899427510446,\n",
       "    'f1_macro': 0.035707107291389976,\n",
       "    'f1_weighted': 0.20364289982365094,\n",
       "    'loss': 2.628428847381579,\n",
       "    'train_loss': 2.7083589281506564},\n",
       "   {'accuracy': 0.36693485997214914,\n",
       "    'f1_macro': 0.08829746149060783,\n",
       "    'f1_weighted': 0.30273081763443316,\n",
       "    'loss': 2.2358995009165845,\n",
       "    'train_loss': 2.3191037978260765},\n",
       "   {'accuracy': 0.3997756459848368,\n",
       "    'f1_macro': 0.12309210962453974,\n",
       "    'f1_weighted': 0.3595738827692406,\n",
       "    'loss': 2.116290607011375,\n",
       "    'train_loss': 2.014256622985541},\n",
       "   {'accuracy': 0.4253829490948476,\n",
       "    'f1_macro': 0.1355251417366761,\n",
       "    'f1_weighted': 0.38658467839798377,\n",
       "    'loss': 2.0689050994649745,\n",
       "    'train_loss': 1.7923125872310681},\n",
       "   {'accuracy': 0.43259709113414824,\n",
       "    'f1_macro': 0.14181047341196062,\n",
       "    'f1_weighted': 0.39954622642455734,\n",
       "    'loss': 2.046155003116916,\n",
       "    'train_loss': 1.6495337091072528},\n",
       "   {'accuracy': 0.4419774098715767,\n",
       "    'f1_macro': 0.14840736097309398,\n",
       "    'f1_weighted': 0.40742477504681474,\n",
       "    'loss': 2.05850020165332,\n",
       "    'train_loss': 1.5118463633324368},\n",
       "   {'accuracy': 0.44567151477641964,\n",
       "    'f1_macro': 0.1463116507312884,\n",
       "    'f1_weighted': 0.4161168862797097,\n",
       "    'loss': 2.053658525055554,\n",
       "    'train_loss': 1.4191929841679454},\n",
       "   {'accuracy': 0.44835989478570326,\n",
       "    'f1_macro': 0.1538856675765707,\n",
       "    'f1_weighted': 0.41695978655912813,\n",
       "    'loss': 2.064490881846414,\n",
       "    'train_loss': 1.362118258487593},\n",
       "   {'accuracy': 0.4498491412656661,\n",
       "    'f1_macro': 0.1590762723603423,\n",
       "    'f1_weighted': 0.41946921339535703,\n",
       "    'loss': 2.0629626311851443,\n",
       "    'train_loss': 1.3326055292294776},\n",
       "   {'accuracy': 0.45099025220485844,\n",
       "    'f1_macro': 0.16099068867204075,\n",
       "    'f1_weighted': 0.42422057628541976,\n",
       "    'loss': 2.048146631910621,\n",
       "    'train_loss': 1.2998474646177476},\n",
       "   {'accuracy': 0.4547036979730775,\n",
       "    'f1_macro': 0.16755175174342232,\n",
       "    'f1_weighted': 0.4255465293450274,\n",
       "    'loss': 2.0603833103777043,\n",
       "    'train_loss': 1.2962324497965794},\n",
       "   {'accuracy': 0.45400742689153645,\n",
       "    'f1_macro': 0.16654781868920093,\n",
       "    'f1_weighted': 0.4293574949684566,\n",
       "    'loss': 2.040133178014491,\n",
       "    'train_loss': 1.264347450379617},\n",
       "   {'accuracy': 0.4605833204394244,\n",
       "    'f1_macro': 0.17128934216597544,\n",
       "    'f1_weighted': 0.43208408960146055,\n",
       "    'loss': 2.0487285602533603,\n",
       "    'train_loss': 1.233050571011346},\n",
       "   {'accuracy': 0.45859121151168186,\n",
       "    'f1_macro': 0.17394862677826536,\n",
       "    'f1_weighted': 0.43713792265485263,\n",
       "    'loss': 2.049875336389011,\n",
       "    'train_loss': 1.1983214160470408},\n",
       "   {'accuracy': 0.46267213368404764,\n",
       "    'f1_macro': 0.17628974274557016,\n",
       "    'f1_weighted': 0.43680170084043235,\n",
       "    'loss': 2.0724054694206844,\n",
       "    'train_loss': 1.1642598253669523},\n",
       "   {'accuracy': 0.4623626798700294,\n",
       "    'f1_macro': 0.17696403445652095,\n",
       "    'f1_weighted': 0.437186052046901,\n",
       "    'loss': 2.0677807069397685,\n",
       "    'train_loss': 1.1826255192188062},\n",
       "   {'accuracy': 0.4629815874980659,\n",
       "    'f1_macro': 0.18101215813249413,\n",
       "    'f1_weighted': 0.4421987798370691,\n",
       "    'loss': 2.022084206594873,\n",
       "    'train_loss': 1.2202572065947013},\n",
       "   {'accuracy': 0.4700410026303574,\n",
       "    'f1_macro': 0.18140701339801796,\n",
       "    'f1_weighted': 0.443966044142421,\n",
       "    'loss': 2.0500434457903585,\n",
       "    'train_loss': 1.1499459154924065},\n",
       "   {'accuracy': 0.4670044870803033,\n",
       "    'f1_macro': 0.18567447117702998,\n",
       "    'f1_weighted': 0.4419968826167111,\n",
       "    'loss': 2.062030463288526,\n",
       "    'train_loss': 1.1707169069521908},\n",
       "   {'accuracy': 0.4687258239207798,\n",
       "    'f1_macro': 0.18534535143386996,\n",
       "    'f1_weighted': 0.447252336302021,\n",
       "    'loss': 2.0463596921983047,\n",
       "    'train_loss': 1.137407679734539},\n",
       "   {'accuracy': 0.4703117747176234,\n",
       "    'f1_macro': 0.18273105499811002,\n",
       "    'f1_weighted': 0.4453783241121226,\n",
       "    'loss': 2.0577207041315533,\n",
       "    'train_loss': 1.1481442318494044},\n",
       "   {'accuracy': 0.4697702305430914,\n",
       "    'f1_macro': 0.1856314908158044,\n",
       "    'f1_weighted': 0.44724860475853057,\n",
       "    'loss': 2.0244831757191424,\n",
       "    'train_loss': 1.1715375730997135},\n",
       "   {'accuracy': 0.47298081386353086,\n",
       "    'f1_macro': 0.190291943195637,\n",
       "    'f1_weighted': 0.45011927774780175,\n",
       "    'loss': 2.020184629247614,\n",
       "    'train_loss': 1.135347630997803},\n",
       "   {'accuracy': 0.47419928825622776,\n",
       "    'f1_macro': 0.19164264587259203,\n",
       "    'f1_weighted': 0.4510627040986048,\n",
       "    'loss': 2.0222402165499624,\n",
       "    'train_loss': 1.1506645012567822},\n",
       "   {'accuracy': 0.4753017174686678,\n",
       "    'f1_macro': 0.19008218010518513,\n",
       "    'f1_weighted': 0.4540702080376509,\n",
       "    'loss': 2.0178128993863496,\n",
       "    'train_loss': 1.129297607791878},\n",
       "   {'accuracy': 0.4756885347361906,\n",
       "    'f1_macro': 0.1920029824981149,\n",
       "    'f1_weighted': 0.45166579975862575,\n",
       "    'loss': 2.0072530202352,\n",
       "    'train_loss': 1.1391944698767493},\n",
       "   {'accuracy': 0.4780287792047037,\n",
       "    'f1_macro': 0.19253945404456138,\n",
       "    'f1_weighted': 0.45262896702987326,\n",
       "    'loss': 2.0373745062974247,\n",
       "    'train_loss': 1.1151670448082156},\n",
       "   {'accuracy': 0.47942132136778587,\n",
       "    'f1_macro': 0.19111442988376268,\n",
       "    'f1_weighted': 0.4525010872957845,\n",
       "    'loss': 2.042397358934475,\n",
       "    'train_loss': 1.1104627760109795},\n",
       "   {'accuracy': 0.4810459538913817,\n",
       "    'f1_macro': 0.195917195915255,\n",
       "    'f1_weighted': 0.45399553174718177,\n",
       "    'loss': 2.0100604902515418,\n",
       "    'train_loss': 1.133537817574119},\n",
       "   {'accuracy': 0.4799241838155655,\n",
       "    'f1_macro': 0.19855981818335175,\n",
       "    'f1_weighted': 0.45941728930578507,\n",
       "    'loss': 2.0169724592244167,\n",
       "    'train_loss': 1.1101367416274817},\n",
       "   {'accuracy': 0.4790731858270153,\n",
       "    'f1_macro': 0.19350151998191253,\n",
       "    'f1_weighted': 0.45930455998802844,\n",
       "    'loss': 2.0143916290619415,\n",
       "    'train_loss': 1.1024072116130852},\n",
       "   {'accuracy': 0.4800402289958224,\n",
       "    'f1_macro': 0.1980541565504848,\n",
       "    'f1_weighted': 0.4577297516729607,\n",
       "    'loss': 2.01671980615315,\n",
       "    'train_loss': 1.1084437018592732},\n",
       "   {'accuracy': 0.477390530713291,\n",
       "    'f1_macro': 0.1982714988209507,\n",
       "    'f1_weighted': 0.4571765547886931,\n",
       "    'loss': 2.0308662342155763,\n",
       "    'train_loss': 1.0939986642056314},\n",
       "   {'accuracy': 0.4802916602197122,\n",
       "    'f1_macro': 0.19489531039321945,\n",
       "    'f1_weighted': 0.45885551427304966,\n",
       "    'loss': 2.008288580094829,\n",
       "    'train_loss': 1.1365568552773824},\n",
       "   {'accuracy': 0.4787443911496209,\n",
       "    'f1_macro': 0.19825786556494615,\n",
       "    'f1_weighted': 0.45634728964844645,\n",
       "    'loss': 2.0302536180456165,\n",
       "    'train_loss': 1.0864993058753305},\n",
       "   {'accuracy': 0.47855098251585954,\n",
       "    'f1_macro': 0.2016021008317581,\n",
       "    'f1_weighted': 0.45883856047480176,\n",
       "    'loss': 2.0097416655410356,\n",
       "    'train_loss': 1.1146421551549572},\n",
       "   {'accuracy': 0.4818389292898035,\n",
       "    'f1_macro': 0.19931873041302275,\n",
       "    'f1_weighted': 0.46016521795501864,\n",
       "    'loss': 1.9867842308094725,\n",
       "    'train_loss': 1.1527344738601877},\n",
       "   {'accuracy': 0.48230311001083087,\n",
       "    'f1_macro': 0.19759045537003755,\n",
       "    'f1_weighted': 0.45920106823173246,\n",
       "    'loss': 2.0304409518164115,\n",
       "    'train_loss': 1.062516178258909},\n",
       "   {'accuracy': 0.4819936561968126,\n",
       "    'f1_macro': 0.19900627725967796,\n",
       "    'f1_weighted': 0.4625561552869748,\n",
       "    'loss': 1.971113621789121,\n",
       "    'train_loss': 1.1228033349157425},\n",
       "   {'accuracy': 0.4810459538913817,\n",
       "    'f1_macro': 0.1896692924145636,\n",
       "    'f1_weighted': 0.4565543336174737,\n",
       "    'loss': 2.0107428228663307,\n",
       "    'train_loss': 1.0874540260437724},\n",
       "   {'accuracy': 0.48448862757233485,\n",
       "    'f1_macro': 0.19435273078412038,\n",
       "    'f1_weighted': 0.4610192671366429,\n",
       "    'loss': 2.000180280895775,\n",
       "    'train_loss': 1.0826987043964769},\n",
       "   {'accuracy': 0.48303806281912426,\n",
       "    'f1_macro': 0.20233605123007817,\n",
       "    'f1_weighted': 0.46168551049735995,\n",
       "    'loss': 1.989963413167756,\n",
       "    'train_loss': 1.0914419624655616},\n",
       "   {'accuracy': 0.4835796069936562,\n",
       "    'f1_macro': 0.20030452447370964,\n",
       "    'f1_weighted': 0.46537858197866105,\n",
       "    'loss': 1.9757850555116265,\n",
       "    'train_loss': 1.0790828197283597},\n",
       "   {'accuracy': 0.4829606993656197,\n",
       "    'f1_macro': 0.2024759575109994,\n",
       "    'f1_weighted': 0.46453256406565097,\n",
       "    'loss': 1.9804940108188522,\n",
       "    'train_loss': 1.1010189908185497},\n",
       "   {'accuracy': 0.4869255763577286,\n",
       "    'f1_macro': 0.19756886624960654,\n",
       "    'f1_weighted': 0.46239063688146487,\n",
       "    'loss': 1.9962716709426716,\n",
       "    'train_loss': 1.1148885047731},\n",
       "   {'accuracy': 0.48684821290422403,\n",
       "    'f1_macro': 0.2070622239349432,\n",
       "    'f1_weighted': 0.47022050735542853,\n",
       "    'loss': 1.9719942337178407,\n",
       "    'train_loss': 1.080486482037708},\n",
       "   {'accuracy': 0.4880280055701687,\n",
       "    'f1_macro': 0.20534370032728902,\n",
       "    'f1_weighted': 0.4669361978508444,\n",
       "    'loss': 2.007139127196016,\n",
       "    'train_loss': 1.0649147156264278},\n",
       "   {'accuracy': 0.4841404920315643,\n",
       "    'f1_macro': 0.20183032070184156,\n",
       "    'f1_weighted': 0.46552942028385597,\n",
       "    'loss': 1.9743117740925078,\n",
       "    'train_loss': 1.1145367923482512},\n",
       "   {'accuracy': 0.48872427665170975,\n",
       "    'f1_macro': 0.20064847023216778,\n",
       "    'f1_weighted': 0.4653095289683048,\n",
       "    'loss': 1.9561889639846795,\n",
       "    'train_loss': 1.1170008678944268},\n",
       "   {'accuracy': 0.49089045334983755,\n",
       "    'f1_macro': 0.20457942221576994,\n",
       "    'f1_weighted': 0.46753815097209644,\n",
       "    'loss': 1.9637344245512558,\n",
       "    'train_loss': 1.1298429648717643}],\n",
       "  'hyperparams': {'C': 0.07,\n",
       "   'E': 5,\n",
       "   'K': 143,\n",
       "   'M': 0.01,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.8,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[0.2919309917994739,\n",
       "    0.3724470060343494,\n",
       "    0.40323766052916604,\n",
       "    0.42447392851616894,\n",
       "    0.4348019495590283,\n",
       "    0.4369101036670277,\n",
       "    0.4498104595389138,\n",
       "    0.4437954510289339,\n",
       "    0.45010057248955593,\n",
       "    0.45495512919696734,\n",
       "    0.4545489710660684,\n",
       "    0.4591327556862138,\n",
       "    0.45899736964258087,\n",
       "    0.4591327556862138,\n",
       "    0.46135695497447005,\n",
       "    0.46135695497447005,\n",
       "    0.46398731239362523,\n",
       "    0.463542472535974,\n",
       "    0.4685324152870184,\n",
       "    0.4656506266439734,\n",
       "    0.4677200990252205,\n",
       "    0.47033111558099955,\n",
       "    0.4689385734179174,\n",
       "    0.47236190623549434,\n",
       "    0.4691900046418072,\n",
       "    0.46770075816184437,\n",
       "    0.47249729227912735,\n",
       "    0.4720911341482284,\n",
       "    0.4738511527154572,\n",
       "    0.47516633142503484,\n",
       "    0.4735610397648151,\n",
       "    0.47777734798081384,\n",
       "    0.47539842178554853,\n",
       "    0.4783188921553458,\n",
       "    0.4790151632368869,\n",
       "    0.4788217546031255,\n",
       "    0.48108463561813397,\n",
       "    0.4792085718706483,\n",
       "    0.4803303419464645,\n",
       "    0.48031100108308833,\n",
       "    0.4805237505802259,\n",
       "    0.48195497447006036,\n",
       "    0.4835796069936562,\n",
       "    0.4778547114343184,\n",
       "    0.4831154262726288,\n",
       "    0.48495280829336224,\n",
       "    0.4831154262726288,\n",
       "    0.48276729073185826,\n",
       "    0.4865967816803342,\n",
       "    0.48704162153798547],\n",
       "   [0.30049899427510446,\n",
       "    0.36693485997214914,\n",
       "    0.3997756459848368,\n",
       "    0.4253829490948476,\n",
       "    0.43259709113414824,\n",
       "    0.4419774098715767,\n",
       "    0.44567151477641964,\n",
       "    0.44835989478570326,\n",
       "    0.4498491412656661,\n",
       "    0.45099025220485844,\n",
       "    0.4547036979730775,\n",
       "    0.45400742689153645,\n",
       "    0.4605833204394244,\n",
       "    0.45859121151168186,\n",
       "    0.46267213368404764,\n",
       "    0.4623626798700294,\n",
       "    0.4629815874980659,\n",
       "    0.4700410026303574,\n",
       "    0.4670044870803033,\n",
       "    0.4687258239207798,\n",
       "    0.4703117747176234,\n",
       "    0.4697702305430914,\n",
       "    0.47298081386353086,\n",
       "    0.47419928825622776,\n",
       "    0.4753017174686678,\n",
       "    0.4756885347361906,\n",
       "    0.4780287792047037,\n",
       "    0.47942132136778587,\n",
       "    0.4810459538913817,\n",
       "    0.4799241838155655,\n",
       "    0.4790731858270153,\n",
       "    0.4800402289958224,\n",
       "    0.477390530713291,\n",
       "    0.4802916602197122,\n",
       "    0.4787443911496209,\n",
       "    0.47855098251585954,\n",
       "    0.4818389292898035,\n",
       "    0.48230311001083087,\n",
       "    0.4819936561968126,\n",
       "    0.4810459538913817,\n",
       "    0.48448862757233485,\n",
       "    0.48303806281912426,\n",
       "    0.4835796069936562,\n",
       "    0.4829606993656197,\n",
       "    0.4869255763577286,\n",
       "    0.48684821290422403,\n",
       "    0.4880280055701687,\n",
       "    0.4841404920315643,\n",
       "    0.48872427665170975,\n",
       "    0.49089045334983755]],\n",
       "  'test_loss': [[2.6779249328800017,\n",
       "    2.235698129584615,\n",
       "    2.10972946091827,\n",
       "    2.0609972273627433,\n",
       "    2.0518916424173064,\n",
       "    2.052734631716481,\n",
       "    2.030785779133969,\n",
       "    2.0654123856050717,\n",
       "    2.048690597784237,\n",
       "    2.0479890254886572,\n",
       "    2.0552280313445883,\n",
       "    2.04225580045775,\n",
       "    2.049907781106482,\n",
       "    2.0623387811688465,\n",
       "    2.0780455642545177,\n",
       "    2.0600777862616013,\n",
       "    2.054473769803908,\n",
       "    2.0600206333303483,\n",
       "    2.0425355895632067,\n",
       "    2.021507719102956,\n",
       "    2.0552999691978044,\n",
       "    2.0400049155312874,\n",
       "    2.031019779700632,\n",
       "    2.0319660536082567,\n",
       "    2.0058778176306364,\n",
       "    2.0144284553295564,\n",
       "    2.040944423301152,\n",
       "    2.0099440884803648,\n",
       "    2.0154243396580998,\n",
       "    2.0202107100980826,\n",
       "    2.0109169361148846,\n",
       "    2.018557669370375,\n",
       "    2.0274389436151172,\n",
       "    1.9821552247994667,\n",
       "    2.0047297213170645,\n",
       "    2.010739153954263,\n",
       "    2.011685104644969,\n",
       "    1.995315624337281,\n",
       "    1.9953973107725849,\n",
       "    2.015101602233851,\n",
       "    2.0113039426200072,\n",
       "    2.003606814915021,\n",
       "    1.985377384839646,\n",
       "    1.9934547582954518,\n",
       "    1.9656747898498168,\n",
       "    1.9815229581028877,\n",
       "    2.017724233437096,\n",
       "    1.990859971347572,\n",
       "    1.9775960506675654,\n",
       "    1.9966044985167146],\n",
       "   [2.628428847381579,\n",
       "    2.2358995009165845,\n",
       "    2.116290607011375,\n",
       "    2.0689050994649745,\n",
       "    2.046155003116916,\n",
       "    2.05850020165332,\n",
       "    2.053658525055554,\n",
       "    2.064490881846414,\n",
       "    2.0629626311851443,\n",
       "    2.048146631910621,\n",
       "    2.0603833103777043,\n",
       "    2.040133178014491,\n",
       "    2.0487285602533603,\n",
       "    2.049875336389011,\n",
       "    2.0724054694206844,\n",
       "    2.0677807069397685,\n",
       "    2.022084206594873,\n",
       "    2.0500434457903585,\n",
       "    2.062030463288526,\n",
       "    2.0463596921983047,\n",
       "    2.0577207041315533,\n",
       "    2.0244831757191424,\n",
       "    2.020184629247614,\n",
       "    2.0222402165499624,\n",
       "    2.0178128993863496,\n",
       "    2.0072530202352,\n",
       "    2.0373745062974247,\n",
       "    2.042397358934475,\n",
       "    2.0100604902515418,\n",
       "    2.0169724592244167,\n",
       "    2.0143916290619415,\n",
       "    2.01671980615315,\n",
       "    2.0308662342155763,\n",
       "    2.008288580094829,\n",
       "    2.0302536180456165,\n",
       "    2.0097416655410356,\n",
       "    1.9867842308094725,\n",
       "    2.0304409518164115,\n",
       "    1.971113621789121,\n",
       "    2.0107428228663307,\n",
       "    2.000180280895775,\n",
       "    1.989963413167756,\n",
       "    1.9757850555116265,\n",
       "    1.9804940108188522,\n",
       "    1.9962716709426716,\n",
       "    1.9719942337178407,\n",
       "    2.007139127196016,\n",
       "    1.9743117740925078,\n",
       "    1.9561889639846795,\n",
       "    1.9637344245512558]],\n",
       "  'train_loss': [[2.727059651873362,\n",
       "    2.326837158053598,\n",
       "    2.0468327310749355,\n",
       "    1.8273648788653218,\n",
       "    1.6440130942786833,\n",
       "    1.5351230379689695,\n",
       "    1.4612000562563632,\n",
       "    1.3651574661318253,\n",
       "    1.346813936732596,\n",
       "    1.2819642628139925,\n",
       "    1.2897677947321124,\n",
       "    1.2515556038417863,\n",
       "    1.2188795236113157,\n",
       "    1.2232367338378751,\n",
       "    1.2218903581113882,\n",
       "    1.1994466587424761,\n",
       "    1.1864677027836612,\n",
       "    1.213374550973618,\n",
       "    1.1598683687546811,\n",
       "    1.1738178581008523,\n",
       "    1.148726183737011,\n",
       "    1.1424321793135834,\n",
       "    1.1406566691422322,\n",
       "    1.147056347869782,\n",
       "    1.1763267565549662,\n",
       "    1.167707191924413,\n",
       "    1.1403735424399073,\n",
       "    1.145392801969777,\n",
       "    1.125324153564474,\n",
       "    1.1394701905504305,\n",
       "    1.1111358572728638,\n",
       "    1.1615913930066384,\n",
       "    1.1540131105560831,\n",
       "    1.1925744697780387,\n",
       "    1.1181279299414637,\n",
       "    1.132703884848214,\n",
       "    1.1410623748217774,\n",
       "    1.0935760177199034,\n",
       "    1.1170257463339521,\n",
       "    1.1171297474087243,\n",
       "    1.1275379320216132,\n",
       "    1.1204518440883622,\n",
       "    1.1226362917287582,\n",
       "    1.160399314289034,\n",
       "    1.1578290965749443,\n",
       "    1.117652826723636,\n",
       "    1.0707478153446053,\n",
       "    1.1310549835227612,\n",
       "    1.145156097370377,\n",
       "    1.0915892030190764],\n",
       "   [2.7083589281506564,\n",
       "    2.3191037978260765,\n",
       "    2.014256622985541,\n",
       "    1.7923125872310681,\n",
       "    1.6495337091072528,\n",
       "    1.5118463633324368,\n",
       "    1.4191929841679454,\n",
       "    1.362118258487593,\n",
       "    1.3326055292294776,\n",
       "    1.2998474646177476,\n",
       "    1.2962324497965794,\n",
       "    1.264347450379617,\n",
       "    1.233050571011346,\n",
       "    1.1983214160470408,\n",
       "    1.1642598253669523,\n",
       "    1.1826255192188062,\n",
       "    1.2202572065947013,\n",
       "    1.1499459154924065,\n",
       "    1.1707169069521908,\n",
       "    1.137407679734539,\n",
       "    1.1481442318494044,\n",
       "    1.1715375730997135,\n",
       "    1.135347630997803,\n",
       "    1.1506645012567822,\n",
       "    1.129297607791878,\n",
       "    1.1391944698767493,\n",
       "    1.1151670448082156,\n",
       "    1.1104627760109795,\n",
       "    1.133537817574119,\n",
       "    1.1101367416274817,\n",
       "    1.1024072116130852,\n",
       "    1.1084437018592732,\n",
       "    1.0939986642056314,\n",
       "    1.1365568552773824,\n",
       "    1.0864993058753305,\n",
       "    1.1146421551549572,\n",
       "    1.1527344738601877,\n",
       "    1.062516178258909,\n",
       "    1.1228033349157425,\n",
       "    1.0874540260437724,\n",
       "    1.0826987043964769,\n",
       "    1.0914419624655616,\n",
       "    1.0790828197283597,\n",
       "    1.1010189908185497,\n",
       "    1.1148885047731,\n",
       "    1.080486482037708,\n",
       "    1.0649147156264278,\n",
       "    1.1145367923482512,\n",
       "    1.1170008678944268,\n",
       "    1.1298429648717643]]},\n",
       " 'Shakespeare LSTM on Non IID': {'history': [{'accuracy': 0.1882350667298047,\n",
       "    'f1_macro': 0.007716593754334542,\n",
       "    'f1_weighted': 0.08422957738794828,\n",
       "    'loss': 3.1030948995162593,\n",
       "    'train_loss': 3.0407416653811556},\n",
       "   {'accuracy': 0.22673637619954193,\n",
       "    'f1_macro': 0.021695843802209992,\n",
       "    'f1_weighted': 0.1466994680413453,\n",
       "    'loss': 2.8292785049163354,\n",
       "    'train_loss': 2.6628495481971375},\n",
       "   {'accuracy': 0.30050156073330303,\n",
       "    'f1_macro': 0.038656322126210646,\n",
       "    'f1_weighted': 0.2078514922975185,\n",
       "    'loss': 2.5873728958585795,\n",
       "    'train_loss': 2.4107734065991537},\n",
       "   {'accuracy': 0.3338229751538989,\n",
       "    'f1_macro': 0.0669532799752985,\n",
       "    'f1_weighted': 0.2798214993882138,\n",
       "    'loss': 2.489639851712807,\n",
       "    'train_loss': 2.0816250941038574},\n",
       "   {'accuracy': 0.3583598287542159,\n",
       "    'f1_macro': 0.07376931771388497,\n",
       "    'f1_weighted': 0.3048563345488462,\n",
       "    'loss': 2.430910937870915,\n",
       "    'train_loss': 1.8531370002262872},\n",
       "   {'accuracy': 0.3600993457483305,\n",
       "    'f1_macro': 0.08031331535566688,\n",
       "    'f1_weighted': 0.3070228608143511,\n",
       "    'loss': 2.427248329267774,\n",
       "    'train_loss': 1.490720051141887},\n",
       "   {'accuracy': 0.370120896431091,\n",
       "    'f1_macro': 0.08944764502599355,\n",
       "    'f1_weighted': 0.31768298357588104,\n",
       "    'loss': 2.3537743078426994,\n",
       "    'train_loss': 1.564870000968117},\n",
       "   {'accuracy': 0.391062748243571,\n",
       "    'f1_macro': 0.10248832451443163,\n",
       "    'f1_weighted': 0.34513953319679275,\n",
       "    'loss': 2.183273864729947,\n",
       "    'train_loss': 1.5450653990984475},\n",
       "   {'accuracy': 0.39961537346463466,\n",
       "    'f1_macro': 0.11007568428453451,\n",
       "    'f1_weighted': 0.359199643662035,\n",
       "    'loss': 2.253861902877047,\n",
       "    'train_loss': 1.4046218464151548},\n",
       "   {'accuracy': 0.41196594412284854,\n",
       "    'f1_macro': 0.11855012851987817,\n",
       "    'f1_weighted': 0.37295564820644167,\n",
       "    'loss': 2.2830119339866815,\n",
       "    'train_loss': 1.2656534555547703},\n",
       "   {'accuracy': 0.4123235115049721,\n",
       "    'f1_macro': 0.12119070584083566,\n",
       "    'f1_weighted': 0.3753024356467661,\n",
       "    'loss': 2.2407282870465366,\n",
       "    'train_loss': 1.1099597479859287},\n",
       "   {'accuracy': 0.41314495008552626,\n",
       "    'f1_macro': 0.12281866673771749,\n",
       "    'f1_weighted': 0.3812077200118772,\n",
       "    'loss': 2.2428284583393614,\n",
       "    'train_loss': 1.0442943943267378},\n",
       "   {'accuracy': 0.42944808991370065,\n",
       "    'f1_macro': 0.12909713486592542,\n",
       "    'f1_weighted': 0.3964704196876914,\n",
       "    'loss': 2.1465967658078107,\n",
       "    'train_loss': 1.362749882185001},\n",
       "   {'accuracy': 0.43351662688326875,\n",
       "    'f1_macro': 0.13459715808962913,\n",
       "    'f1_weighted': 0.4011174342404929,\n",
       "    'loss': 2.131263421231267,\n",
       "    'train_loss': 1.2448289476453651},\n",
       "   {'accuracy': 0.4359712786416305,\n",
       "    'f1_macro': 0.13825705713513747,\n",
       "    'f1_weighted': 0.4068907897151775,\n",
       "    'loss': 2.1273515743748797,\n",
       "    'train_loss': 0.9622188206940505},\n",
       "   {'accuracy': 0.4337968823989872,\n",
       "    'f1_macro': 0.13622021432303158,\n",
       "    'f1_weighted': 0.4038800190215588,\n",
       "    'loss': 2.1828746016935168,\n",
       "    'train_loss': 0.9828209234185449},\n",
       "   {'accuracy': 0.43591329474182666,\n",
       "    'f1_macro': 0.139306534269425,\n",
       "    'f1_weighted': 0.40823363315788164,\n",
       "    'loss': 2.178611658288971,\n",
       "    'train_loss': 1.0445874699462505},\n",
       "   {'accuracy': 0.44203059617112983,\n",
       "    'f1_macro': 0.1466192730412015,\n",
       "    'f1_weighted': 0.4156826939047862,\n",
       "    'loss': 2.089913610189645,\n",
       "    'train_loss': 1.2262516162773536},\n",
       "   {'accuracy': 0.44032007112691707,\n",
       "    'f1_macro': 0.14675311954833953,\n",
       "    'f1_weighted': 0.4193281151296243,\n",
       "    'loss': 2.13777809941566,\n",
       "    'train_loss': 0.7617252530486065},\n",
       "   {'accuracy': 0.44262009915246864,\n",
       "    'f1_macro': 0.14762737962066008,\n",
       "    'f1_weighted': 0.41928540662764696,\n",
       "    'loss': 2.141120882615481,\n",
       "    'train_loss': 0.8128754696455889},\n",
       "   {'accuracy': 0.4463214047566126,\n",
       "    'f1_macro': 0.14735403858215337,\n",
       "    'f1_weighted': 0.4191224501012173,\n",
       "    'loss': 2.15290292541552,\n",
       "    'train_loss': 1.070865492221299},\n",
       "   {'accuracy': 0.4471911632536699,\n",
       "    'f1_macro': 0.1493984501187964,\n",
       "    'f1_weighted': 0.4205934034209793,\n",
       "    'loss': 2.14879615173771,\n",
       "    'train_loss': 0.9340538019726085},\n",
       "   {'accuracy': 0.4478966340346164,\n",
       "    'f1_macro': 0.1482197948550099,\n",
       "    'f1_weighted': 0.4199194408571894,\n",
       "    'loss': 2.140739427641899,\n",
       "    'train_loss': 0.7516418062847114},\n",
       "   {'accuracy': 0.45483537404447366,\n",
       "    'f1_macro': 0.1481822785324268,\n",
       "    'f1_weighted': 0.428086297418418,\n",
       "    'loss': 2.0669817313851,\n",
       "    'train_loss': 1.0843063225166578},\n",
       "   {'accuracy': 0.45371435198159976,\n",
       "    'f1_macro': 0.1535883038135325,\n",
       "    'f1_weighted': 0.4295179246006399,\n",
       "    'loss': 2.115803155393811,\n",
       "    'train_loss': 0.9441803329393581},\n",
       "   {'accuracy': 0.4515399557389565,\n",
       "    'f1_macro': 0.15387850466354014,\n",
       "    'f1_weighted': 0.42793583668138313,\n",
       "    'loss': 2.130763002063917,\n",
       "    'train_loss': 0.5060495214663489},\n",
       "   {'accuracy': 0.4529412333175488,\n",
       "    'f1_macro': 0.15328538173597697,\n",
       "    'f1_weighted': 0.4257811796140872,\n",
       "    'loss': 2.1684853997096387,\n",
       "    'train_loss': 0.659263032857502},\n",
       "   {'accuracy': 0.45443915072914753,\n",
       "    'f1_macro': 0.15197507194670884,\n",
       "    'f1_weighted': 0.42504594671425167,\n",
       "    'loss': 2.19026462406812,\n",
       "    'train_loss': 0.6960192945266808},\n",
       "   {'accuracy': 0.4544488147124482,\n",
       "    'f1_macro': 0.1526836478562835,\n",
       "    'f1_weighted': 0.43009185579815545,\n",
       "    'loss': 2.1380683044250577,\n",
       "    'train_loss': 0.8223927719336961},\n",
       "   {'accuracy': 0.4558790842409424,\n",
       "    'f1_macro': 0.15369055687249983,\n",
       "    'f1_weighted': 0.42986854567338717,\n",
       "    'loss': 2.129693690305914,\n",
       "    'train_loss': 0.7964605766497671},\n",
       "   {'accuracy': 0.4534630884157832,\n",
       "    'f1_macro': 0.1531708404870162,\n",
       "    'f1_weighted': 0.4266241536173104,\n",
       "    'loss': 2.1396559573151155,\n",
       "    'train_loss': 0.6547828210629476},\n",
       "   {'accuracy': 0.45580177237453734,\n",
       "    'f1_macro': 0.15464863412990432,\n",
       "    'f1_weighted': 0.4286059562901423,\n",
       "    'loss': 2.103071428362985,\n",
       "    'train_loss': 0.8033491881709466},\n",
       "   {'accuracy': 0.45337611256607746,\n",
       "    'f1_macro': 0.15337484885841254,\n",
       "    'f1_weighted': 0.42827307672542153,\n",
       "    'loss': 2.162212238064356,\n",
       "    'train_loss': 0.6272377759103321},\n",
       "   {'accuracy': 0.4616871382046252,\n",
       "    'f1_macro': 0.15653060893675297,\n",
       "    'f1_weighted': 0.4343603284348675,\n",
       "    'loss': 2.0674694721732654,\n",
       "    'train_loss': 0.9739511213731327},\n",
       "   {'accuracy': 0.46225731321936275,\n",
       "    'f1_macro': 0.15741600884430312,\n",
       "    'f1_weighted': 0.43499252643529407,\n",
       "    'loss': 2.0635331597924433,\n",
       "    'train_loss': 0.7551434591788537},\n",
       "   {'accuracy': 0.45843037583231055,\n",
       "    'f1_macro': 0.15874100469500377,\n",
       "    'f1_weighted': 0.43601406802721304,\n",
       "    'loss': 2.0807414418983288,\n",
       "    'train_loss': 0.5410530778857218},\n",
       "   {'accuracy': 0.46002493307691567,\n",
       "    'f1_macro': 0.15917487002275602,\n",
       "    'f1_weighted': 0.4383097421255592,\n",
       "    'loss': 2.058658797152453,\n",
       "    'train_loss': 0.6754014011741442},\n",
       "   {'accuracy': 0.4573673376692405,\n",
       "    'f1_macro': 0.15839060915509548,\n",
       "    'f1_weighted': 0.43818143065767157,\n",
       "    'loss': 2.0768038376720677,\n",
       "    'train_loss': 0.6674918064089891},\n",
       "   {'accuracy': 0.45905853474685193,\n",
       "    'f1_macro': 0.15884995179623407,\n",
       "    'f1_weighted': 0.4365437458279956,\n",
       "    'loss': 2.108417367696018,\n",
       "    'train_loss': 0.4988530343943098},\n",
       "   {'accuracy': 0.4633976632488379,\n",
       "    'f1_macro': 0.1571336903104294,\n",
       "    'f1_weighted': 0.4379339135191479,\n",
       "    'loss': 2.0612484076533293,\n",
       "    'train_loss': 0.9054836684745666},\n",
       "   {'accuracy': 0.4607787237743653,\n",
       "    'f1_macro': 0.15750377863425008,\n",
       "    'f1_weighted': 0.43763382100281323,\n",
       "    'loss': 2.0769493932445298,\n",
       "    'train_loss': 0.7087130848913263},\n",
       "   {'accuracy': 0.46684770528716524,\n",
       "    'f1_macro': 0.1557613154924246,\n",
       "    'f1_weighted': 0.4376280777249062,\n",
       "    'loss': 1.9936784408761994,\n",
       "    'train_loss': 1.045787456718061},\n",
       "   {'accuracy': 0.46631618620563026,\n",
       "    'f1_macro': 0.1583593558987021,\n",
       "    'f1_weighted': 0.4416838511541982,\n",
       "    'loss': 2.030619456884691,\n",
       "    'train_loss': 0.8713340908619278},\n",
       "   {'accuracy': 0.4666544256211525,\n",
       "    'f1_macro': 0.15684604209631056,\n",
       "    'f1_weighted': 0.440761809980914,\n",
       "    'loss': 2.0602079523576613,\n",
       "    'train_loss': 0.6965670819669862},\n",
       "   {'accuracy': 0.4636392628313538,\n",
       "    'f1_macro': 0.15669531654867408,\n",
       "    'f1_weighted': 0.43880575127229254,\n",
       "    'loss': 2.1167115428065086,\n",
       "    'train_loss': 0.5578499807704423},\n",
       "   {'accuracy': 0.46283715221740096,\n",
       "    'f1_macro': 0.16207358093847776,\n",
       "    'f1_weighted': 0.4419601071743389,\n",
       "    'loss': 2.0831326456001378,\n",
       "    'train_loss': 0.8250697174116421},\n",
       "   {'accuracy': 0.4653497878755666,\n",
       "    'f1_macro': 0.16120764598629847,\n",
       "    'f1_weighted': 0.44323623867224454,\n",
       "    'loss': 2.0798185060319576,\n",
       "    'train_loss': 0.7208205380868208},\n",
       "   {'accuracy': 0.4682489828657576,\n",
       "    'f1_macro': 0.16071536052829874,\n",
       "    'f1_weighted': 0.4428586825674871,\n",
       "    'loss': 2.0572231615942296,\n",
       "    'train_loss': 0.8669888931931119},\n",
       "   {'accuracy': 0.47104187403964165,\n",
       "    'f1_macro': 0.16498097821149285,\n",
       "    'f1_weighted': 0.44790596832075796,\n",
       "    'loss': 2.090086560617197,\n",
       "    'train_loss': 0.7869165001992651},\n",
       "   {'accuracy': 0.467466200218406,\n",
       "    'f1_macro': 0.16622855617859755,\n",
       "    'f1_weighted': 0.448016402302588,\n",
       "    'loss': 2.0758925753267308,\n",
       "    'train_loss': 0.6823221910756004}],\n",
       "  'hyperparams': {'C': 0.07,\n",
       "   'E': 5,\n",
       "   'K': 143,\n",
       "   'M': 0.01,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.8,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[0.1863215980362786,\n",
       "    0.221517825217198,\n",
       "    0.3240526880369551,\n",
       "    0.3576157020400669,\n",
       "    0.37507851986431767,\n",
       "    0.39494766953042704,\n",
       "    0.39746996917189326,\n",
       "    0.3966581945746398,\n",
       "    0.4112218174086995,\n",
       "    0.40492090029668426,\n",
       "    0.40868018980063203,\n",
       "    0.4125844390540893,\n",
       "    0.417010543405781,\n",
       "    0.42432617876436307,\n",
       "    0.42719638180465225,\n",
       "    0.42696444620543694,\n",
       "    0.4324825806701006,\n",
       "    0.4372855803705171,\n",
       "    0.4412864694569808,\n",
       "    0.43933434483025213,\n",
       "    0.4368120451887859,\n",
       "    0.4409482300414585,\n",
       "    0.45085381292461124,\n",
       "    0.4473167950365782,\n",
       "    0.44906597601399345,\n",
       "    0.4484378170994521,\n",
       "    0.4533954405326788,\n",
       "    0.4516462595552635,\n",
       "    0.45337611256607746,\n",
       "    0.45263198585192843,\n",
       "    0.4552026054098979,\n",
       "    0.4555408448254201,\n",
       "    0.46132957082250164,\n",
       "    0.4575606173352533,\n",
       "    0.4563622834059743,\n",
       "    0.4587589512645322,\n",
       "    0.4569711143539144,\n",
       "    0.46085603564077043,\n",
       "    0.4654657556751742,\n",
       "    0.4644220454787054,\n",
       "    0.4640451501299806,\n",
       "    0.4680846951496468,\n",
       "    0.46423842979599333,\n",
       "    0.4639871662301768,\n",
       "    0.46537877982546844,\n",
       "    0.4658619789905003,\n",
       "    0.46540777177537035,\n",
       "    0.46628719425572834,\n",
       "    0.4656880272910888,\n",
       "    0.4690317655131092],\n",
       "   [0.1882350667298047,\n",
       "    0.22673637619954193,\n",
       "    0.30050156073330303,\n",
       "    0.3338229751538989,\n",
       "    0.3583598287542159,\n",
       "    0.3600993457483305,\n",
       "    0.370120896431091,\n",
       "    0.391062748243571,\n",
       "    0.39961537346463466,\n",
       "    0.41196594412284854,\n",
       "    0.4123235115049721,\n",
       "    0.41314495008552626,\n",
       "    0.42944808991370065,\n",
       "    0.43351662688326875,\n",
       "    0.4359712786416305,\n",
       "    0.4337968823989872,\n",
       "    0.43591329474182666,\n",
       "    0.44203059617112983,\n",
       "    0.44032007112691707,\n",
       "    0.44262009915246864,\n",
       "    0.4463214047566126,\n",
       "    0.4471911632536699,\n",
       "    0.4478966340346164,\n",
       "    0.45483537404447366,\n",
       "    0.45371435198159976,\n",
       "    0.4515399557389565,\n",
       "    0.4529412333175488,\n",
       "    0.45443915072914753,\n",
       "    0.4544488147124482,\n",
       "    0.4558790842409424,\n",
       "    0.4534630884157832,\n",
       "    0.45580177237453734,\n",
       "    0.45337611256607746,\n",
       "    0.4616871382046252,\n",
       "    0.46225731321936275,\n",
       "    0.45843037583231055,\n",
       "    0.46002493307691567,\n",
       "    0.4573673376692405,\n",
       "    0.45905853474685193,\n",
       "    0.4633976632488379,\n",
       "    0.4607787237743653,\n",
       "    0.46684770528716524,\n",
       "    0.46631618620563026,\n",
       "    0.4666544256211525,\n",
       "    0.4636392628313538,\n",
       "    0.46283715221740096,\n",
       "    0.4653497878755666,\n",
       "    0.4682489828657576,\n",
       "    0.47104187403964165,\n",
       "    0.467466200218406]],\n",
       "  'test_loss': [[3.176174099380345,\n",
       "    2.905674707120342,\n",
       "    2.461735315927557,\n",
       "    2.3178169422116386,\n",
       "    2.279595675201126,\n",
       "    2.2079627428058775,\n",
       "    2.2596715702575967,\n",
       "    2.2707073138939546,\n",
       "    2.243885017793145,\n",
       "    2.3416455565776557,\n",
       "    2.2538947709911263,\n",
       "    2.285044482250439,\n",
       "    2.234873898465235,\n",
       "    2.118977435260004,\n",
       "    2.1811251331654664,\n",
       "    2.2252845048111816,\n",
       "    2.189519155330426,\n",
       "    2.0576590251796807,\n",
       "    2.1085229804700925,\n",
       "    2.16774879208367,\n",
       "    2.1919359145134583,\n",
       "    2.17317819050078,\n",
       "    2.0757494495491877,\n",
       "    2.0832444676693758,\n",
       "    2.1561874673597807,\n",
       "    2.1487857889313218,\n",
       "    2.0796102760001163,\n",
       "    2.076225702554569,\n",
       "    2.0951452347941886,\n",
       "    2.136838705272408,\n",
       "    2.123729276199976,\n",
       "    2.163374751986265,\n",
       "    2.0467710339619942,\n",
       "    2.104841444532592,\n",
       "    2.1106655206224736,\n",
       "    2.092375966179987,\n",
       "    2.1471711600136825,\n",
       "    2.1033734131561195,\n",
       "    2.0241886804325433,\n",
       "    2.043893933048516,\n",
       "    2.068797358171479,\n",
       "    2.081312629639626,\n",
       "    2.0961777624284457,\n",
       "    2.1141022268512035,\n",
       "    2.0530810961973134,\n",
       "    2.0761995482067124,\n",
       "    2.096645995359497,\n",
       "    2.1065236058174754,\n",
       "    2.0292236450941314,\n",
       "    2.0183343164840877],\n",
       "   [3.1030948995162593,\n",
       "    2.8292785049163354,\n",
       "    2.5873728958585795,\n",
       "    2.489639851712807,\n",
       "    2.430910937870915,\n",
       "    2.427248329267774,\n",
       "    2.3537743078426994,\n",
       "    2.183273864729947,\n",
       "    2.253861902877047,\n",
       "    2.2830119339866815,\n",
       "    2.2407282870465366,\n",
       "    2.2428284583393614,\n",
       "    2.1465967658078107,\n",
       "    2.131263421231267,\n",
       "    2.1273515743748797,\n",
       "    2.1828746016935168,\n",
       "    2.178611658288971,\n",
       "    2.089913610189645,\n",
       "    2.13777809941566,\n",
       "    2.141120882615481,\n",
       "    2.15290292541552,\n",
       "    2.14879615173771,\n",
       "    2.140739427641899,\n",
       "    2.0669817313851,\n",
       "    2.115803155393811,\n",
       "    2.130763002063917,\n",
       "    2.1684853997096387,\n",
       "    2.19026462406812,\n",
       "    2.1380683044250577,\n",
       "    2.129693690305914,\n",
       "    2.1396559573151155,\n",
       "    2.103071428362985,\n",
       "    2.162212238064356,\n",
       "    2.0674694721732654,\n",
       "    2.0635331597924433,\n",
       "    2.0807414418983288,\n",
       "    2.058658797152453,\n",
       "    2.0768038376720677,\n",
       "    2.108417367696018,\n",
       "    2.0612484076533293,\n",
       "    2.0769493932445298,\n",
       "    1.9936784408761994,\n",
       "    2.030619456884691,\n",
       "    2.0602079523576613,\n",
       "    2.1167115428065086,\n",
       "    2.0831326456001378,\n",
       "    2.0798185060319576,\n",
       "    2.0572231615942296,\n",
       "    2.090086560617197,\n",
       "    2.0758925753267308]],\n",
       "  'train_loss': [[3.1360296887995966,\n",
       "    2.746494262782075,\n",
       "    2.412644198180246,\n",
       "    2.065011260368259,\n",
       "    1.7716001382129913,\n",
       "    1.7812241947601328,\n",
       "    1.3616364250220037,\n",
       "    1.3744047969292048,\n",
       "    1.264674345773925,\n",
       "    1.0228054202991523,\n",
       "    1.300845729761781,\n",
       "    1.0176392017380154,\n",
       "    1.0637272558520015,\n",
       "    1.2507408060199574,\n",
       "    1.0076115141803483,\n",
       "    0.9856574223772917,\n",
       "    1.020391129901339,\n",
       "    1.1678164956630162,\n",
       "    0.8531376515655262,\n",
       "    0.8195945891575654,\n",
       "    0.6839735431929322,\n",
       "    0.8484673402585354,\n",
       "    1.275182525051505,\n",
       "    1.0175961574556691,\n",
       "    0.9327839408893634,\n",
       "    0.866092444110165,\n",
       "    0.9631994454868791,\n",
       "    0.8477117711860854,\n",
       "    0.8555428731397601,\n",
       "    0.6937316619769579,\n",
       "    0.7149529661437034,\n",
       "    0.7208001868557055,\n",
       "    0.978962137082956,\n",
       "    0.5671294462483747,\n",
       "    0.5345021060508853,\n",
       "    0.8309025888693101,\n",
       "    0.5523381473155943,\n",
       "    0.8801917592911177,\n",
       "    1.0804567033436445,\n",
       "    0.8545747615146508,\n",
       "    0.8049424136444442,\n",
       "    0.905200197361534,\n",
       "    0.575625081932435,\n",
       "    0.5740591980033772,\n",
       "    0.8260059080379186,\n",
       "    0.5194685907017389,\n",
       "    0.7386849092995248,\n",
       "    0.7211278866192454,\n",
       "    0.8732231162102705,\n",
       "    1.0713149255440562],\n",
       "   [3.0407416653811556,\n",
       "    2.6628495481971375,\n",
       "    2.4107734065991537,\n",
       "    2.0816250941038574,\n",
       "    1.8531370002262872,\n",
       "    1.490720051141887,\n",
       "    1.564870000968117,\n",
       "    1.5450653990984475,\n",
       "    1.4046218464151548,\n",
       "    1.2656534555547703,\n",
       "    1.1099597479859287,\n",
       "    1.0442943943267378,\n",
       "    1.362749882185001,\n",
       "    1.2448289476453651,\n",
       "    0.9622188206940505,\n",
       "    0.9828209234185449,\n",
       "    1.0445874699462505,\n",
       "    1.2262516162773536,\n",
       "    0.7617252530486065,\n",
       "    0.8128754696455889,\n",
       "    1.070865492221299,\n",
       "    0.9340538019726085,\n",
       "    0.7516418062847114,\n",
       "    1.0843063225166578,\n",
       "    0.9441803329393581,\n",
       "    0.5060495214663489,\n",
       "    0.659263032857502,\n",
       "    0.6960192945266808,\n",
       "    0.8223927719336961,\n",
       "    0.7964605766497671,\n",
       "    0.6547828210629476,\n",
       "    0.8033491881709466,\n",
       "    0.6272377759103321,\n",
       "    0.9739511213731327,\n",
       "    0.7551434591788537,\n",
       "    0.5410530778857218,\n",
       "    0.6754014011741442,\n",
       "    0.6674918064089891,\n",
       "    0.4988530343943098,\n",
       "    0.9054836684745666,\n",
       "    0.7087130848913263,\n",
       "    1.045787456718061,\n",
       "    0.8713340908619278,\n",
       "    0.6965670819669862,\n",
       "    0.5578499807704423,\n",
       "    0.8250697174116421,\n",
       "    0.7208205380868208,\n",
       "    0.8669888931931119,\n",
       "    0.7869165001992651,\n",
       "    0.6823221910756004]]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "aSs9xXfpQ3ML"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(path + 'Local_Round_FedMed_5.pkl', 'rb') as file:\n",
    "  log_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "N8ep-MalQ3PO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48704162153798547, 0.49089045334983755]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['Shakespeare LSTM on IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_-2I2g0HQ3WA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4690317655131092, 0.467466200218406]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['Shakespeare LSTM on Non IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfR3lDa7Q-8s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "FederatedAveraging",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "QSGD",
   "language": "python",
   "name": "qsgd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
