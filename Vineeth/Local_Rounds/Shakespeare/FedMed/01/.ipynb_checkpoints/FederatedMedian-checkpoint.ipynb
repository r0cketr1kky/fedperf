{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tushar-semwal/fedperf/blob/main/Vineeth/Local_Rounds/Shakesphere/FedMed/FederatedMedian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WQ6Rq0UiG6ev"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummaryX in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (1.3.0)\r\n",
      "Requirement already satisfied: unidecode in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (1.2.0)\r\n",
      "Requirement already satisfied: pandas in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (0.24.2)\r\n",
      "Requirement already satisfied: numpy in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (1.19.1)\r\n",
      "Requirement already satisfied: torch in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (1.7.1+cu101)\r\n",
      "Requirement already satisfied: pytz>=2011k in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from pandas->torchsummaryX) (2021.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from pandas->torchsummaryX) (2.8.1)\r\n",
      "Requirement already satisfied: typing-extensions in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torch->torchsummaryX) (3.7.4.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas->torchsummaryX) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummaryX unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yKcpjZLrQQJV"
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    import os\n",
    "    path = '/content/drive/MyDrive/Colab Notebooks/OpenMined/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "except:\n",
    "    path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0_nKpfq2h1R"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DLLNM9X2JbQ8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 26 11:56:22 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 28%   51C    P2   106W / 250W |   1540MiB / 11178MiB |     53%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 23%   27C    P8     9W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     71868      C   ...3/envs/QSGD-PT/bin/python      781MiB |\n",
      "|    0   N/A  N/A     71906      C   ...3/envs/QSGD-PT/bin/python      757MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import copy\n",
    "from functools import reduce\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchsummaryX import summary as summaryx\n",
    "from torchvision import transforms, utils, datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Check assigned GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "# set manual seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# general reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# gpu training specific\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY4eWzGiL6Mj"
   },
   "source": [
    "## Load the Shakespeare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hf03LRxof7Zj"
   },
   "outputs": [],
   "source": [
    "!rm -Rf data\n",
    "!mkdir -p data scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ngygA4-Fgobx"
   },
   "outputs": [],
   "source": [
    "GENERATE_DATASET = False  # If False, download the dataset provided by the q-FFL paper\n",
    "DATA_DIR = 'data/'\n",
    "# Dataset generation params\n",
    "SAMPLES_FRACTION = 1.  # If using an already generated dataset\n",
    "# SAMPLES_FRACTION = 0.2  # Fraction of total samples in the dataset - FedProx default script\n",
    "# SAMPLES_FRACTION = 0.05  # Fraction of total samples in the dataset - qFFL\n",
    "TRAIN_FRACTION = 0.8  # Train set size\n",
    "MIN_SAMPLES = 0  # Min samples per client (for filtering purposes) - FedProx\n",
    "# MIN_SAMPLES = 64  # Min samples per client (for filtering purposes) - qFFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nUmwJgJygoYD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-26 11:56:23--  http://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5757108 (5.5M) [text/plain]\n",
      "Saving to: ‘data/shakespeare.txt’\n",
      "\n",
      "data/shakespeare.tx 100%[===================>]   5.49M  1.14MB/s    in 5.7s    \n",
      "\n",
      "2021-04-26 11:56:29 (981 KB/s) - ‘data/shakespeare.txt’ saved [5757108/5757108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download raw dataset\n",
    "# !wget https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt -O data/shakespeare.txt\n",
    "!wget --adjust-extension http://www.gutenberg.org/files/100/100-0.txt -O data/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4dCvx80BgoVr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1n46Mftp3_ahRi1Z6jYhEriyLtdRDS1tD\n",
      "To: /home/vineeth/code/OM/Vineeth/Local_Rounds/Shakespeare/FedMed/01/shakespeare.zip\n",
      "2.96MB [00:00, 9.32MB/s]\n",
      "Archive:  shakespeare.zip\n",
      "   creating: shakespeare_paper/\n",
      "   creating: shakespeare_paper/test/\n",
      "  inflating: shakespeare_paper/test/all_data_niid_2_keep_0_test_8.json  \n",
      "   creating: shakespeare_paper/train/\n",
      "  inflating: shakespeare_paper/train/all_data_niid_2_keep_0_train_8.json  \n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_DATASET:\n",
    "    !rm -Rf data/train data/test\n",
    "    !gdown --id 1n46Mftp3_ahRi1Z6jYhEriyLtdRDS1tD  # Download Shakespeare dataset used by the FedProx paper\n",
    "    !unzip shakespeare.zip\n",
    "    !mv -f shakespeare_paper/train data/\n",
    "    !mv -f shakespeare_paper/test data/\n",
    "    !rm -R shakespeare_paper/ shakespeare.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a4pzFvPvhQhq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Length: 90\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "with open('data/shakespeare.txt', 'r') as f:\n",
    "    data = list(unidecode(f.read()))\n",
    "    corpus = list(set(list(data)))\n",
    "print('Corpus Length:', len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cce_-qnxhD4n"
   },
   "source": [
    "#### Dataset Preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Rt13M4IcgoTV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if GENERATE_DATASET:\n",
    "    # Download dataset generation scripts\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/preprocess_shakespeare.py -O scripts/preprocess_shakespeare.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/shake_utils.py -O scripts/shake_utils.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/gen_all_data.py -O scripts/gen_all_data.py\n",
    "\n",
    "    # Download data preprocessing scripts\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/utils/sample.py -O scripts/sample.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/utils/remove_users.py -O scripts/remove_users.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EIEyRW27goPo"
   },
   "outputs": [],
   "source": [
    "# Running scripts\n",
    "if GENERATE_DATASET:\n",
    "    !mkdir -p data/raw_data data/all_data data/train data/test\n",
    "    !python scripts/preprocess_shakespeare.py data/shakespeare.txt data/raw_data\n",
    "    !python scripts/gen_all_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mq8V6v_4hhhD"
   },
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "H2SjEBKoWDxv"
   },
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, x, y, corpus, seq_length):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.corpus = corpus\n",
    "        self.corpus_size = len(self.corpus)\n",
    "        super(ShakespeareDataset, self).__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__} - (length: {self.__len__()})'\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        input_seq = self.x[i]\n",
    "        next_char = self.y[i]\n",
    "        # print('\\tgetitem', i, input_seq, next_char)\n",
    "        input_value = self.text2charindxs(input_seq).long()\n",
    "        target_value = self.get_label_from_char(next_char)\n",
    "        return input_value, target_value\n",
    "\n",
    "    def text2charindxs(self, text):\n",
    "        tensor = torch.zeros(len(text), dtype=torch.int32)\n",
    "        for i, c in enumerate(text):\n",
    "            tensor[i] = self.get_label_from_char(c)\n",
    "        return tensor\n",
    "\n",
    "    def get_label_from_char(self, c):\n",
    "        return self.corpus.index(c)\n",
    "\n",
    "    def get_char_from_label(self, l):\n",
    "        return self.corpus[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fgJtS62lYAN"
   },
   "source": [
    "##### Federated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5DqL5pTmgn5X"
   },
   "outputs": [],
   "source": [
    "class ShakespeareFedDataset(ShakespeareDataset):\n",
    "    def __init__(self, x, y, corpus, seq_length):\n",
    "        super(ShakespeareFedDataset, self).__init__(x, y, corpus, seq_length)\n",
    "\n",
    "    def dataloader(self, batch_size, shuffle=True):\n",
    "        return DataLoader(self,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XelbyPsDlfgb"
   },
   "source": [
    "## Partitioning & Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOBblyFGlwlU"
   },
   "source": [
    "### IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cSZFWKmsgn1p"
   },
   "outputs": [],
   "source": [
    "def iid_partition_(dataset, clients):\n",
    "  \"\"\"\n",
    "  I.I.D paritioning of data over clients\n",
    "  Shuffle the data\n",
    "  Split it between clients\n",
    "  \n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "\n",
    "  num_items_per_client = int(len(dataset)/clients)\n",
    "  client_dict = {}\n",
    "  image_idxs = [i for i in range(len(dataset))]\n",
    "\n",
    "  for i in range(clients):\n",
    "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
    "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
    "\n",
    "  return client_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-lGwDyhSll9h"
   },
   "outputs": [],
   "source": [
    "def iid_partition(corpus, seq_length=80, val_split=False):\n",
    "\n",
    "    train_file = [os.path.join(DATA_DIR, 'train', f) for f in os.listdir(f'{DATA_DIR}/train') if f.endswith('.json')][0]\n",
    "    test_file = [os.path.join(DATA_DIR, 'test', f) for f in os.listdir(f'{DATA_DIR}/test') if f.endswith('.json')][0]\n",
    "\n",
    "    with open(train_file, 'r') as file:\n",
    "        data_train = json.loads(unidecode(file.read()))\n",
    "\n",
    "    with open(test_file, 'r') as file:\n",
    "        data_test = json.loads(unidecode(file.read()))\n",
    "\n",
    "    \n",
    "    total_samples_train = sum(data_train['num_samples'])\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_test, y_test = [], []\n",
    "    # x_val, y_val = [], []\n",
    "\n",
    "    users = list(zip(data_train['users'], data_train['num_samples']))\n",
    "    # random.shuffle(users)\n",
    "\n",
    "\n",
    "\n",
    "    total_samples = int(sum(data_train['num_samples']) * SAMPLES_FRACTION)\n",
    "    print('Objective', total_samples, '/', sum(data_train['num_samples']))\n",
    "    sample_count = 0\n",
    "    \n",
    "    for i, (author_id, samples) in enumerate(users):\n",
    "\n",
    "        if sample_count >= total_samples:\n",
    "            print('Max samples reached', sample_count, '/', total_samples)\n",
    "            break\n",
    "\n",
    "        if samples < MIN_SAMPLES: # or data_train['num_samples'][i] > 10000:\n",
    "            print('SKIP', author_id, samples)\n",
    "            continue\n",
    "        else:\n",
    "            udata_train = data_train['user_data'][author_id]\n",
    "            max_samples = samples if (sample_count + samples) <= total_samples else (sample_count + samples - total_samples) \n",
    "            \n",
    "            sample_count += max_samples\n",
    "            # print('sample_count', sample_count)\n",
    "\n",
    "            x_train.extend(data_train['user_data'][author_id]['x'][:max_samples])\n",
    "            y_train.extend(data_train['user_data'][author_id]['y'][:max_samples])\n",
    "\n",
    "            author_data = data_test['user_data'][author_id]\n",
    "            test_size = int(len(author_data['x']) * SAMPLES_FRACTION)\n",
    "\n",
    "            if val_split:\n",
    "                x_test.extend(author_data['x'][:int(test_size / 2)])\n",
    "                y_test.extend(author_data['y'][:int(test_size / 2)])\n",
    "                # x_val.extend(author_data['x'][int(test_size / 2):])\n",
    "                # y_val.extend(author_data['y'][int(test_size / 2):int(test_size)])\n",
    "\n",
    "            else:\n",
    "                x_test.extend(author_data['x'][:int(test_size)])\n",
    "                y_test.extend(author_data['y'][:int(test_size)])\n",
    "\n",
    "    train_ds = ShakespeareDataset(x_train, y_train, corpus, seq_length)\n",
    "    test_ds = ShakespeareDataset(x_test, y_test, corpus, seq_length)\n",
    "    # val_ds = ShakespeareDataset(x_val, y_val, corpus, seq_length)\n",
    "\n",
    "    data_dict = iid_partition_(train_ds, clients=len(users))\n",
    "\n",
    "    return train_ds, data_dict, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFvc8mLoouKa"
   },
   "source": [
    "### Non-IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GZ76WsCZot9s"
   },
   "outputs": [],
   "source": [
    "def noniid_partition(corpus, seq_length=80, val_split=False):\n",
    "\n",
    "    train_file = [os.path.join(DATA_DIR, 'train', f) for f in os.listdir(f'{DATA_DIR}/train') if f.endswith('.json')][0]\n",
    "    test_file = [os.path.join(DATA_DIR, 'test', f) for f in os.listdir(f'{DATA_DIR}/test') if f.endswith('.json')][0]\n",
    "\n",
    "    with open(train_file, 'r') as file:\n",
    "        data_train = json.loads(unidecode(file.read()))\n",
    "\n",
    "    with open(test_file, 'r') as file:\n",
    "        data_test = json.loads(unidecode(file.read()))\n",
    "\n",
    "    \n",
    "    total_samples_train = sum(data_train['num_samples'])\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    x_test, y_test = [], []\n",
    "\n",
    "    users = list(zip(data_train['users'], data_train['num_samples']))\n",
    "    # random.shuffle(users)\n",
    "\n",
    "    total_samples = int(sum(data_train['num_samples']) * SAMPLES_FRACTION)\n",
    "    print('Objective', total_samples, '/', sum(data_train['num_samples']))\n",
    "    sample_count = 0\n",
    "    \n",
    "    for i, (author_id, samples) in enumerate(users):\n",
    "\n",
    "        if sample_count >= total_samples:\n",
    "            print('Max samples reached', sample_count, '/', total_samples)\n",
    "            break\n",
    "\n",
    "        if samples < MIN_SAMPLES: # or data_train['num_samples'][i] > 10000:\n",
    "            print('SKIP', author_id, samples)\n",
    "            continue\n",
    "        else:\n",
    "            udata_train = data_train['user_data'][author_id]\n",
    "            max_samples = samples if (sample_count + samples) <= total_samples else (sample_count + samples - total_samples) \n",
    "            \n",
    "            sample_count += max_samples\n",
    "            # print('sample_count', sample_count)\n",
    "\n",
    "            x_train = data_train['user_data'][author_id]['x'][:max_samples]\n",
    "            y_train = data_train['user_data'][author_id]['y'][:max_samples]\n",
    "\n",
    "            train_ds = ShakespeareFedDataset(x_train, y_train, corpus, seq_length)\n",
    "\n",
    "            x_val, y_val = None, None\n",
    "            val_ds = None\n",
    "            author_data = data_test['user_data'][author_id]\n",
    "            test_size = int(len(author_data['x']) * SAMPLES_FRACTION)\n",
    "            if val_split:\n",
    "                x_test += author_data['x'][:int(test_size / 2)]\n",
    "                y_test += author_data['y'][:int(test_size / 2)]\n",
    "                x_val = author_data['x'][int(test_size / 2):]\n",
    "                y_val = author_data['y'][int(test_size / 2):int(test_size)]\n",
    "\n",
    "                val_ds = ShakespeareFedDataset(x_val, y_val, corpus, seq_length)\n",
    "\n",
    "            else:\n",
    "                x_test += author_data['x'][:int(test_size)]\n",
    "                y_test += author_data['y'][:int(test_size)]\n",
    "\n",
    "            data_dict[author_id] = {\n",
    "                'train_ds': train_ds,\n",
    "                'val_ds': val_ds\n",
    "            }\n",
    "\n",
    "    test_ds = ShakespeareFedDataset(x_test, y_test, corpus, seq_length)\n",
    "\n",
    "    return data_dict, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWVOxcAao2_t"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQQQ2mLeo6EA"
   },
   "source": [
    "### Shakespeare LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2mGXTrXRot7R"
   },
   "outputs": [],
   "source": [
    "class ShakespeareLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, classes, lstm_layers=2, dropout=0.1, batch_first=True):\n",
    "        super(ShakespeareLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.classes = classes\n",
    "        self.no_layers = lstm_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=self.classes,\n",
    "                                      embedding_dim=self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim,\n",
    "                            num_layers=self.no_layers,\n",
    "                            batch_first=batch_first, \n",
    "                            dropout=dropout if self.no_layers > 1 else 0.)\n",
    "        self.fc = nn.Linear(hidden_dim, self.classes)\n",
    "\n",
    "    def forward(self, x, hc=None):\n",
    "        batch_size = x.size(0)\n",
    "        x_emb = self.embedding(x)\n",
    "        self.lstm.flatten_parameters()\n",
    "        out, (ht, ct) = self.lstm(x_emb.view(batch_size, -1, self.embedding_dim), hc)\n",
    "        dense = self.fc(ht[-1])\n",
    "        return dense\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (Variable(torch.zeros(self.no_layers, batch_size, self.hidden_dim)),\n",
    "                Variable(torch.zeros(self.no_layers, batch_size, self.hidden_dim)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QsuJlVipMc8"
   },
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "n_Vb0BYpot5I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shakespeare LSTM SUMMARY\n",
      "==========================================================\n",
      "            Kernel Shape   Output Shape  Params  Mult-Adds\n",
      "Layer                                                     \n",
      "0_embedding      [8, 90]    [10, 80, 8]     720        720\n",
      "1_lstm                 -  [10, 80, 256]  798720     794624\n",
      "2_fc           [256, 90]       [10, 90]   23130      23040\n",
      "----------------------------------------------------------\n",
      "                      Totals\n",
      "Total params          822570\n",
      "Trainable params      822570\n",
      "Non-trainable params       0\n",
      "Mult-Adds             818384\n",
      "==========================================================\n",
      "            Kernel Shape   Output Shape  Params  Mult-Adds\n",
      "Layer                                                     \n",
      "0_embedding      [8, 90]    [10, 80, 8]     720        720\n",
      "1_lstm                 -  [10, 80, 256]  798720     794624\n",
      "2_fc           [256, 90]       [10, 90]   23130      23040\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "seq_length = 80 # mcmahan17a, fedprox, qFFL\n",
    "\n",
    "shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,  \n",
    "                                   embedding_dim=8,  # mcmahan17a, fedprox, qFFL\n",
    "                                   hidden_dim=256,  # mcmahan17a, fedprox impl\n",
    "                                   # hidden_dim=100,  # fedprox paper\n",
    "                                   classes=len(corpus),\n",
    "                                   lstm_layers=2,\n",
    "                                   dropout=0.1,\n",
    "                                   batch_first=True\n",
    "                                   )\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  shakespeare_lstm.cuda()\n",
    "\n",
    "hc = shakespeare_lstm.init_hidden(batch_size)\n",
    "\n",
    "x_sample = torch.zeros((batch_size, seq_length),\n",
    "                       dtype=torch.long,\n",
    "                       device=(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')))\n",
    "\n",
    "x_sample[0][0] = 1\n",
    "x_sample\n",
    "\n",
    "print(\"\\nShakespeare LSTM SUMMARY\")\n",
    "print(summaryx(shakespeare_lstm, x_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn7egnzTpeks"
   },
   "source": [
    "## FedMed Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFFAfTOwpk4j"
   },
   "source": [
    "### Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oyYjWa6IpnTY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "367THsiTpo-C"
   },
   "outputs": [],
   "source": [
    "def plot_scores(history, exp_id, title, suffix):\n",
    "    accuracies = [x['accuracy'] for x in history]\n",
    "    f1_macro = [x['f1_macro'] for x in history]\n",
    "    f1_weighted = [x['f1_weighted'] for x in history]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(accuracies, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test Accuracy', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_Accuracy_{suffix}.jpg', format='jpg', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(f1_macro, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test F1 (macro)', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_F1_Macro_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(f1_weighted, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test F1 (weighted)', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_F1_Weighted_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_losses(history, exp_id, title, suffix):\n",
    "    val_losses = [x['loss'] for x in history]\n",
    "    train_losses = [x['train_loss'] for x in history]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_losses, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Train Loss', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Train_Loss_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(val_losses, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test Loss', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_Loss_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ9PZM0Gp9ve"
   },
   "source": [
    "### Local Training (Client Update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "EDJFltwdotzZ"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, dataset, idxs):\n",
    "      self.dataset = dataset\n",
    "      self.idxs = list(idxs)\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.idxs)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "      data, label = self.dataset[self.idxs[item]]\n",
    "      return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HtRzU5Yepddq"
   },
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "  def __init__(self, dataset, batchSize, learning_rate, epochs, idxs):\n",
    "    # self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batchSize, shuffle=True)\n",
    "    if hasattr(dataset, 'dataloader'):\n",
    "        self.train_loader = dataset.dataloader(batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epochs = epochs\n",
    "\n",
    "  def train(self, model):\n",
    "    # print(\"Client training for {} epochs.\".format(self.epochs))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.5)\n",
    "\n",
    "    # use the weights of global model for proximal term calculation\n",
    "    global_model = copy.deepcopy(model)\n",
    "\n",
    "    # calculate local training time\n",
    "    start_time = time.time()\n",
    "\n",
    "    e_loss = []\n",
    "    for epoch in range(1, self.epochs+1):\n",
    "\n",
    "      train_loss = 0.0\n",
    "      model.train()\n",
    "      for data, labels in self.train_loader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "          data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # make a forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        # do a backwards pass\n",
    "        loss.backward()\n",
    "        # perform a single optimization step\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "      # average losses\n",
    "      train_loss = train_loss/len(self.train_loader.dataset)\n",
    "      e_loss.append(train_loss)\n",
    "\n",
    "    total_loss = sum(e_loss)/len(e_loss)\n",
    "\n",
    "    return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3crFDN0xqGu6"
   },
   "source": [
    "### Server Side Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "c085xSOoqEHk"
   },
   "outputs": [],
   "source": [
    "def training(model, rounds, batch_size, lr, ds, data_dict, test_ds, C, K, E, M, plt_title, plt_color, classes, eval_every=1, tb_logger=None):\n",
    "  \"\"\"\n",
    "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
    "  Specifically, this function is used for the server side training and weight update\n",
    "\n",
    "  Params:\n",
    "    - model:           PyTorch model to train\n",
    "    - rounds:          Number of communication rounds for the client update\n",
    "    - batch_size:      Batch size for client update training\n",
    "    - lr:              Learning rate used for client update training\n",
    "    - ds:              Dataset used for training\n",
    "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
    "    - test_data_dict:  Data used for testing the model\n",
    "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
    "    - K:               Total number of clients\n",
    "    - E:               Number of training passes each client makes over its local dataset per round\n",
    "    - mu:              proximal term constant\n",
    "    - percentage:      percentage of selected client to have fewer than E epochs\n",
    "  Returns:\n",
    "    - model:           Trained model on the server\n",
    "  \"\"\"\n",
    "\n",
    "  # global model weights\n",
    "  global_weights = model.state_dict()\n",
    "\n",
    "  # training loss\n",
    "  train_loss = []\n",
    "\n",
    "  # test accuracy\n",
    "  test_accuracy = []\n",
    "\n",
    "  # test loss\n",
    "  test_loss = []\n",
    "\n",
    "  # history\n",
    "  history=[]\n",
    "\n",
    "  # store last loss for convergence\n",
    "  last_loss = 0.0\n",
    "\n",
    "  # total time taken \n",
    "  total_time = 0\n",
    "  start = time.time()\n",
    "\n",
    "\n",
    "  users_id = list(data_dict.keys())\n",
    "\n",
    "  for curr_round in range(1, rounds+1):\n",
    "    w, local_loss = [], []\n",
    "\n",
    "    m = max(int(C*K), 1)\n",
    "    newM = max(int(M*m), 1)\n",
    "\n",
    "    c = 0\n",
    "    S_t = np.random.choice(range(K), m, replace=False)\n",
    "    print('Clients: {}/{} -> {}'.format(len(S_t), K, S_t))\n",
    "\n",
    "    # for i in tqdm(range(len(S_t))):\n",
    "    for i in range(len(S_t)):\n",
    "      if c == newM:\n",
    "        break\n",
    "      c += 1\n",
    "\n",
    "      k = S_t[i]\n",
    "      key = users_id[k]\n",
    "      ds_ = ds if ds else data_dict[key]['train_ds']\n",
    "      idxs = data_dict[key] if ds else None\n",
    "      # print(f'Client {k}: {len(idxs) if idxs else len(ds_)} samples')\n",
    "      local_update = ClientUpdate(dataset=ds_, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=idxs)\n",
    "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
    "\n",
    "      for k in weights.keys():\n",
    "        t = torch.Tensor(weights[k].shape).cuda()\n",
    "        t.fill_(0.1)\n",
    "        weights[k] = t\n",
    "\n",
    "      w.append(copy.deepcopy(weights))\n",
    "      local_loss.append(copy.deepcopy(loss))\n",
    "\n",
    "    for i in tqdm(range(newM, len(S_t))):\n",
    "      k = S_t[i]\n",
    "      key = users_id[k]\n",
    "      ds_ = ds if ds else data_dict[key]['train_ds']\n",
    "      idxs = data_dict[key] if ds else None\n",
    "      # print(f'Client {k}: {len(idxs) if idxs else len(ds_)} samples')\n",
    "      local_update = ClientUpdate(dataset=ds_, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=idxs)\n",
    "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
    "      \n",
    "      w.append(copy.deepcopy(weights))\n",
    "      local_loss.append(copy.deepcopy(loss))\n",
    "      \n",
    "    # calculate time to update the global weights\n",
    "    global_start_time = time.time()\n",
    "\n",
    "    # updating the global weights\n",
    "    target = copy.deepcopy(w[0]);\n",
    "    weights_med = copy.deepcopy(w[0]);\n",
    "    for k in weights_med.keys():\n",
    "      tmp = copy.deepcopy(torch.median(torch.stack([w[i][k].data for i in range(0, len(w))]), dim=0))[0]\n",
    "      target[k].data = tmp\n",
    "\n",
    "    global_weights = target\n",
    "    global_end_time = time.time()\n",
    "\n",
    "    # move the updated weights to our model state dict\n",
    "    model.load_state_dict(global_weights)\n",
    "\n",
    "    # loss\n",
    "    loss_avg = sum(local_loss) / len(local_loss)\n",
    "    print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)))\n",
    "    train_loss.append(loss_avg)\n",
    "    if tb_logger:\n",
    "        tb_logger.add_scalar(f'Train/Loss', loss_avg, curr_round)\n",
    "\n",
    "    # testing\n",
    "    # if curr_round % eval_every == 0:\n",
    "    test_scores = testing(model, test_ds, batch_size * 2, nn.CrossEntropyLoss(), len(classes), classes)\n",
    "    test_scores['train_loss'] = loss_avg\n",
    "    test_loss_current, test_accuracy_current = test_scores['loss'], test_scores['accuracy']\n",
    "\n",
    "    history.append(test_scores)\n",
    "    test_accuracy.append(test_accuracy_current)\n",
    "    test_loss.append(test_loss_current)\n",
    "    \n",
    "    # print('Round: {}... \\tAverage Loss: {} \\tTest Loss: {} \\tTest Acc: {}'.format(curr_round, round(loss_avg, 3), round(test_loss, 3), round(test_accuracy, 3)))\n",
    "\n",
    "    if tb_logger:\n",
    "        tb_logger.add_scalar(f'Test/Loss', test_scores['loss'], curr_round)\n",
    "        tb_logger.add_scalars(f'Test/Scores', {\n",
    "            'accuracy': test_scores['accuracy'], 'f1_macro': test_scores['f1_macro'], 'f1_weighted': test_scores['f1_weighted']\n",
    "        }, curr_round)\n",
    "    \n",
    "    # update the last loss\n",
    "    last_loss = loss_avg\n",
    "\n",
    "  end = time.time()\n",
    "  \n",
    "  # plot train loss\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(train_loss)\n",
    "  ax.plot(x_axis, y_axis)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Train Loss', title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Train_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_loss)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Loss',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  # plot test accuracy\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_accuracy)\n",
    "  ax.plot(x_axis, y_axis)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Accuracy', title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_Accuracy.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  print(\"Training Done! Total time taken to Train: {}\".format(end-start))\n",
    "\n",
    "  return model, train_loss, test_accuracy, test_loss, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXtGLkoAqLIW"
   },
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dQJIJno4qKvc"
   },
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion, num_classes, classes, print_all=False):\n",
    "  #test loss \n",
    "  test_loss = 0.0\n",
    "  correct_class = list(0. for i in range(num_classes))\n",
    "  total_class = list(0. for i in range(num_classes))\n",
    "\n",
    "  test_loader = DataLoader(dataset, batch_size=bs)\n",
    "  l = len(test_loader)\n",
    "  model.eval()\n",
    "  print('running validation...')\n",
    "  for i, (data, labels) in enumerate(tqdm(test_loader)):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "      data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    output = model(data)\n",
    "    loss = criterion(output, labels)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "\n",
    "    # For F1Score\n",
    "    y_true = np.append(y_true, labels.data.view_as(pred).cpu().numpy()) if i != 0 else labels.data.view_as(pred).cpu().numpy()\n",
    "    y_hat = np.append(y_hat, pred.cpu().numpy()) if i != 0 else pred.cpu().numpy()\n",
    "\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "    for i, lbl in enumerate(labels.data):\n",
    "    #   print('lbl', i, lbl)\n",
    "      correct_class[lbl] += correct.data[i]\n",
    "      total_class[lbl] += 1\n",
    "    \n",
    "  # avg test loss\n",
    "  test_loss = test_loss/len(test_loader.dataset)\n",
    "  print(\"Test Loss: {:.6f}\\n\".format(test_loss))\n",
    "\n",
    "  # Avg F1 Score\n",
    "  f1_macro = f1_score(y_true, y_hat, average='macro')\n",
    "  # F1-Score -> weigthed to consider class imbalance\n",
    "  f1_weighted =  f1_score(y_true, y_hat, average='weighted')\n",
    "  print(\"F1 Score: {:.6f} (macro) {:.6f} (weighted) %\\n\".format(f1_macro, f1_weighted))\n",
    "\n",
    "  # print test accuracy\n",
    "  if print_all:\n",
    "    for i in range(num_classes):\n",
    "        if total_class[i]>0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % \n",
    "                    (classes[i], 100 * correct_class[i] / total_class[i],\n",
    "                    np.sum(correct_class[i]), np.sum(total_class[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "  overall_accuracy = np.sum(correct_class) / np.sum(total_class)\n",
    "\n",
    "  print('\\nFinal Test  Accuracy: {:.3f} ({}/{})'.format(overall_accuracy, np.sum(correct_class), np.sum(total_class)))\n",
    "\n",
    "  return {'loss': test_loss, 'accuracy': overall_accuracy, 'f1_macro': f1_macro, 'f1_weighted': f1_weighted}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxqXLBd8qbC2"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "c8gl5P3SMq4a"
   },
   "outputs": [],
   "source": [
    "log_dict = {}\n",
    "NUM_REPEAT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "E2CfSkNVqKtL"
   },
   "outputs": [],
   "source": [
    "seq_length = 80  # mcmahan17a, fedprox, qFFL\n",
    "embedding_dim = 8  # mcmahan17a, fedprox, qFFL\n",
    "# hidden_dim = 100  # fedprox paper\n",
    "hidden_dim = 256  # mcmahan17a, fedprox impl\n",
    "num_classes = len(corpus)\n",
    "classes = list(range(num_classes))\n",
    "lstm_layers = 2  # mcmahan17a, fedprox, qFFL\n",
    "dropout = 0.1  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPIpStyNJ-63"
   },
   "source": [
    "## LSTM FedMed on IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gpS1gyJ_H_MA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective 413629 / 413629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Total users:', 143)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, data_dict, test_ds = iid_partition(corpus, seq_length, val_split=True)  # Not using val_ds but makes train eval periods faster\n",
    "\n",
    "total_clients = len(data_dict.keys())\n",
    "'Total users:', total_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYoGsy05H_RC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Run Number:  0\n",
      "Objective 413629 / 413629\n",
      "Clients: 10/143 -> [ 30  16  81  41 133 142  54  39 113  24]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d33fce968ca4868b8357d306761efaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1... \tAverage Loss: 3.207\n",
      "running validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7739613ae44fb28cf3ecb9295137a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.950988\n",
      "\n",
      "F1 Score: 0.017039 (macro) 0.135244 (weighted) %\n",
      "\n",
      "\n",
      "Final Test  Accuracy: 0.236 (12186.0/51704.0)\n",
      "Clients: 10/143 -> [ 16  24  52  10  42 133  95 131 100  33]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9cc20d52a04dac8bbb97f255a2fc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # partition data\n",
    "  train_ds, data_dict, test_ds = iid_partition(corpus, seq_length, val_split=True)  # Not using val_ds but makes train eval periods faster\n",
    "  total_clients = len(data_dict.keys())\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.07  # 10 clients\n",
    "  # number of clients\n",
    "  K = total_clients\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 1\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr = 0.8\n",
    "  # proximal term constant\n",
    "  M = 0.01\n",
    "\n",
    "  shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,  \n",
    "                                    embedding_dim=embedding_dim,  \n",
    "                                    hidden_dim=hidden_dim,\n",
    "                                    classes=num_classes,\n",
    "                                    lstm_layers=lstm_layers,\n",
    "                                    dropout=dropout,\n",
    "                                    batch_first=True\n",
    "                                    )\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      shakespeare_lstm.cuda()\n",
    "\n",
    "  lstm_iid_trained, train_loss, test_accuracy, test_loss, history = training(shakespeare_lstm,\n",
    "                                          rounds, batch_size, lr,\n",
    "                                          train_ds,\n",
    "                                          data_dict,\n",
    "                                          test_ds,\n",
    "                                          C, K, E, M,\n",
    "                                          'Shakespeare LSTM on IID', \"green\",\n",
    "                                          corpus, # classes\n",
    "                                          )\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss\n",
    "\n",
    "  del lstm_iid_trained\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-irvQHuNNTtB"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               'M': M,\n",
    "               }\n",
    "\n",
    "log_dict['Shakespeare LSTM on IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'history': history,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QO0GkVyKEgu"
   },
   "source": [
    "## LSTM FedMed on Non IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wsHRfwmKGdS"
   },
   "outputs": [],
   "source": [
    "data_dict, test_ds = noniid_partition(corpus, seq_length=seq_length, val_split=False)\n",
    " \n",
    "total_clients = len(data_dict.keys())  \n",
    "'Total users:', total_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNJZG5tvKGgd"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "  # partition dataset\n",
    "  data_dict, test_ds = noniid_partition(corpus, seq_length=seq_length, val_split=False)\n",
    "  total_clients = len(data_dict.keys())  \n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.07  # 10 clients\n",
    "  # number of clients\n",
    "  K = total_clients\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 1\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr = 0.8\n",
    "  # proximal term constant\n",
    "  M = 0.01\n",
    "\n",
    "  shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,\n",
    "                                        embedding_dim=embedding_dim,\n",
    "                                        hidden_dim=hidden_dim,\n",
    "                                        classes=num_classes,\n",
    "                                        lstm_layers=lstm_layers,\n",
    "                                        dropout=dropout,\n",
    "                                        batch_first=True\n",
    "                                        )\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      shakespeare_lstm.cuda()\n",
    "\n",
    "  lstm_non_iid_trained, train_loss, test_accuracy, test_loss, history = training(shakespeare_lstm,\n",
    "                                                rounds, batch_size, lr,\n",
    "                                                None, #  ds empty as it is included in data_dict\n",
    "                                                data_dict,\n",
    "                                                test_ds,\n",
    "                                                C, K, E, M,\n",
    "                                                'Shakespeare LSTM on Non IID', \"green\",\n",
    "                                                corpus, # classes,\n",
    "                                                )\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss\n",
    "\n",
    "  del lstm_non_iid_trained\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uANkBpTRKGkv"
   },
   "outputs": [],
   "source": [
    " hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               'M': M,\n",
    "               }\n",
    "\n",
    "log_dict['Shakespeare LSTM on Non IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'history': history,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShdScPNuQzUQ"
   },
   "source": [
    "## Pickle Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwHt7jviQ1AV"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(path + 'Local_Round_FedMed_1.pkl', 'wb') as file:\n",
    "  pickle.dump(log_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qNkwXxO8Q3Ei"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shakespeare LSTM on IID': {'history': [{'accuracy': 0.2236577440816958,\n",
       "    'f1_macro': 0.015104077724457116,\n",
       "    'f1_weighted': 0.1293341930942227,\n",
       "    'loss': 2.9936777422178387,\n",
       "    'train_loss': 3.208054148614983},\n",
       "   {'accuracy': 0.2746596008045799,\n",
       "    'f1_macro': 0.02972625458570651,\n",
       "    'f1_weighted': 0.182603798501229,\n",
       "    'loss': 2.653277253294884,\n",
       "    'train_loss': 2.8590919136341513},\n",
       "   {'accuracy': 0.30309066996750733,\n",
       "    'f1_macro': 0.039177137688121116,\n",
       "    'f1_weighted': 0.21511828957689233,\n",
       "    'loss': 2.5186536252756855,\n",
       "    'train_loss': 2.6962320110074054},\n",
       "   {'accuracy': 0.32947160761256383,\n",
       "    'f1_macro': 0.057335162095962254,\n",
       "    'f1_weighted': 0.24347908370095914,\n",
       "    'loss': 2.440899636180855,\n",
       "    'train_loss': 2.5896037261866107},\n",
       "   {'accuracy': 0.3387358811697354,\n",
       "    'f1_macro': 0.06284333230659382,\n",
       "    'f1_weighted': 0.2645290702319815,\n",
       "    'loss': 2.360869685715056,\n",
       "    'train_loss': 2.5271001585951156},\n",
       "   {'accuracy': 0.3526032802104286,\n",
       "    'f1_macro': 0.07073642525179528,\n",
       "    'f1_weighted': 0.28872619247472214,\n",
       "    'loss': 2.3096859111157655,\n",
       "    'train_loss': 2.453111573691025},\n",
       "   {'accuracy': 0.3625831657125174,\n",
       "    'f1_macro': 0.08088280108011871,\n",
       "    'f1_weighted': 0.3034094526213914,\n",
       "    'loss': 2.262566891927275,\n",
       "    'train_loss': 2.410258068418437},\n",
       "   {'accuracy': 0.3680953117747176,\n",
       "    'f1_macro': 0.08451285934998949,\n",
       "    'f1_weighted': 0.3156739538952029,\n",
       "    'loss': 2.2232142647095148,\n",
       "    'train_loss': 2.37831243248154},\n",
       "   {'accuracy': 0.3812857805972459,\n",
       "    'f1_macro': 0.09455499773448323,\n",
       "    'f1_weighted': 0.3268816241179035,\n",
       "    'loss': 2.1840985668493134,\n",
       "    'train_loss': 2.3305376095354644},\n",
       "   {'accuracy': 0.3810150085099799,\n",
       "    'f1_macro': 0.0885292931308737,\n",
       "    'f1_weighted': 0.31853143558697905,\n",
       "    'loss': 2.1601685405068034,\n",
       "    'train_loss': 2.289606506819547},\n",
       "   {'accuracy': 0.3910722574655733,\n",
       "    'f1_macro': 0.09768501201794201,\n",
       "    'f1_weighted': 0.3353493946942519,\n",
       "    'loss': 2.131164348708316,\n",
       "    'train_loss': 2.2783318618727257},\n",
       "   {'accuracy': 0.3954046108618289,\n",
       "    'f1_macro': 0.10944261377304139,\n",
       "    'f1_weighted': 0.343442504598909,\n",
       "    'loss': 2.0986252595410706,\n",
       "    'train_loss': 2.2537472012626676},\n",
       "   {'accuracy': 0.40076203001701993,\n",
       "    'f1_macro': 0.10671600690260769,\n",
       "    'f1_weighted': 0.353338316557121,\n",
       "    'loss': 2.070575353526514,\n",
       "    'train_loss': 2.2225229079050646},\n",
       "   {'accuracy': 0.40592604053844966,\n",
       "    'f1_macro': 0.0996563707619239,\n",
       "    'f1_weighted': 0.34629716715232906,\n",
       "    'loss': 2.0487074456439194,\n",
       "    'train_loss': 2.1993023631566126},\n",
       "   {'accuracy': 0.4140298622930528,\n",
       "    'f1_macro': 0.11730893712180161,\n",
       "    'f1_weighted': 0.3610874723857282,\n",
       "    'loss': 2.0359000439545087,\n",
       "    'train_loss': 2.165217515158455},\n",
       "   {'accuracy': 0.41834287482593224,\n",
       "    'f1_macro': 0.12178734413106036,\n",
       "    'f1_weighted': 0.36812943613514576,\n",
       "    'loss': 2.0128087136602226,\n",
       "    'train_loss': 2.152759569273285},\n",
       "   {'accuracy': 0.42377765743462786,\n",
       "    'f1_macro': 0.12874449177255542,\n",
       "    'f1_weighted': 0.3725885409885954,\n",
       "    'loss': 1.9946405719640028,\n",
       "    'train_loss': 2.1565538264295787},\n",
       "   {'accuracy': 0.4238163391613802,\n",
       "    'f1_macro': 0.13066854433512837,\n",
       "    'f1_weighted': 0.3827016543758644,\n",
       "    'loss': 1.9795240111805819,\n",
       "    'train_loss': 2.123505398763001},\n",
       "   {'accuracy': 0.4296572799009748,\n",
       "    'f1_macro': 0.12364073878434105,\n",
       "    'f1_weighted': 0.3801799603879638,\n",
       "    'loss': 1.96474634184246,\n",
       "    'train_loss': 2.1064450208597494},\n",
       "   {'accuracy': 0.43538217546031255,\n",
       "    'f1_macro': 0.135766965120061,\n",
       "    'f1_weighted': 0.3953853780990067,\n",
       "    'loss': 1.9462408784655305,\n",
       "    'train_loss': 2.076433290407206},\n",
       "   {'accuracy': 0.43830264583010986,\n",
       "    'f1_macro': 0.13302064523560136,\n",
       "    'f1_weighted': 0.3931468291695933,\n",
       "    'loss': 1.935522165067601,\n",
       "    'train_loss': 2.0663459428909388},\n",
       "   {'accuracy': 0.43830264583010986,\n",
       "    'f1_macro': 0.1347563443189132,\n",
       "    'f1_weighted': 0.3956879339937979,\n",
       "    'loss': 1.9283112236705706,\n",
       "    'train_loss': 2.0629827721546796},\n",
       "   {'accuracy': 0.4446657898808603,\n",
       "    'f1_macro': 0.1443625003769147,\n",
       "    'f1_weighted': 0.39927155302832695,\n",
       "    'loss': 1.9105383574411574,\n",
       "    'train_loss': 2.0610911699127854},\n",
       "   {'accuracy': 0.4505067306204549,\n",
       "    'f1_macro': 0.14432131246605434,\n",
       "    'f1_weighted': 0.40738402793892,\n",
       "    'loss': 1.8969696288634137,\n",
       "    'train_loss': 2.0383580885198933},\n",
       "   {'accuracy': 0.44921089277425347,\n",
       "    'f1_macro': 0.1385231573464721,\n",
       "    'f1_weighted': 0.4074459194384559,\n",
       "    'loss': 1.8898661149936333,\n",
       "    'train_loss': 2.0280747153143173},\n",
       "   {'accuracy': 0.45259554386507816,\n",
       "    'f1_macro': 0.1486610382234933,\n",
       "    'f1_weighted': 0.41219775099733513,\n",
       "    'loss': 1.8833340318689364,\n",
       "    'train_loss': 2.019520201644297},\n",
       "   {'accuracy': 0.4556514002785084,\n",
       "    'f1_macro': 0.15116727154829282,\n",
       "    'f1_weighted': 0.4156533855351602,\n",
       "    'loss': 1.8664007410101573,\n",
       "    'train_loss': 1.9981115343700964},\n",
       "   {'accuracy': 0.45613492186291194,\n",
       "    'f1_macro': 0.15664697276765405,\n",
       "    'f1_weighted': 0.4118061411484467,\n",
       "    'loss': 1.8633945691969194,\n",
       "    'train_loss': 2.0064437659428984},\n",
       "   {'accuracy': 0.4567344886275723,\n",
       "    'f1_macro': 0.15783960736168265,\n",
       "    'f1_weighted': 0.4156325471322504,\n",
       "    'loss': 1.8536533025219752,\n",
       "    'train_loss': 1.9794209295273202},\n",
       "   {'accuracy': 0.46126025065758935,\n",
       "    'f1_macro': 0.15269426347672505,\n",
       "    'f1_weighted': 0.4214270611177604,\n",
       "    'loss': 1.8428288802179449,\n",
       "    'train_loss': 1.978623929666162},\n",
       "   {'accuracy': 0.46367785857960697,\n",
       "    'f1_macro': 0.16135522907969857,\n",
       "    'f1_weighted': 0.42368935179551975,\n",
       "    'loss': 1.8311841659260557,\n",
       "    'train_loss': 1.9721835891653061},\n",
       "   {'accuracy': 0.46596008045799164,\n",
       "    'f1_macro': 0.16423696371844007,\n",
       "    'f1_weighted': 0.4288275000104561,\n",
       "    'loss': 1.8211252829957705,\n",
       "    'train_loss': 1.9515916633655421},\n",
       "   {'accuracy': 0.4667723967197896,\n",
       "    'f1_macro': 0.1596663600986461,\n",
       "    'f1_weighted': 0.4247917309469977,\n",
       "    'loss': 1.8175038054248838,\n",
       "    'train_loss': 1.9416088493327053},\n",
       "   {'accuracy': 0.46536051369333126,\n",
       "    'f1_macro': 0.1561220591976984,\n",
       "    'f1_weighted': 0.42457840369850874,\n",
       "    'loss': 1.815392455352122,\n",
       "    'train_loss': 1.9509844684836817},\n",
       "   {'accuracy': 0.47259399659600804,\n",
       "    'f1_macro': 0.16553922026150697,\n",
       "    'f1_weighted': 0.43711367839481996,\n",
       "    'loss': 1.79919940381539,\n",
       "    'train_loss': 1.9431163443667223},\n",
       "   {'accuracy': 0.47023441126411886,\n",
       "    'f1_macro': 0.16493282683279792,\n",
       "    'f1_weighted': 0.4343108886247401,\n",
       "    'loss': 1.8073362272844333,\n",
       "    'train_loss': 1.932948131755221},\n",
       "   {'accuracy': 0.47423796998298007,\n",
       "    'f1_macro': 0.17010541285005368,\n",
       "    'f1_weighted': 0.44086242017326227,\n",
       "    'loss': 1.788794862110189,\n",
       "    'train_loss': 1.9404067867830974},\n",
       "   {'accuracy': 0.4746054463871267,\n",
       "    'f1_macro': 0.16567411456096096,\n",
       "    'f1_weighted': 0.4305940744142858,\n",
       "    'loss': 1.7856705737809324,\n",
       "    'train_loss': 1.8905223597320286},\n",
       "   {'accuracy': 0.47456676466037445,\n",
       "    'f1_macro': 0.1689842011946874,\n",
       "    'f1_weighted': 0.43772585347375953,\n",
       "    'loss': 1.775502470531908,\n",
       "    'train_loss': 1.9212203218646728},\n",
       "   {'accuracy': 0.4778547114343184,\n",
       "    'f1_macro': 0.17068985016228505,\n",
       "    'f1_weighted': 0.44342269334579454,\n",
       "    'loss': 1.7710408885242326,\n",
       "    'train_loss': 1.8890121208660997},\n",
       "   {'accuracy': 0.48046572799009746,\n",
       "    'f1_macro': 0.1701552788058677,\n",
       "    'f1_weighted': 0.4445133077235638,\n",
       "    'loss': 1.7717610602677052,\n",
       "    'train_loss': 1.8848806743614408},\n",
       "   {'accuracy': 0.47636546495435556,\n",
       "    'f1_macro': 0.17000603762683456,\n",
       "    'f1_weighted': 0.4424543506836585,\n",
       "    'loss': 1.7693066110276234,\n",
       "    'train_loss': 1.8777324944322369},\n",
       "   {'accuracy': 0.4816455206560421,\n",
       "    'f1_macro': 0.17172622848045294,\n",
       "    'f1_weighted': 0.44600938889540676,\n",
       "    'loss': 1.7569709974369194,\n",
       "    'train_loss': 1.9015619938654686},\n",
       "   {'accuracy': 0.4835796069936562,\n",
       "    'f1_macro': 0.17669141931173415,\n",
       "    'f1_weighted': 0.44371073610582257,\n",
       "    'loss': 1.7506832755743562,\n",
       "    'train_loss': 1.9084458150598187},\n",
       "   {'accuracy': 0.4862293052761875,\n",
       "    'f1_macro': 0.17988055998628596,\n",
       "    'f1_weighted': 0.45379537910773965,\n",
       "    'loss': 1.7398337833623703,\n",
       "    'train_loss': 1.8814351837025804},\n",
       "   {'accuracy': 0.48704162153798547,\n",
       "    'f1_macro': 0.17877112251952346,\n",
       "    'f1_weighted': 0.45171726085227004,\n",
       "    'loss': 1.7367263815694136,\n",
       "    'train_loss': 1.8664136903672215},\n",
       "   {'accuracy': 0.48638403218319665,\n",
       "    'f1_macro': 0.17802381833395087,\n",
       "    'f1_weighted': 0.45222591181269267,\n",
       "    'loss': 1.7375911972527993,\n",
       "    'train_loss': 1.8714817009258233},\n",
       "   {'accuracy': 0.4886082314714529,\n",
       "    'f1_macro': 0.17580530336447203,\n",
       "    'f1_weighted': 0.4532760624937139,\n",
       "    'loss': 1.7317705060926436,\n",
       "    'train_loss': 1.8614851385725981},\n",
       "   {'accuracy': 0.49052297694569086,\n",
       "    'f1_macro': 0.1822224603110044,\n",
       "    'f1_weighted': 0.4530624276622123,\n",
       "    'loss': 1.729958966654529,\n",
       "    'train_loss': 1.8752640947266734},\n",
       "   {'accuracy': 0.49222497292279127,\n",
       "    'f1_macro': 0.1762057442953883,\n",
       "    'f1_weighted': 0.4575881958979546,\n",
       "    'loss': 1.716984340859081,\n",
       "    'train_loss': 1.860168727686214}],\n",
       "  'hyperparams': {'C': 0.07,\n",
       "   'E': 1,\n",
       "   'K': 143,\n",
       "   'M': 0.01,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.8,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[0.23568776110165557,\n",
       "    0.27496905461859816,\n",
       "    0.29833281757697666,\n",
       "    0.3239594615503636,\n",
       "    0.33672443137861674,\n",
       "    0.34227525916756923,\n",
       "    0.3615774408169581,\n",
       "    0.3690816958069008,\n",
       "    0.37931301253287947,\n",
       "    0.39031796379390377,\n",
       "    0.3938186600649853,\n",
       "    0.40043323533962555,\n",
       "    0.40480427046263345,\n",
       "    0.4133142503481355,\n",
       "    0.4151322915054928,\n",
       "    0.42039300634380317,\n",
       "    0.42464799628655425,\n",
       "    0.42865155500541546,\n",
       "    0.43114652638093764,\n",
       "    0.43429908711124865,\n",
       "    0.4383606684202383,\n",
       "    0.44371808757542935,\n",
       "    0.44526535664552064,\n",
       "    0.446406467584713,\n",
       "    0.45110629738511526,\n",
       "    0.4515317963793904,\n",
       "    0.45437490329568314,\n",
       "    0.4569472381247099,\n",
       "    0.4598290267677549,\n",
       "    0.4612409097942132,\n",
       "    0.46414203930063436,\n",
       "    0.46644360204239516,\n",
       "    0.468068234565991,\n",
       "    0.4696541853628346,\n",
       "    0.47093068234565993,\n",
       "    0.4725359740058796,\n",
       "    0.47394785703233794,\n",
       "    0.47354169890143893,\n",
       "    0.4752050131517871,\n",
       "    0.47975011604518025,\n",
       "    0.4797307751818041,\n",
       "    0.4820710196503172,\n",
       "    0.48421785548506885,\n",
       "    0.484507968435711,\n",
       "    0.4870222806746093,\n",
       "    0.48398576512455516,\n",
       "    0.48822141420393006,\n",
       "    0.48591985146216926,\n",
       "    0.48957527464025996,\n",
       "    0.48953659291350765],\n",
       "   [0.2236577440816958,\n",
       "    0.2746596008045799,\n",
       "    0.30309066996750733,\n",
       "    0.32947160761256383,\n",
       "    0.3387358811697354,\n",
       "    0.3526032802104286,\n",
       "    0.3625831657125174,\n",
       "    0.3680953117747176,\n",
       "    0.3812857805972459,\n",
       "    0.3810150085099799,\n",
       "    0.3910722574655733,\n",
       "    0.3954046108618289,\n",
       "    0.40076203001701993,\n",
       "    0.40592604053844966,\n",
       "    0.4140298622930528,\n",
       "    0.41834287482593224,\n",
       "    0.42377765743462786,\n",
       "    0.4238163391613802,\n",
       "    0.4296572799009748,\n",
       "    0.43538217546031255,\n",
       "    0.43830264583010986,\n",
       "    0.43830264583010986,\n",
       "    0.4446657898808603,\n",
       "    0.4505067306204549,\n",
       "    0.44921089277425347,\n",
       "    0.45259554386507816,\n",
       "    0.4556514002785084,\n",
       "    0.45613492186291194,\n",
       "    0.4567344886275723,\n",
       "    0.46126025065758935,\n",
       "    0.46367785857960697,\n",
       "    0.46596008045799164,\n",
       "    0.4667723967197896,\n",
       "    0.46536051369333126,\n",
       "    0.47259399659600804,\n",
       "    0.47023441126411886,\n",
       "    0.47423796998298007,\n",
       "    0.4746054463871267,\n",
       "    0.47456676466037445,\n",
       "    0.4778547114343184,\n",
       "    0.48046572799009746,\n",
       "    0.47636546495435556,\n",
       "    0.4816455206560421,\n",
       "    0.4835796069936562,\n",
       "    0.4862293052761875,\n",
       "    0.48704162153798547,\n",
       "    0.48638403218319665,\n",
       "    0.4886082314714529,\n",
       "    0.49052297694569086,\n",
       "    0.49222497292279127]],\n",
       "  'test_loss': [[2.9509879754605204,\n",
       "    2.679323325446935,\n",
       "    2.55582371149826,\n",
       "    2.4602977079945267,\n",
       "    2.3825923498802357,\n",
       "    2.3360962757251955,\n",
       "    2.2777489618990936,\n",
       "    2.2307701528524255,\n",
       "    2.1913712402878023,\n",
       "    2.1526000082317602,\n",
       "    2.125350153881497,\n",
       "    2.097129419330711,\n",
       "    2.069289115658305,\n",
       "    2.0507141062437926,\n",
       "    2.0314796197719662,\n",
       "    2.0150503819154437,\n",
       "    1.9922002833921642,\n",
       "    1.979433805481321,\n",
       "    1.9706518617603463,\n",
       "    1.9579183641067788,\n",
       "    1.9406791153996052,\n",
       "    1.9248357560833171,\n",
       "    1.915647324204039,\n",
       "    1.9017506698528328,\n",
       "    1.892348248105189,\n",
       "    1.886189284511216,\n",
       "    1.8743380679746502,\n",
       "    1.8616515075182392,\n",
       "    1.8528239656122738,\n",
       "    1.8443819464530329,\n",
       "    1.8330372120276077,\n",
       "    1.8279991264283684,\n",
       "    1.8216407500817258,\n",
       "    1.8149606894454442,\n",
       "    1.8080047049681993,\n",
       "    1.8025727108139362,\n",
       "    1.7920672414637324,\n",
       "    1.7850973619655082,\n",
       "    1.782142607628626,\n",
       "    1.7709939722747012,\n",
       "    1.765488362161991,\n",
       "    1.7639896363600958,\n",
       "    1.7579580021705972,\n",
       "    1.7543640605426325,\n",
       "    1.7454725120740557,\n",
       "    1.748421536026799,\n",
       "    1.7399307321004873,\n",
       "    1.7344210117008596,\n",
       "    1.7306095597279592,\n",
       "    1.7239611449220704],\n",
       "   [2.9936777422178387,\n",
       "    2.653277253294884,\n",
       "    2.5186536252756855,\n",
       "    2.440899636180855,\n",
       "    2.360869685715056,\n",
       "    2.3096859111157655,\n",
       "    2.262566891927275,\n",
       "    2.2232142647095148,\n",
       "    2.1840985668493134,\n",
       "    2.1601685405068034,\n",
       "    2.131164348708316,\n",
       "    2.0986252595410706,\n",
       "    2.070575353526514,\n",
       "    2.0487074456439194,\n",
       "    2.0359000439545087,\n",
       "    2.0128087136602226,\n",
       "    1.9946405719640028,\n",
       "    1.9795240111805819,\n",
       "    1.96474634184246,\n",
       "    1.9462408784655305,\n",
       "    1.935522165067601,\n",
       "    1.9283112236705706,\n",
       "    1.9105383574411574,\n",
       "    1.8969696288634137,\n",
       "    1.8898661149936333,\n",
       "    1.8833340318689364,\n",
       "    1.8664007410101573,\n",
       "    1.8633945691969194,\n",
       "    1.8536533025219752,\n",
       "    1.8428288802179449,\n",
       "    1.8311841659260557,\n",
       "    1.8211252829957705,\n",
       "    1.8175038054248838,\n",
       "    1.815392455352122,\n",
       "    1.79919940381539,\n",
       "    1.8073362272844333,\n",
       "    1.788794862110189,\n",
       "    1.7856705737809324,\n",
       "    1.775502470531908,\n",
       "    1.7710408885242326,\n",
       "    1.7717610602677052,\n",
       "    1.7693066110276234,\n",
       "    1.7569709974369194,\n",
       "    1.7506832755743562,\n",
       "    1.7398337833623703,\n",
       "    1.7367263815694136,\n",
       "    1.7375911972527993,\n",
       "    1.7317705060926436,\n",
       "    1.729958966654529,\n",
       "    1.716984340859081]],\n",
       "  'train_loss': [[3.2073186003485823,\n",
       "    2.879929837844184,\n",
       "    2.721279323999648,\n",
       "    2.6180177492637027,\n",
       "    2.5419564212341363,\n",
       "    2.4804931424135654,\n",
       "    2.439099968312357,\n",
       "    2.3695801622227846,\n",
       "    2.3440147008803542,\n",
       "    2.2956218415399805,\n",
       "    2.269146683311314,\n",
       "    2.240612109032244,\n",
       "    2.2093946399729125,\n",
       "    2.2013601121730986,\n",
       "    2.1798378747075096,\n",
       "    2.163343544623829,\n",
       "    2.1485977393050737,\n",
       "    2.126936033114606,\n",
       "    2.10306505405062,\n",
       "    2.1059509476685423,\n",
       "    2.0889342861304145,\n",
       "    2.0650402813799484,\n",
       "    2.064005495168856,\n",
       "    2.0437639407020054,\n",
       "    2.0388741631395755,\n",
       "    2.0309781332316073,\n",
       "    2.003497287642886,\n",
       "    1.9965950321978057,\n",
       "    1.9880086074860182,\n",
       "    1.9857029868529423,\n",
       "    1.975878913592377,\n",
       "    1.9539970949632255,\n",
       "    1.942562334732163,\n",
       "    1.9691780352720254,\n",
       "    1.9370448582812134,\n",
       "    1.9326399823524483,\n",
       "    1.926873881263687,\n",
       "    1.9202561818568207,\n",
       "    1.9081388580498193,\n",
       "    1.9013679802335315,\n",
       "    1.8874624790739716,\n",
       "    1.8883518416563336,\n",
       "    1.9040995558247196,\n",
       "    1.877616799131221,\n",
       "    1.9040732832143745,\n",
       "    1.873563853684519,\n",
       "    1.861123964268802,\n",
       "    1.8639852694146861,\n",
       "    1.8598573955798705,\n",
       "    1.8637752993271932],\n",
       "   [3.208054148614983,\n",
       "    2.8590919136341513,\n",
       "    2.6962320110074054,\n",
       "    2.5896037261866107,\n",
       "    2.5271001585951156,\n",
       "    2.453111573691025,\n",
       "    2.410258068418437,\n",
       "    2.37831243248154,\n",
       "    2.3305376095354644,\n",
       "    2.289606506819547,\n",
       "    2.2783318618727257,\n",
       "    2.2537472012626676,\n",
       "    2.2225229079050646,\n",
       "    2.1993023631566126,\n",
       "    2.165217515158455,\n",
       "    2.152759569273285,\n",
       "    2.1565538264295787,\n",
       "    2.123505398763001,\n",
       "    2.1064450208597494,\n",
       "    2.076433290407206,\n",
       "    2.0663459428909388,\n",
       "    2.0629827721546796,\n",
       "    2.0610911699127854,\n",
       "    2.0383580885198933,\n",
       "    2.0280747153143173,\n",
       "    2.019520201644297,\n",
       "    1.9981115343700964,\n",
       "    2.0064437659428984,\n",
       "    1.9794209295273202,\n",
       "    1.978623929666162,\n",
       "    1.9721835891653061,\n",
       "    1.9515916633655421,\n",
       "    1.9416088493327053,\n",
       "    1.9509844684836817,\n",
       "    1.9431163443667223,\n",
       "    1.932948131755221,\n",
       "    1.9404067867830974,\n",
       "    1.8905223597320286,\n",
       "    1.9212203218646728,\n",
       "    1.8890121208660997,\n",
       "    1.8848806743614408,\n",
       "    1.8777324944322369,\n",
       "    1.9015619938654686,\n",
       "    1.9084458150598187,\n",
       "    1.8814351837025804,\n",
       "    1.8664136903672215,\n",
       "    1.8714817009258233,\n",
       "    1.8614851385725981,\n",
       "    1.8752640947266734,\n",
       "    1.860168727686214]]},\n",
       " 'Shakespeare LSTM on Non IID': {'history': [{'accuracy': 0.1863215980362786,\n",
       "    'f1_macro': 0.004832561639912748,\n",
       "    'f1_weighted': 0.05852668947822855,\n",
       "    'loss': 3.2430589799622833,\n",
       "    'train_loss': 3.5411432452997564},\n",
       "   {'accuracy': 0.1863215980362786,\n",
       "    'f1_macro': 0.004832561639912748,\n",
       "    'f1_weighted': 0.05852668947822855,\n",
       "    'loss': 3.1795849220405055,\n",
       "    'train_loss': 3.1619731250939322},\n",
       "   {'accuracy': 0.21872493404331397,\n",
       "    'f1_macro': 0.013481117364525229,\n",
       "    'f1_weighted': 0.10080736911745393,\n",
       "    'loss': 2.9960446554080167,\n",
       "    'train_loss': 3.067862387415631},\n",
       "   {'accuracy': 0.23502807387148836,\n",
       "    'f1_macro': 0.01963356141398289,\n",
       "    'f1_weighted': 0.13820249842636326,\n",
       "    'loss': 2.896202556025481,\n",
       "    'train_loss': 2.958092130518429},\n",
       "   {'accuracy': 0.2599128308706283,\n",
       "    'f1_macro': 0.02618768476045969,\n",
       "    'f1_weighted': 0.15622839023909016,\n",
       "    'loss': 2.794514358247005,\n",
       "    'train_loss': 2.814349858141109},\n",
       "   {'accuracy': 0.2446630652222233,\n",
       "    'f1_macro': 0.017600392767917836,\n",
       "    'f1_weighted': 0.12562995234804405,\n",
       "    'loss': 2.782499752854145,\n",
       "    'train_loss': 2.7582349136701163},\n",
       "   {'accuracy': 0.2773080008117746,\n",
       "    'f1_macro': 0.028317599121072626,\n",
       "    'f1_weighted': 0.17981570072304517,\n",
       "    'loss': 2.6890230529259496,\n",
       "    'train_loss': 2.764080592497641},\n",
       "   {'accuracy': 0.29514771398475026,\n",
       "    'f1_macro': 0.03689941468924419,\n",
       "    'f1_weighted': 0.20834617787713333,\n",
       "    'loss': 2.5636276470404855,\n",
       "    'train_loss': 2.727227530901683},\n",
       "   {'accuracy': 0.2993418827372266,\n",
       "    'f1_macro': 0.036800222556769874,\n",
       "    'f1_weighted': 0.20154488942067725,\n",
       "    'loss': 2.5327135503746563,\n",
       "    'train_loss': 2.60883108842582},\n",
       "   {'accuracy': 0.3119243889946558,\n",
       "    'f1_macro': 0.0421549124776514,\n",
       "    'f1_weighted': 0.21973190300773796,\n",
       "    'loss': 2.4790464062067112,\n",
       "    'train_loss': 2.5843138377527657},\n",
       "   {'accuracy': 0.31020419996714244,\n",
       "    'f1_macro': 0.04765017941021805,\n",
       "    'f1_weighted': 0.23755367581570197,\n",
       "    'loss': 2.470070054416654,\n",
       "    'train_loss': 2.475229862092251},\n",
       "   {'accuracy': 0.3222358591764353,\n",
       "    'f1_macro': 0.05053498172367987,\n",
       "    'f1_weighted': 0.24482925348821566,\n",
       "    'loss': 2.447994856404149,\n",
       "    'train_loss': 2.60862198821258},\n",
       "   {'accuracy': 0.3302666292992646,\n",
       "    'f1_macro': 0.05528415752142335,\n",
       "    'f1_weighted': 0.2492702753636989,\n",
       "    'loss': 2.3965893757212307,\n",
       "    'train_loss': 2.515281088466732},\n",
       "   {'accuracy': 0.3422982885085575,\n",
       "    'f1_macro': 0.06270448445817176,\n",
       "    'f1_weighted': 0.2675062348543258,\n",
       "    'loss': 2.355440403222842,\n",
       "    'train_loss': 2.5694203893522536},\n",
       "   {'accuracy': 0.3463474975115243,\n",
       "    'f1_macro': 0.0630210551610223,\n",
       "    'f1_weighted': 0.26886402016561434,\n",
       "    'loss': 2.338979499602975,\n",
       "    'train_loss': 2.3992199836751076},\n",
       "   {'accuracy': 0.35338287735438795,\n",
       "    'f1_macro': 0.07017906102287522,\n",
       "    'f1_weighted': 0.2848944614260002,\n",
       "    'loss': 2.3134980550719155,\n",
       "    'train_loss': 2.3630168060388175},\n",
       "   {'accuracy': 0.3598577461658146,\n",
       "    'f1_macro': 0.07429053374533028,\n",
       "    'f1_weighted': 0.2982581633216336,\n",
       "    'loss': 2.2909948102933226,\n",
       "    'train_loss': 2.411659228962232},\n",
       "   {'accuracy': 0.36610067937802604,\n",
       "    'f1_macro': 0.07943535138106385,\n",
       "    'f1_weighted': 0.308051355894155,\n",
       "    'loss': 2.2441002218846586,\n",
       "    'train_loss': 2.3869333957886005},\n",
       "   {'accuracy': 0.37211167699102216,\n",
       "    'f1_macro': 0.08096949199250474,\n",
       "    'f1_weighted': 0.3195009924007582,\n",
       "    'loss': 2.2300110606586774,\n",
       "    'train_loss': 2.2542314449017975},\n",
       "   {'accuracy': 0.3735419465195164,\n",
       "    'f1_macro': 0.08274080164073738,\n",
       "    'f1_weighted': 0.31948574570847516,\n",
       "    'loss': 2.2177960435832436,\n",
       "    'train_loss': 2.3675594426569804},\n",
       "   {'accuracy': 0.3785768818191482,\n",
       "    'f1_macro': 0.08514793494511404,\n",
       "    'f1_weighted': 0.3239756116307781,\n",
       "    'loss': 2.1947668303229295,\n",
       "    'train_loss': 2.2735422105852074},\n",
       "   {'accuracy': 0.3813987649429342,\n",
       "    'f1_macro': 0.08570309063985879,\n",
       "    'f1_weighted': 0.33012828520115745,\n",
       "    'loss': 2.1842116007296637,\n",
       "    'train_loss': 2.2555151211696605},\n",
       "   {'accuracy': 0.3818433081747635,\n",
       "    'f1_macro': 0.09105834664769893,\n",
       "    'f1_weighted': 0.3345531040126541,\n",
       "    'loss': 2.177778722402898,\n",
       "    'train_loss': 2.272596418150019},\n",
       "   {'accuracy': 0.38391140060109974,\n",
       "    'f1_macro': 0.0886314034504803,\n",
       "    'f1_weighted': 0.33263274650650804,\n",
       "    'loss': 2.16675943766552,\n",
       "    'train_loss': 2.2209896339403943},\n",
       "   {'accuracy': 0.3815340607091431,\n",
       "    'f1_macro': 0.09116372889343419,\n",
       "    'f1_weighted': 0.3384954597887637,\n",
       "    'loss': 2.1553537706295787,\n",
       "    'train_loss': 2.1908668112031173},\n",
       "   {'accuracy': 0.3850420866472743,\n",
       "    'f1_macro': 0.0914306938236347,\n",
       "    'f1_weighted': 0.3371219240518521,\n",
       "    'loss': 2.148176225625661,\n",
       "    'train_loss': 2.243664883921616},\n",
       "   {'accuracy': 0.3909467804439634,\n",
       "    'f1_macro': 0.09632087848740314,\n",
       "    'f1_weighted': 0.33665287271997896,\n",
       "    'loss': 2.1375420769712727,\n",
       "    'train_loss': 2.1781027020030193},\n",
       "   {'accuracy': 0.39381698348425254,\n",
       "    'f1_macro': 0.09647565483824307,\n",
       "    'f1_weighted': 0.34804800132045055,\n",
       "    'loss': 2.1256723815818304,\n",
       "    'train_loss': 2.2392103145055993},\n",
       "   {'accuracy': 0.3928892410873914,\n",
       "    'f1_macro': 0.10063263816471298,\n",
       "    'f1_weighted': 0.3486773549950724,\n",
       "    'loss': 2.1199555887674553,\n",
       "    'train_loss': 2.2281557670742416},\n",
       "   {'accuracy': 0.3940005991669646,\n",
       "    'f1_macro': 0.09424416857861875,\n",
       "    'f1_weighted': 0.3421697532611533,\n",
       "    'loss': 2.115735541352933,\n",
       "    'train_loss': 2.1732776413355426},\n",
       "   {'accuracy': 0.3953535568290538,\n",
       "    'f1_macro': 0.09919580116219837,\n",
       "    'f1_weighted': 0.35229499888057103,\n",
       "    'loss': 2.1112177658720666,\n",
       "    'train_loss': 2.151782714400755},\n",
       "   {'accuracy': 0.39245436183886273,\n",
       "    'f1_macro': 0.10390602360577071,\n",
       "    'f1_weighted': 0.35194851738232097,\n",
       "    'loss': 2.1037146122400276,\n",
       "    'train_loss': 2.0902992428442912},\n",
       "   {'accuracy': 0.3943485025657876,\n",
       "    'f1_macro': 0.10157025500088189,\n",
       "    'f1_weighted': 0.34961370037783285,\n",
       "    'loss': 2.098522637414519,\n",
       "    'train_loss': 2.1447072792855626},\n",
       "   {'accuracy': 0.40068807561100533,\n",
       "    'f1_macro': 0.09733981060426969,\n",
       "    'f1_weighted': 0.3516780334467986,\n",
       "    'loss': 2.0856888642641915,\n",
       "    'train_loss': 2.1634046870748036},\n",
       "   {'accuracy': 0.4013838824086512,\n",
       "    'f1_macro': 0.09851007953847578,\n",
       "    'f1_weighted': 0.355358955064516,\n",
       "    'loss': 2.077539134150224,\n",
       "    'train_loss': 2.105865296026189},\n",
       "   {'accuracy': 0.4060709143094601,\n",
       "    'f1_macro': 0.10732235539565756,\n",
       "    'f1_weighted': 0.3562774075033851,\n",
       "    'loss': 2.068088937069772,\n",
       "    'train_loss': 2.0071701974360687},\n",
       "   {'accuracy': 0.4060322583762575,\n",
       "    'f1_macro': 0.10875209162075762,\n",
       "    'f1_weighted': 0.3586017024924734,\n",
       "    'loss': 2.063131281821903,\n",
       "    'train_loss': 2.2250546500397776},\n",
       "   {'accuracy': 0.4058679706601467,\n",
       "    'f1_macro': 0.10718598824446708,\n",
       "    'f1_weighted': 0.3621274547166224,\n",
       "    'loss': 2.0643241642426426,\n",
       "    'train_loss': 2.1218991054714937},\n",
       "   {'accuracy': 0.40908607709925876,\n",
       "    'f1_macro': 0.10740700930900256,\n",
       "    'f1_weighted': 0.3624781861722643,\n",
       "    'loss': 2.0587593172889043,\n",
       "    'train_loss': 2.0818298823765686},\n",
       "   {'accuracy': 0.4114247610580129,\n",
       "    'f1_macro': 0.10841192979952048,\n",
       "    'f1_weighted': 0.36025842698232724,\n",
       "    'loss': 2.047049650644615,\n",
       "    'train_loss': 2.182505236648072},\n",
       "   {'accuracy': 0.4083129584352078,\n",
       "    'f1_macro': 0.10873135439030722,\n",
       "    'f1_weighted': 0.35932434015390363,\n",
       "    'loss': 2.0464768912685134,\n",
       "    'train_loss': 2.132759417971146},\n",
       "   {'accuracy': 0.4120819119224562,\n",
       "    'f1_macro': 0.10656537939571133,\n",
       "    'f1_weighted': 0.35952563344888794,\n",
       "    'loss': 2.036888390546496,\n",
       "    'train_loss': 2.1550643582317695},\n",
       "   {'accuracy': 0.41450757173091607,\n",
       "    'f1_macro': 0.11295221633042772,\n",
       "    'f1_weighted': 0.3720774156657782,\n",
       "    'loss': 2.023330504154165,\n",
       "    'train_loss': 2.0716527940167158},\n",
       "   {'accuracy': 0.4153580022613721,\n",
       "    'f1_macro': 0.10294964957138612,\n",
       "    'f1_weighted': 0.36697912044012165,\n",
       "    'loss': 2.0204414680403024,\n",
       "    'train_loss': 2.058276893273732},\n",
       "   {'accuracy': 0.4151840505619606,\n",
       "    'f1_macro': 0.10434693193732911,\n",
       "    'f1_weighted': 0.36656521114503465,\n",
       "    'loss': 2.0234757437218405,\n",
       "    'train_loss': 2.06789739472297},\n",
       "   {'accuracy': 0.4197067947466587,\n",
       "    'f1_macro': 0.10783577766963093,\n",
       "    'f1_weighted': 0.3723615271850335,\n",
       "    'loss': 2.0056929034821893,\n",
       "    'train_loss': 2.095987485310699},\n",
       "   {'accuracy': 0.4206538651101211,\n",
       "    'f1_macro': 0.11756048519408847,\n",
       "    'f1_weighted': 0.37629143562385453,\n",
       "    'loss': 2.0041812927437204,\n",
       "    'train_loss': 2.144899221584325},\n",
       "   {'accuracy': 0.4197937705963644,\n",
       "    'f1_macro': 0.1164271905226175,\n",
       "    'f1_weighted': 0.37433498354925465,\n",
       "    'loss': 1.9995336722736412,\n",
       "    'train_loss': 2.093869415825277},\n",
       "   {'accuracy': 0.4214076558075708,\n",
       "    'f1_macro': 0.11550119412494005,\n",
       "    'f1_weighted': 0.37907274340048847,\n",
       "    'loss': 1.9903559832421467,\n",
       "    'train_loss': 2.1040837733524134},\n",
       "   {'accuracy': 0.4245581143635784,\n",
       "    'f1_macro': 0.11430704076232122,\n",
       "    'f1_weighted': 0.38181947189577137,\n",
       "    'loss': 1.9827766018366246,\n",
       "    'train_loss': 2.0569070153891973}],\n",
       "  'hyperparams': {'C': 0.07,\n",
       "   'E': 1,\n",
       "   'K': 143,\n",
       "   'M': 0.01,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.8,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[0.1863215980362786,\n",
       "    0.1863215980362786,\n",
       "    0.2197009963566783,\n",
       "    0.267131826396204,\n",
       "    0.2837055577567962,\n",
       "    0.2800719000357567,\n",
       "    0.29740908607709926,\n",
       "    0.299332218753926,\n",
       "    0.30797181982469535,\n",
       "    0.31977154343477293,\n",
       "    0.319104728587029,\n",
       "    0.3248451346676073,\n",
       "    0.33520492476589,\n",
       "    0.34625085767851793,\n",
       "    0.3434676304879345,\n",
       "    0.35149840061076376,\n",
       "    0.3580699092551968,\n",
       "    0.3651632729978643,\n",
       "    0.3649216734153483,\n",
       "    0.36872928283579925,\n",
       "    0.3735999304193202,\n",
       "    0.3682944035872706,\n",
       "    0.38393072856770105,\n",
       "    0.3852836862297902,\n",
       "    0.39230940208935317,\n",
       "    0.39292789702059394,\n",
       "    0.398301071735748,\n",
       "    0.3986779670844729,\n",
       "    0.39607835557660154,\n",
       "    0.39557582844496847,\n",
       "    0.4029204557534525,\n",
       "    0.4082259825855021,\n",
       "    0.4134155416179441,\n",
       "    0.4080810228359925,\n",
       "    0.41372478908356447,\n",
       "    0.41331890178493774,\n",
       "    0.414642867497125,\n",
       "    0.41530001836156827,\n",
       "    0.4170878552721861,\n",
       "    0.4187983803163988,\n",
       "    0.4195038510973453,\n",
       "    0.42122404012485865,\n",
       "    0.422519013887144,\n",
       "    0.4229345651690714,\n",
       "    0.42190051895590325,\n",
       "    0.42746697333707007,\n",
       "    0.4263169593242943,\n",
       "    0.42740898943726624,\n",
       "    0.4278728606356968,\n",
       "    0.4310909670748089],\n",
       "   [0.1863215980362786,\n",
       "    0.1863215980362786,\n",
       "    0.21872493404331397,\n",
       "    0.23502807387148836,\n",
       "    0.2599128308706283,\n",
       "    0.2446630652222233,\n",
       "    0.2773080008117746,\n",
       "    0.29514771398475026,\n",
       "    0.2993418827372266,\n",
       "    0.3119243889946558,\n",
       "    0.31020419996714244,\n",
       "    0.3222358591764353,\n",
       "    0.3302666292992646,\n",
       "    0.3422982885085575,\n",
       "    0.3463474975115243,\n",
       "    0.35338287735438795,\n",
       "    0.3598577461658146,\n",
       "    0.36610067937802604,\n",
       "    0.37211167699102216,\n",
       "    0.3735419465195164,\n",
       "    0.3785768818191482,\n",
       "    0.3813987649429342,\n",
       "    0.3818433081747635,\n",
       "    0.38391140060109974,\n",
       "    0.3815340607091431,\n",
       "    0.3850420866472743,\n",
       "    0.3909467804439634,\n",
       "    0.39381698348425254,\n",
       "    0.3928892410873914,\n",
       "    0.3940005991669646,\n",
       "    0.3953535568290538,\n",
       "    0.39245436183886273,\n",
       "    0.3943485025657876,\n",
       "    0.40068807561100533,\n",
       "    0.4013838824086512,\n",
       "    0.4060709143094601,\n",
       "    0.4060322583762575,\n",
       "    0.4058679706601467,\n",
       "    0.40908607709925876,\n",
       "    0.4114247610580129,\n",
       "    0.4083129584352078,\n",
       "    0.4120819119224562,\n",
       "    0.41450757173091607,\n",
       "    0.4153580022613721,\n",
       "    0.4151840505619606,\n",
       "    0.4197067947466587,\n",
       "    0.4206538651101211,\n",
       "    0.4197937705963644,\n",
       "    0.4214076558075708,\n",
       "    0.4245581143635784]],\n",
       "  'test_loss': [[3.398926038868421,\n",
       "    3.2093583108427763,\n",
       "    2.8945172185584567,\n",
       "    2.728865097569421,\n",
       "    2.645725111506679,\n",
       "    2.5513662316386574,\n",
       "    2.529816155771109,\n",
       "    2.512757356960109,\n",
       "    2.4747312092348595,\n",
       "    2.458137491984181,\n",
       "    2.4402480866693663,\n",
       "    2.3978866672831987,\n",
       "    2.3843406533352116,\n",
       "    2.3452518929158908,\n",
       "    2.3233077035324943,\n",
       "    2.3087933502225653,\n",
       "    2.2957956948753084,\n",
       "    2.262020478854383,\n",
       "    2.2490741788292046,\n",
       "    2.2320684822966212,\n",
       "    2.2297127316589465,\n",
       "    2.236142082304537,\n",
       "    2.1818265794955423,\n",
       "    2.1608131636520467,\n",
       "    2.147093886866075,\n",
       "    2.1422807957491363,\n",
       "    2.122751938617827,\n",
       "    2.114286141868733,\n",
       "    2.109299246598317,\n",
       "    2.106516320709077,\n",
       "    2.0898446827948054,\n",
       "    2.0834017012984405,\n",
       "    2.0640995264657014,\n",
       "    2.06457272116302,\n",
       "    2.0578372110202054,\n",
       "    2.048655678601126,\n",
       "    2.0483349148824415,\n",
       "    2.0405316460179486,\n",
       "    2.036499723720218,\n",
       "    2.0216887935084364,\n",
       "    2.017714322401881,\n",
       "    2.00702090066115,\n",
       "    2.001617901289075,\n",
       "    1.999682174597855,\n",
       "    1.996012660868302,\n",
       "    1.997626743645718,\n",
       "    1.9893852516370698,\n",
       "    1.9808750738651941,\n",
       "    1.9755525248170756,\n",
       "    1.97298727452721],\n",
       "   [3.2430589799622833,\n",
       "    3.1795849220405055,\n",
       "    2.9960446554080167,\n",
       "    2.896202556025481,\n",
       "    2.794514358247005,\n",
       "    2.782499752854145,\n",
       "    2.6890230529259496,\n",
       "    2.5636276470404855,\n",
       "    2.5327135503746563,\n",
       "    2.4790464062067112,\n",
       "    2.470070054416654,\n",
       "    2.447994856404149,\n",
       "    2.3965893757212307,\n",
       "    2.355440403222842,\n",
       "    2.338979499602975,\n",
       "    2.3134980550719155,\n",
       "    2.2909948102933226,\n",
       "    2.2441002218846586,\n",
       "    2.2300110606586774,\n",
       "    2.2177960435832436,\n",
       "    2.1947668303229295,\n",
       "    2.1842116007296637,\n",
       "    2.177778722402898,\n",
       "    2.16675943766552,\n",
       "    2.1553537706295787,\n",
       "    2.148176225625661,\n",
       "    2.1375420769712727,\n",
       "    2.1256723815818304,\n",
       "    2.1199555887674553,\n",
       "    2.115735541352933,\n",
       "    2.1112177658720666,\n",
       "    2.1037146122400276,\n",
       "    2.098522637414519,\n",
       "    2.0856888642641915,\n",
       "    2.077539134150224,\n",
       "    2.068088937069772,\n",
       "    2.063131281821903,\n",
       "    2.0643241642426426,\n",
       "    2.0587593172889043,\n",
       "    2.047049650644615,\n",
       "    2.0464768912685134,\n",
       "    2.036888390546496,\n",
       "    2.023330504154165,\n",
       "    2.0204414680403024,\n",
       "    2.0234757437218405,\n",
       "    2.0056929034821893,\n",
       "    2.0041812927437204,\n",
       "    1.9995336722736412,\n",
       "    1.9903559832421467,\n",
       "    1.9827766018366246]],\n",
       "  'train_loss': [[3.7723823213874574,\n",
       "    3.2552605715821996,\n",
       "    2.9878571766779674,\n",
       "    2.7929164368844286,\n",
       "    2.7148694794043084,\n",
       "    2.7937372669798206,\n",
       "    2.6492244552316278,\n",
       "    2.639386473575569,\n",
       "    2.6161662879087992,\n",
       "    2.486721296903151,\n",
       "    2.5174509052924408,\n",
       "    2.4976258097129547,\n",
       "    2.744589013008322,\n",
       "    2.4371564437124165,\n",
       "    2.426014218663314,\n",
       "    2.4010631826192648,\n",
       "    2.449510290540137,\n",
       "    2.377795490678859,\n",
       "    2.3552720957904665,\n",
       "    2.321800352022877,\n",
       "    2.3100705496632274,\n",
       "    2.3114445697873913,\n",
       "    2.2674267540070883,\n",
       "    2.358510147751887,\n",
       "    2.1874759586966315,\n",
       "    2.204201862683415,\n",
       "    2.3075088623136395,\n",
       "    2.310419892591721,\n",
       "    2.2419959650291696,\n",
       "    2.2231522688131653,\n",
       "    2.1396495473532786,\n",
       "    2.1473098034528855,\n",
       "    2.1197552954355103,\n",
       "    2.0981150879529493,\n",
       "    2.0661276822533416,\n",
       "    2.198639230898608,\n",
       "    2.137159498444246,\n",
       "    2.1177276886707714,\n",
       "    2.094879377688318,\n",
       "    2.1053705050771194,\n",
       "    2.1225656443351513,\n",
       "    2.078379471459827,\n",
       "    2.10047459801138,\n",
       "    2.066809041910663,\n",
       "    2.144137717499131,\n",
       "    2.037577314357493,\n",
       "    2.058349594376081,\n",
       "    2.123797118019808,\n",
       "    2.0123612935077455,\n",
       "    2.034643488021623],\n",
       "   [3.5411432452997564,\n",
       "    3.1619731250939322,\n",
       "    3.067862387415631,\n",
       "    2.958092130518429,\n",
       "    2.814349858141109,\n",
       "    2.7582349136701163,\n",
       "    2.764080592497641,\n",
       "    2.727227530901683,\n",
       "    2.60883108842582,\n",
       "    2.5843138377527657,\n",
       "    2.475229862092251,\n",
       "    2.60862198821258,\n",
       "    2.515281088466732,\n",
       "    2.5694203893522536,\n",
       "    2.3992199836751076,\n",
       "    2.3630168060388175,\n",
       "    2.411659228962232,\n",
       "    2.3869333957886005,\n",
       "    2.2542314449017975,\n",
       "    2.3675594426569804,\n",
       "    2.2735422105852074,\n",
       "    2.2555151211696605,\n",
       "    2.272596418150019,\n",
       "    2.2209896339403943,\n",
       "    2.1908668112031173,\n",
       "    2.243664883921616,\n",
       "    2.1781027020030193,\n",
       "    2.2392103145055993,\n",
       "    2.2281557670742416,\n",
       "    2.1732776413355426,\n",
       "    2.151782714400755,\n",
       "    2.0902992428442912,\n",
       "    2.1447072792855626,\n",
       "    2.1634046870748036,\n",
       "    2.105865296026189,\n",
       "    2.0071701974360687,\n",
       "    2.2250546500397776,\n",
       "    2.1218991054714937,\n",
       "    2.0818298823765686,\n",
       "    2.182505236648072,\n",
       "    2.132759417971146,\n",
       "    2.1550643582317695,\n",
       "    2.0716527940167158,\n",
       "    2.058276893273732,\n",
       "    2.06789739472297,\n",
       "    2.095987485310699,\n",
       "    2.144899221584325,\n",
       "    2.093869415825277,\n",
       "    2.1040837733524134,\n",
       "    2.0569070153891973]]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aSs9xXfpQ3ML"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(path + 'Local_Round_FedMed_1.pkl', 'rb') as file:\n",
    "  log_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N8ep-MalQ3PO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48953659291350765, 0.49222497292279127]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['Shakespeare LSTM on IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_-2I2g0HQ3WA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4310909670748089, 0.4245581143635784]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['Shakespeare LSTM on Non IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfR3lDa7Q-8s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "FederatedAveraging",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "QSGD",
   "language": "python",
   "name": "qsgd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
