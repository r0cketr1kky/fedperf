{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FederatedAveraging",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8771fa3febe485f909e0734d3aa3708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e84175ba2aca4dc8a0fdcea219e04614",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d65c269bf99e4ba68dfbb1b264018e19",
              "IPY_MODEL_57ae00f0cdbd4f00a1a2945f67671747"
            ]
          }
        },
        "e84175ba2aca4dc8a0fdcea219e04614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d65c269bf99e4ba68dfbb1b264018e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a5ade9cbed74b0fb571159ef28e8718",
            "_dom_classes": [],
            "description": " 33%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 9,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9af33d37c9d3452faa1cb5dd809d3dda"
          }
        },
        "57ae00f0cdbd4f00a1a2945f67671747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a02f39379ee14c9ea78d5bfac4a7a2cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/9 [00:11&lt;00:19,  3.29s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6159989bf9942d3b495333793a9af6c"
          }
        },
        "0a5ade9cbed74b0fb571159ef28e8718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9af33d37c9d3452faa1cb5dd809d3dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a02f39379ee14c9ea78d5bfac4a7a2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6159989bf9942d3b495333793a9af6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72d12659f553443197727b77b84fec7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a7bcfb8caf2c46388c6923be55eae2b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f0bcd77e2d1431d9d0becdccd8b0575",
              "IPY_MODEL_530c38a866754525b70209b2fdb8f9ad"
            ]
          }
        },
        "a7bcfb8caf2c46388c6923be55eae2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f0bcd77e2d1431d9d0becdccd8b0575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_323d04e8628940a892efbd701ed878c9",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 9,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79920e9aeea642da9cf0cf7fba5ddf8e"
          }
        },
        "530c38a866754525b70209b2fdb8f9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0acc13e842854dfa8f74f4e056e6efe2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/9 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22e224d8d6bd4aa0b38d5b2681332fa3"
          }
        },
        "323d04e8628940a892efbd701ed878c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79920e9aeea642da9cf0cf7fba5ddf8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0acc13e842854dfa8f74f4e056e6efe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22e224d8d6bd4aa0b38d5b2681332fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tushar-semwal/fedperf/blob/main/Vineeth/Local_Rounds/Shakesphere/FedMed/FederatedMedian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ6Rq0UiG6ev",
        "outputId": "63862fce-a355-40f9-d188-36afc7e9ec8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torchsummaryX unidecode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchsummaryX\n",
            "  Downloading https://files.pythonhosted.org/packages/36/23/87eeaaf70daa61aa21495ece0969c50c446b8fd42c4b8905af264b40fe7f/torchsummaryX-1.3.0-py3-none-any.whl\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 24.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 11.9MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 11.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.1.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.8.1+cu101)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchsummaryX) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Installing collected packages: torchsummaryX, unidecode\n",
            "Successfully installed torchsummaryX-1.3.0 unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKcpjZLrQQJV"
      },
      "source": [
        "%%capture output\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    import os\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/OpenMined/'\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "except:\n",
        "    path = './'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0_nKpfq2h1R"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLLNM9X2JbQ8",
        "outputId": "df795a4d-880f-4781-929d-29cf7f56a720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "import copy\n",
        "from functools import reduce\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import time\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.sampler import Sampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "from torchsummaryX import summary as summaryx\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm.notebook import tqdm\n",
        "from unidecode import unidecode\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Check assigned GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# set manual seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# general reproducibility\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# gpu training specific\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 25 09:47:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY4eWzGiL6Mj"
      },
      "source": [
        "## Load the Shakespeare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf03LRxof7Zj"
      },
      "source": [
        "!rm -Rf data\n",
        "!mkdir -p data scripts"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngygA4-Fgobx"
      },
      "source": [
        "GENERATE_DATASET = False  # If False, download the dataset provided by the q-FFL paper\n",
        "DATA_DIR = 'data/'\n",
        "# Dataset generation params\n",
        "SAMPLES_FRACTION = 1.  # If using an already generated dataset\n",
        "# SAMPLES_FRACTION = 0.2  # Fraction of total samples in the dataset - FedProx default script\n",
        "# SAMPLES_FRACTION = 0.05  # Fraction of total samples in the dataset - qFFL\n",
        "TRAIN_FRACTION = 0.8  # Train set size\n",
        "MIN_SAMPLES = 0  # Min samples per client (for filtering purposes) - FedProx\n",
        "# MIN_SAMPLES = 64  # Min samples per client (for filtering purposes) - qFFL"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUmwJgJygoYD",
        "outputId": "03140f66-f130-4fa0-f5f1-c17651d8b0c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download raw dataset\n",
        "# !wget https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt -O data/shakespeare.txt\n",
        "!wget --adjust-extension http://www.gutenberg.org/files/100/100-0.txt -O data/shakespeare.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-25 09:47:30--  http://www.gutenberg.org/files/100/100-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5757108 (5.5M) [text/plain]\n",
            "Saving to: ‘data/shakespeare.txt’\n",
            "\n",
            "data/shakespeare.tx 100%[===================>]   5.49M  9.83MB/s    in 0.6s    \n",
            "\n",
            "2021-04-25 09:47:31 (9.83 MB/s) - ‘data/shakespeare.txt’ saved [5757108/5757108]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dCvx80BgoVr",
        "outputId": "cac0c52b-914d-45bc-a472-f9d86ddfa211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if not GENERATE_DATASET:\n",
        "    !rm -Rf data/train data/test\n",
        "    !gdown --id 1n46Mftp3_ahRi1Z6jYhEriyLtdRDS1tD  # Download Shakespeare dataset used by the FedProx paper\n",
        "    !unzip shakespeare.zip\n",
        "    !mv -f shakespeare_paper/train data/\n",
        "    !mv -f shakespeare_paper/test data/\n",
        "    !rm -R shakespeare_paper/ shakespeare.zip\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n46Mftp3_ahRi1Z6jYhEriyLtdRDS1tD\n",
            "To: /content/shakespeare.zip\n",
            "\r0.00B [00:00, ?B/s]\r2.96MB [00:00, 94.6MB/s]\n",
            "Archive:  shakespeare.zip\n",
            "   creating: shakespeare_paper/\n",
            "   creating: shakespeare_paper/test/\n",
            "  inflating: shakespeare_paper/test/all_data_niid_2_keep_0_test_8.json  \n",
            "   creating: shakespeare_paper/train/\n",
            "  inflating: shakespeare_paper/train/all_data_niid_2_keep_0_train_8.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4pzFvPvhQhq",
        "outputId": "c26d6ab9-3337-4959-cd95-8e61e7b67e06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpus = []\n",
        "with open('data/shakespeare.txt', 'r') as f:\n",
        "    data = list(unidecode(f.read()))\n",
        "    corpus = list(set(list(data)))\n",
        "print('Corpus Length:', len(corpus))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus Length: 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cce_-qnxhD4n"
      },
      "source": [
        "#### Dataset Preprocessing script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt13M4IcgoTV"
      },
      "source": [
        "%%capture\n",
        "if GENERATE_DATASET:\n",
        "    # Download dataset generation scripts\n",
        "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/preprocess_shakespeare.py -O scripts/preprocess_shakespeare.py\n",
        "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/shake_utils.py -O scripts/shake_utils.py\n",
        "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/gen_all_data.py -O scripts/gen_all_data.py\n",
        "\n",
        "    # Download data preprocessing scripts\n",
        "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/utils/sample.py -O scripts/sample.py\n",
        "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/utils/remove_users.py -O scripts/remove_users.py"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIEyRW27goPo"
      },
      "source": [
        "# Running scripts\n",
        "if GENERATE_DATASET:\n",
        "    !mkdir -p data/raw_data data/all_data data/train data/test\n",
        "    !python scripts/preprocess_shakespeare.py data/shakespeare.txt data/raw_data\n",
        "    !python scripts/gen_all_data.py"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq8V6v_4hhhD"
      },
      "source": [
        "#### Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2SjEBKoWDxv"
      },
      "source": [
        "class ShakespeareDataset(Dataset):\n",
        "    def __init__(self, x, y, corpus, seq_length):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.corpus = corpus\n",
        "        self.corpus_size = len(self.corpus)\n",
        "        super(ShakespeareDataset, self).__init__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__} - (length: {self.__len__()})'\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        input_seq = self.x[i]\n",
        "        next_char = self.y[i]\n",
        "        # print('\\tgetitem', i, input_seq, next_char)\n",
        "        input_value = self.text2charindxs(input_seq)\n",
        "        target_value = self.get_label_from_char(next_char)\n",
        "        return input_value, target_value\n",
        "\n",
        "    def text2charindxs(self, text):\n",
        "        tensor = torch.zeros(len(text), dtype=torch.int32)\n",
        "        for i, c in enumerate(text):\n",
        "            tensor[i] = self.get_label_from_char(c)\n",
        "        return tensor\n",
        "\n",
        "    def get_label_from_char(self, c):\n",
        "        return self.corpus.index(c)\n",
        "\n",
        "    def get_char_from_label(self, l):\n",
        "        return self.corpus[l]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fgJtS62lYAN"
      },
      "source": [
        "##### Federated Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DqL5pTmgn5X"
      },
      "source": [
        "class ShakespeareFedDataset(ShakespeareDataset):\n",
        "    def __init__(self, x, y, corpus, seq_length):\n",
        "        super(ShakespeareFedDataset, self).__init__(x, y, corpus, seq_length)\n",
        "\n",
        "    def dataloader(self, batch_size, shuffle=True):\n",
        "        return DataLoader(self,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          num_workers=0)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XelbyPsDlfgb"
      },
      "source": [
        "## Partitioning & Data Loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOBblyFGlwlU"
      },
      "source": [
        "### IID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSZFWKmsgn1p"
      },
      "source": [
        "def iid_partition_(dataset, clients):\n",
        "  \"\"\"\n",
        "  I.I.D paritioning of data over clients\n",
        "  Shuffle the data\n",
        "  Split it between clients\n",
        "  \n",
        "  params:\n",
        "    - dataset (torch.utils.Dataset): Dataset\n",
        "    - clients (int): Number of Clients to split the data between\n",
        "\n",
        "  returns:\n",
        "    - Dictionary of image indexes for each client\n",
        "  \"\"\"\n",
        "\n",
        "  num_items_per_client = int(len(dataset)/clients)\n",
        "  client_dict = {}\n",
        "  image_idxs = [i for i in range(len(dataset))]\n",
        "\n",
        "  for i in range(clients):\n",
        "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
        "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
        "\n",
        "  return client_dict"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lGwDyhSll9h"
      },
      "source": [
        "def iid_partition(corpus, seq_length=80, val_split=False):\n",
        "\n",
        "    train_file = [os.path.join(DATA_DIR, 'train', f) for f in os.listdir(f'{DATA_DIR}/train') if f.endswith('.json')][0]\n",
        "    test_file = [os.path.join(DATA_DIR, 'test', f) for f in os.listdir(f'{DATA_DIR}/test') if f.endswith('.json')][0]\n",
        "\n",
        "    with open(train_file, 'r') as file:\n",
        "        data_train = json.loads(unidecode(file.read()))\n",
        "\n",
        "    with open(test_file, 'r') as file:\n",
        "        data_test = json.loads(unidecode(file.read()))\n",
        "\n",
        "    \n",
        "    total_samples_train = sum(data_train['num_samples'])\n",
        "\n",
        "    data_dict = {}\n",
        "\n",
        "    x_train, y_train = [], []\n",
        "    x_test, y_test = [], []\n",
        "    # x_val, y_val = [], []\n",
        "\n",
        "    users = list(zip(data_train['users'], data_train['num_samples']))\n",
        "    # random.shuffle(users)\n",
        "\n",
        "\n",
        "\n",
        "    total_samples = int(sum(data_train['num_samples']) * SAMPLES_FRACTION)\n",
        "    print('Objective', total_samples, '/', sum(data_train['num_samples']))\n",
        "    sample_count = 0\n",
        "    \n",
        "    for i, (author_id, samples) in enumerate(users):\n",
        "\n",
        "        if sample_count >= total_samples:\n",
        "            print('Max samples reached', sample_count, '/', total_samples)\n",
        "            break\n",
        "\n",
        "        if samples < MIN_SAMPLES: # or data_train['num_samples'][i] > 10000:\n",
        "            print('SKIP', author_id, samples)\n",
        "            continue\n",
        "        else:\n",
        "            udata_train = data_train['user_data'][author_id]\n",
        "            max_samples = samples if (sample_count + samples) <= total_samples else (sample_count + samples - total_samples) \n",
        "            \n",
        "            sample_count += max_samples\n",
        "            # print('sample_count', sample_count)\n",
        "\n",
        "            x_train.extend(data_train['user_data'][author_id]['x'][:max_samples])\n",
        "            y_train.extend(data_train['user_data'][author_id]['y'][:max_samples])\n",
        "\n",
        "            author_data = data_test['user_data'][author_id]\n",
        "            test_size = int(len(author_data['x']) * SAMPLES_FRACTION)\n",
        "\n",
        "            if val_split:\n",
        "                x_test.extend(author_data['x'][:int(test_size / 2)])\n",
        "                y_test.extend(author_data['y'][:int(test_size / 2)])\n",
        "                # x_val.extend(author_data['x'][int(test_size / 2):])\n",
        "                # y_val.extend(author_data['y'][int(test_size / 2):int(test_size)])\n",
        "\n",
        "            else:\n",
        "                x_test.extend(author_data['x'][:int(test_size)])\n",
        "                y_test.extend(author_data['y'][:int(test_size)])\n",
        "\n",
        "    train_ds = ShakespeareDataset(x_train, y_train, corpus, seq_length)\n",
        "    test_ds = ShakespeareDataset(x_test, y_test, corpus, seq_length)\n",
        "    # val_ds = ShakespeareDataset(x_val, y_val, corpus, seq_length)\n",
        "\n",
        "    data_dict = iid_partition_(train_ds, clients=len(users))\n",
        "\n",
        "    return train_ds, data_dict, test_ds"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFvc8mLoouKa"
      },
      "source": [
        "### Non-IID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ76WsCZot9s"
      },
      "source": [
        "def noniid_partition(corpus, seq_length=80, val_split=False):\n",
        "\n",
        "    train_file = [os.path.join(DATA_DIR, 'train', f) for f in os.listdir(f'{DATA_DIR}/train') if f.endswith('.json')][0]\n",
        "    test_file = [os.path.join(DATA_DIR, 'test', f) for f in os.listdir(f'{DATA_DIR}/test') if f.endswith('.json')][0]\n",
        "\n",
        "    with open(train_file, 'r') as file:\n",
        "        data_train = json.loads(unidecode(file.read()))\n",
        "\n",
        "    with open(test_file, 'r') as file:\n",
        "        data_test = json.loads(unidecode(file.read()))\n",
        "\n",
        "    \n",
        "    total_samples_train = sum(data_train['num_samples'])\n",
        "\n",
        "    data_dict = {}\n",
        "\n",
        "    x_test, y_test = [], []\n",
        "\n",
        "    users = list(zip(data_train['users'], data_train['num_samples']))\n",
        "    # random.shuffle(users)\n",
        "\n",
        "    total_samples = int(sum(data_train['num_samples']) * SAMPLES_FRACTION)\n",
        "    print('Objective', total_samples, '/', sum(data_train['num_samples']))\n",
        "    sample_count = 0\n",
        "    \n",
        "    for i, (author_id, samples) in enumerate(users):\n",
        "\n",
        "        if sample_count >= total_samples:\n",
        "            print('Max samples reached', sample_count, '/', total_samples)\n",
        "            break\n",
        "\n",
        "        if samples < MIN_SAMPLES: # or data_train['num_samples'][i] > 10000:\n",
        "            print('SKIP', author_id, samples)\n",
        "            continue\n",
        "        else:\n",
        "            udata_train = data_train['user_data'][author_id]\n",
        "            max_samples = samples if (sample_count + samples) <= total_samples else (sample_count + samples - total_samples) \n",
        "            \n",
        "            sample_count += max_samples\n",
        "            # print('sample_count', sample_count)\n",
        "\n",
        "            x_train = data_train['user_data'][author_id]['x'][:max_samples]\n",
        "            y_train = data_train['user_data'][author_id]['y'][:max_samples]\n",
        "\n",
        "            train_ds = ShakespeareFedDataset(x_train, y_train, corpus, seq_length)\n",
        "\n",
        "            x_val, y_val = None, None\n",
        "            val_ds = None\n",
        "            author_data = data_test['user_data'][author_id]\n",
        "            test_size = int(len(author_data['x']) * SAMPLES_FRACTION)\n",
        "            if val_split:\n",
        "                x_test += author_data['x'][:int(test_size / 2)]\n",
        "                y_test += author_data['y'][:int(test_size / 2)]\n",
        "                x_val = author_data['x'][int(test_size / 2):]\n",
        "                y_val = author_data['y'][int(test_size / 2):int(test_size)]\n",
        "\n",
        "                val_ds = ShakespeareFedDataset(x_val, y_val, corpus, seq_length)\n",
        "\n",
        "            else:\n",
        "                x_test += author_data['x'][:int(test_size)]\n",
        "                y_test += author_data['y'][:int(test_size)]\n",
        "\n",
        "            data_dict[author_id] = {\n",
        "                'train_ds': train_ds,\n",
        "                'val_ds': val_ds\n",
        "            }\n",
        "\n",
        "    test_ds = ShakespeareFedDataset(x_test, y_test, corpus, seq_length)\n",
        "\n",
        "    return data_dict, test_ds"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWVOxcAao2_t"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQQQ2mLeo6EA"
      },
      "source": [
        "### Shakespeare LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mGXTrXRot7R"
      },
      "source": [
        "class ShakespeareLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, classes, lstm_layers=2, dropout=0.1, batch_first=True):\n",
        "        super(ShakespeareLSTM, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.classes = classes\n",
        "        self.no_layers = lstm_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(num_embeddings=self.classes,\n",
        "                                      embedding_dim=self.embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
        "                            hidden_size=self.hidden_dim,\n",
        "                            num_layers=self.no_layers,\n",
        "                            batch_first=batch_first, \n",
        "                            dropout=dropout if self.no_layers > 1 else 0.)\n",
        "        self.fc = nn.Linear(hidden_dim, self.classes)\n",
        "\n",
        "    def forward(self, x, hc=None):\n",
        "        batch_size = x.size(0)\n",
        "        x_emb = self.embedding(x)\n",
        "        self.lstm.flatten_parameters()\n",
        "        out, (ht, ct) = self.lstm(x_emb.view(batch_size, -1, self.embedding_dim), hc)\n",
        "        dense = self.fc(ht[-1])\n",
        "        return dense\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        return (Variable(torch.zeros(self.no_layers, batch_size, self.hidden_dim)),\n",
        "                Variable(torch.zeros(self.no_layers, batch_size, self.hidden_dim)))\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QsuJlVipMc8"
      },
      "source": [
        "#### Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Vb0BYpot5I",
        "outputId": "9e156d72-d9a5-4bae-cac4-fdacc03219cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 10\n",
        "seq_length = 80 # mcmahan17a, fedprox, qFFL\n",
        "\n",
        "shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,  \n",
        "                                   embedding_dim=8,  # mcmahan17a, fedprox, qFFL\n",
        "                                   hidden_dim=256,  # mcmahan17a, fedprox impl\n",
        "                                   # hidden_dim=100,  # fedprox paper\n",
        "                                   classes=len(corpus),\n",
        "                                   lstm_layers=2,\n",
        "                                   dropout=0.1,\n",
        "                                   batch_first=True\n",
        "                                   )\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  shakespeare_lstm.cuda()\n",
        "\n",
        "hc = shakespeare_lstm.init_hidden(batch_size)\n",
        "\n",
        "x_sample = torch.zeros((batch_size, seq_length),\n",
        "                       dtype=torch.long,\n",
        "                       device=(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')))\n",
        "\n",
        "x_sample[0][0] = 1\n",
        "x_sample\n",
        "\n",
        "print(\"\\nShakespeare LSTM SUMMARY\")\n",
        "print(summaryx(shakespeare_lstm, x_sample))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Shakespeare LSTM SUMMARY\n",
            "==========================================================\n",
            "            Kernel Shape   Output Shape  Params  Mult-Adds\n",
            "Layer                                                     \n",
            "0_embedding      [8, 90]    [10, 80, 8]     720        720\n",
            "1_lstm                 -  [10, 80, 256]  798720     794624\n",
            "2_fc           [256, 90]       [10, 90]   23130      23040\n",
            "----------------------------------------------------------\n",
            "                      Totals\n",
            "Total params          822570\n",
            "Trainable params      822570\n",
            "Non-trainable params       0\n",
            "Mult-Adds             818384\n",
            "==========================================================\n",
            "            Kernel Shape   Output Shape  Params  Mult-Adds\n",
            "Layer                                                     \n",
            "0_embedding      [8, 90]    [10, 80, 8]     720        720\n",
            "1_lstm                 -  [10, 80, 256]  798720     794624\n",
            "2_fc           [256, 90]       [10, 90]   23130      23040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn7egnzTpeks"
      },
      "source": [
        "## FedAvg Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFFAfTOwpk4j"
      },
      "source": [
        "### Plot Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyYjWa6IpnTY"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "367THsiTpo-C"
      },
      "source": [
        "def plot_scores(history, exp_id, title, suffix):\n",
        "    accuracies = [x['accuracy'] for x in history]\n",
        "    f1_macro = [x['f1_macro'] for x in history]\n",
        "    f1_weighted = [x['f1_weighted'] for x in history]\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(accuracies, 'tab:orange')\n",
        "    ax.set(xlabel='Rounds', ylabel='Test Accuracy', title=title)\n",
        "    ax.grid()\n",
        "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_Accuracy_{suffix}.jpg', format='jpg', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(f1_macro, 'tab:orange')\n",
        "    ax.set(xlabel='Rounds', ylabel='Test F1 (macro)', title=title)\n",
        "    ax.grid()\n",
        "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_F1_Macro_{suffix}.jpg', format='jpg')\n",
        "    plt.show()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(f1_weighted, 'tab:orange')\n",
        "    ax.set(xlabel='Rounds', ylabel='Test F1 (weighted)', title=title)\n",
        "    ax.grid()\n",
        "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_F1_Weighted_{suffix}.jpg', format='jpg')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_losses(history, exp_id, title, suffix):\n",
        "    val_losses = [x['loss'] for x in history]\n",
        "    train_losses = [x['train_loss'] for x in history]\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(train_losses, 'tab:orange')\n",
        "    ax.set(xlabel='Rounds', ylabel='Train Loss', title=title)\n",
        "    ax.grid()\n",
        "    fig.savefig(f'{BASE_DIR}/{exp_id}/Train_Loss_{suffix}.jpg', format='jpg')\n",
        "    plt.show()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(val_losses, 'tab:orange')\n",
        "    ax.set(xlabel='Rounds', ylabel='Test Loss', title=title)\n",
        "    ax.grid()\n",
        "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_Loss_{suffix}.jpg', format='jpg')\n",
        "    plt.show()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ9PZM0Gp9ve"
      },
      "source": [
        "### Local Training (Client Update)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDJFltwdotzZ"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataset, idxs):\n",
        "      self.dataset = dataset\n",
        "      self.idxs = list(idxs)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.idxs)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "      data, label = self.dataset[self.idxs[item]]\n",
        "      return data, label"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtRzU5Yepddq"
      },
      "source": [
        "class ClientUpdate(object):\n",
        "  def __init__(self, dataset, batchSize, learning_rate, epochs, idxs):\n",
        "    # self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batchSize, shuffle=True)\n",
        "    if hasattr(dataset, 'dataloader'):\n",
        "        self.train_loader = dataset.dataloader(batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "  def train(self, model):\n",
        "    # print(\"Client training for {} epochs.\".format(self.epochs))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.5)\n",
        "\n",
        "    # use the weights of global model for proximal term calculation\n",
        "    global_model = copy.deepcopy(model)\n",
        "\n",
        "    # calculate local training time\n",
        "    start_time = time.time()\n",
        "\n",
        "    e_loss = []\n",
        "    for epoch in range(1, self.epochs+1):\n",
        "\n",
        "      train_loss = 0.0\n",
        "      model.train()\n",
        "      for data, labels in self.train_loader:\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          data, labels = data.cuda(), labels.cuda()\n",
        "\n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        # make a forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        # do a backwards pass\n",
        "        loss.backward()\n",
        "        # perform a single optimization step\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "      # average losses\n",
        "      train_loss = train_loss/len(self.train_loader.dataset)\n",
        "      e_loss.append(train_loss)\n",
        "\n",
        "    total_loss = sum(e_loss)/len(e_loss)\n",
        "\n",
        "    return model.state_dict(), total_loss"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3crFDN0xqGu6"
      },
      "source": [
        "### Server Side Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c085xSOoqEHk"
      },
      "source": [
        "def training(model, rounds, batch_size, lr, ds, data_dict, test_ds, C, K, E, M, plt_title, plt_color, classes, eval_every=1, tb_logger=None):\n",
        "  \"\"\"\n",
        "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
        "  Specifically, this function is used for the server side training and weight update\n",
        "\n",
        "  Params:\n",
        "    - model:           PyTorch model to train\n",
        "    - rounds:          Number of communication rounds for the client update\n",
        "    - batch_size:      Batch size for client update training\n",
        "    - lr:              Learning rate used for client update training\n",
        "    - ds:              Dataset used for training\n",
        "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
        "    - test_data_dict:  Data used for testing the model\n",
        "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
        "    - K:               Total number of clients\n",
        "    - E:               Number of training passes each client makes over its local dataset per round\n",
        "    - mu:              proximal term constant\n",
        "    - percentage:      percentage of selected client to have fewer than E epochs\n",
        "  Returns:\n",
        "    - model:           Trained model on the server\n",
        "  \"\"\"\n",
        "\n",
        "  # global model weights\n",
        "  global_weights = model.state_dict()\n",
        "\n",
        "  # training loss\n",
        "  train_loss = []\n",
        "\n",
        "  # test accuracy\n",
        "  test_accuracy = []\n",
        "\n",
        "  # test loss\n",
        "  test_loss = []\n",
        "\n",
        "  # history\n",
        "  history=[]\n",
        "\n",
        "  # store last loss for convergence\n",
        "  last_loss = 0.0\n",
        "\n",
        "  # total time taken \n",
        "  total_time = 0\n",
        "  start = time.time()\n",
        "\n",
        "\n",
        "  users_id = list(data_dict.keys())\n",
        "\n",
        "  for curr_round in range(1, rounds+1):\n",
        "    w, local_loss = [], []\n",
        "\n",
        "    m = max(int(C*K), 1)\n",
        "    newM = max(int(M*m), 1)\n",
        "\n",
        "    c = 0\n",
        "    S_t = np.random.choice(range(K), m, replace=False)\n",
        "    print('Clients: {}/{} -> {}'.format(len(S_t), K, S_t))\n",
        "\n",
        "    # for i in tqdm(range(len(S_t))):\n",
        "    for i in range(len(S_t)):\n",
        "      if c == newM:\n",
        "        break\n",
        "      c += 1\n",
        "\n",
        "      k = S_t[i]\n",
        "      key = users_id[k]\n",
        "      ds_ = ds if ds else data_dict[key]['train_ds']\n",
        "      idxs = data_dict[key] if ds else None\n",
        "      print(f'Client {k}: {len(idxs) if idxs else len(ds_)} samples')\n",
        "      local_update = ClientUpdate(dataset=ds_, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=idxs)\n",
        "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
        "\n",
        "      for k in weights.keys():\n",
        "        t = torch.Tensor(weights[k].shape).cuda()\n",
        "        t.fill_(0.1)\n",
        "        weights[k] = t\n",
        "\n",
        "      w.append(copy.deepcopy(weights))\n",
        "      local_loss.append(copy.deepcopy(loss))\n",
        "\n",
        "    for i in tqdm(range(newM, len(S_t))):\n",
        "      k = S_t[i]\n",
        "      key = users_id[k]\n",
        "      ds_ = ds if ds else data_dict[key]['train_ds']\n",
        "      idxs = data_dict[key] if ds else None\n",
        "      print(ds_)\n",
        "      print(idxs)\n",
        "      print(f'Client {k}: {len(idxs) if idxs else len(ds_)} samples')\n",
        "      local_update = ClientUpdate(dataset=ds, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=idxs)\n",
        "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
        "      \n",
        "      w.append(copy.deepcopy(weights))\n",
        "      local_loss.append(copy.deepcopy(loss))\n",
        "      \n",
        "    # calculate time to update the global weights\n",
        "    global_start_time = time.time()\n",
        "\n",
        "    # updating the global weights\n",
        "    target = copy.deepcopy(w[0]);\n",
        "    weights_med = copy.deepcopy(w[0]);\n",
        "    for k in weights_med.keys():\n",
        "      tmp = copy.deepcopy(torch.median(torch.stack([w[i][k].data for i in range(0, len(w))]), dim=0))[0]\n",
        "      target[k].data = tmp\n",
        "\n",
        "    global_weights = target\n",
        "    global_end_time = time.time()\n",
        "\n",
        "    # move the updated weights to our model state dict\n",
        "    model.load_state_dict(global_weights)\n",
        "\n",
        "    # loss\n",
        "    loss_avg = sum(local_loss) / len(local_loss)\n",
        "    print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)))\n",
        "    train_loss.append(loss_avg)\n",
        "    if tb_logger:\n",
        "        tb_logger.add_scalar(f'Train/Loss', loss_avg, curr_round)\n",
        "\n",
        "    # testing\n",
        "    # if curr_round % eval_every == 0:\n",
        "    test_scores = testing(model, test_ds, batch_size * 2, nn.CrossEntropyLoss(), len(classes), classes)\n",
        "    test_scores['train_loss'] = loss_avg\n",
        "    test_loss_current, test_accuracy_current = test_scores['loss'], test_scores['accuracy']\n",
        "\n",
        "    history.append(test_scores)\n",
        "    test_accuracy.append(test_accuracy_current)\n",
        "    test_loss.append(test_loss_current)\n",
        "    \n",
        "    # print('Round: {}... \\tAverage Loss: {} \\tTest Loss: {} \\tTest Acc: {}'.format(curr_round, round(loss_avg, 3), round(test_loss, 3), round(test_accuracy, 3)))\n",
        "\n",
        "    if tb_logger:\n",
        "        tb_logger.add_scalar(f'Test/Loss', test_scores['loss'], curr_round)\n",
        "        tb_logger.add_scalars(f'Test/Scores', {\n",
        "            'accuracy': test_scores['accuracy'], 'f1_macro': test_scores['f1_macro'], 'f1_weighted': test_scores['f1_weighted']\n",
        "        }, curr_round)\n",
        "    \n",
        "    # update the last loss\n",
        "    last_loss = loss_avg\n",
        "\n",
        "  end = time.time()\n",
        "  \n",
        "  # plot train loss\n",
        "  fig, ax = plt.subplots()\n",
        "  x_axis = np.arange(1, rounds+1)\n",
        "  y_axis = np.array(train_loss)\n",
        "  ax.plot(x_axis, y_axis)\n",
        "\n",
        "  ax.set(xlabel='Number of Rounds', ylabel='Train Loss', title=plt_title)\n",
        "  ax.grid()\n",
        "  fig.savefig(plt_title+'_Train_loss.jpg', format='jpg')\n",
        "  plt.show()\n",
        "  \n",
        "  fig, ax = plt.subplots()\n",
        "  x_axis = np.arange(1, rounds+1)\n",
        "  y_axis = np.array(test_loss)\n",
        "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
        "\n",
        "  ax.set(xlabel='Number of Rounds', ylabel='Test Loss',\n",
        "       title=plt_title)\n",
        "  ax.grid()\n",
        "  fig.savefig(plt_title+'_Test_loss.jpg', format='jpg')\n",
        "  plt.show()\n",
        "\n",
        "  # plot test accuracy\n",
        "  fig, ax = plt.subplots()\n",
        "  x_axis = np.arange(1, rounds+1)\n",
        "  y_axis = np.array(test_accuracy)\n",
        "  ax.plot(x_axis, y_axis)\n",
        "\n",
        "  ax.set(xlabel='Number of Rounds', ylabel='Test Accuracy', title=plt_title)\n",
        "  ax.grid()\n",
        "  fig.savefig(plt_title+'_Test_Accuracy.jpg', format='jpg')\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Training Done! Total time taken to Train: {}\".format(end-start))\n",
        "\n",
        "  return model, train_loss, test_accuracy, test_loss, history"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXtGLkoAqLIW"
      },
      "source": [
        "### Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQJIJno4qKvc"
      },
      "source": [
        "def testing(model, dataset, bs, criterion, num_classes, classes, print_all=False):\n",
        "  #test loss \n",
        "  test_loss = 0.0\n",
        "  correct_class = list(0. for i in range(num_classes))\n",
        "  total_class = list(0. for i in range(num_classes))\n",
        "\n",
        "  test_loader = DataLoader(dataset, batch_size=bs)\n",
        "  l = len(test_loader)\n",
        "  model.eval()\n",
        "  print('running validation...')\n",
        "  for i, (data, labels) in enumerate(tqdm(test_loader)):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      data, labels = data.cuda(), labels.cuda()\n",
        "\n",
        "    output = model(data)\n",
        "    loss = criterion(output, labels)\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    # For F1Score\n",
        "    y_true = np.append(y_true, labels.data.view_as(pred).cpu().numpy()) if i != 0 else labels.data.view_as(pred).cpu().numpy()\n",
        "    y_hat = np.append(y_hat, pred.cpu().numpy()) if i != 0 else pred.cpu().numpy()\n",
        "\n",
        "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
        "\n",
        "    for i, lbl in enumerate(labels.data):\n",
        "    #   print('lbl', i, lbl)\n",
        "      correct_class[lbl] += correct.data[i]\n",
        "      total_class[lbl] += 1\n",
        "    \n",
        "  # avg test loss\n",
        "  test_loss = test_loss/len(test_loader.dataset)\n",
        "  print(\"Test Loss: {:.6f}\\n\".format(test_loss))\n",
        "\n",
        "  # Avg F1 Score\n",
        "  f1_macro = f1_score(y_true, y_hat, average='macro')\n",
        "  # F1-Score -> weigthed to consider class imbalance\n",
        "  f1_weighted =  f1_score(y_true, y_hat, average='weighted')\n",
        "  print(\"F1 Score: {:.6f} (macro) {:.6f} (weighted) %\\n\".format(f1_macro, f1_weighted))\n",
        "\n",
        "  # print test accuracy\n",
        "  if print_all:\n",
        "    for i in range(num_classes):\n",
        "        if total_class[i]>0:\n",
        "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % \n",
        "                    (classes[i], 100 * correct_class[i] / total_class[i],\n",
        "                    np.sum(correct_class[i]), np.sum(total_class[i])))\n",
        "        else:\n",
        "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "  overall_accuracy = np.sum(correct_class) / np.sum(total_class)\n",
        "\n",
        "  print('\\nFinal Test  Accuracy: {:.3f} ({}/{})'.format(overall_accuracy, np.sum(correct_class), np.sum(total_class)))\n",
        "\n",
        "  return {'loss': test_loss, 'accuracy': overall_accuracy, 'f1_macro': f1_macro, 'f1_weighted': f1_weighted}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxqXLBd8qbC2"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8gl5P3SMq4a"
      },
      "source": [
        "log_dict = {}\n",
        "NUM_REPEAT = 2"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2CfSkNVqKtL"
      },
      "source": [
        "seq_length = 80  # mcmahan17a, fedprox, qFFL\n",
        "embedding_dim = 8  # mcmahan17a, fedprox, qFFL\n",
        "# hidden_dim = 100  # fedprox paper\n",
        "hidden_dim = 256  # mcmahan17a, fedprox impl\n",
        "num_classes = len(corpus)\n",
        "classes = list(range(num_classes))\n",
        "lstm_layers = 2  # mcmahan17a, fedprox, qFFL\n",
        "dropout = 0.1  # TODO"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPIpStyNJ-63"
      },
      "source": [
        "## LSTM FedMed on IID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpS1gyJ_H_MA",
        "outputId": "c5045073-f07f-4f0f-de4b-3e221f0ca9d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_ds, data_dict, test_ds = iid_partition(corpus, seq_length, val_split=True)  # Not using val_ds but makes train eval periods faster\n",
        "\n",
        "total_clients = len(data_dict.keys())\n",
        "'Total users:', total_clients"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Objective 413629 / 413629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Total users:', 143)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYoGsy05H_RC",
        "outputId": "54c96cef-a5dc-4566-eb35-82c51df0ae08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692,
          "referenced_widgets": [
            "f8771fa3febe485f909e0734d3aa3708",
            "e84175ba2aca4dc8a0fdcea219e04614",
            "d65c269bf99e4ba68dfbb1b264018e19",
            "57ae00f0cdbd4f00a1a2945f67671747",
            "0a5ade9cbed74b0fb571159ef28e8718",
            "9af33d37c9d3452faa1cb5dd809d3dda",
            "a02f39379ee14c9ea78d5bfac4a7a2cb",
            "c6159989bf9942d3b495333793a9af6c"
          ]
        }
      },
      "source": [
        "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
        "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
        "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
        "\n",
        "for exp_num in range(NUM_REPEAT):\n",
        "  print(\"Experiment Run Number: \", exp_num)\n",
        "\n",
        "  # partition data\n",
        "  train_ds, data_dict, test_ds = iid_partition(corpus, seq_length, val_split=True)  # Not using val_ds but makes train eval periods faster\n",
        "  total_clients = len(data_dict.keys())\n",
        "  # number of training rounds\n",
        "  rounds = 2\n",
        "  # client fraction\n",
        "  C = 0.07  # 10 clients\n",
        "  # number of clients\n",
        "  K = total_clients\n",
        "  # number of training passes on local dataset for each roung\n",
        "  E = 1\n",
        "  # batch size\n",
        "  batch_size = 10\n",
        "  # learning Rate\n",
        "  lr = 0.8\n",
        "  # proximal term constant\n",
        "  M = 0.01\n",
        "\n",
        "  shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,  \n",
        "                                    embedding_dim=embedding_dim,  \n",
        "                                    hidden_dim=hidden_dim,\n",
        "                                    classes=num_classes,\n",
        "                                    lstm_layers=lstm_layers,\n",
        "                                    dropout=dropout,\n",
        "                                    batch_first=True\n",
        "                                    )\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      shakespeare_lstm.cuda()\n",
        "\n",
        "  lstm_iid_trained, train_loss, test_accuracy, test_loss, history = training(shakespeare_lstm,\n",
        "                                          rounds, batch_size, lr,\n",
        "                                          train_ds,\n",
        "                                          data_dict,\n",
        "                                          test_ds,\n",
        "                                          C, K, E, M,\n",
        "                                          'Shakespeare LSTM on IID', \"green\",\n",
        "                                          corpus, # classes\n",
        "                                          )\n",
        "\n",
        "  train_loss_multiple_runs[exp_num] = train_loss\n",
        "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
        "  test_loss_multiple_runs[exp_num] = test_loss\n",
        "\n",
        "  del lstm_iid_trained\n",
        "  torch.cuda.empty_cache()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment Run Number:  0\n",
            "Objective 413629 / 413629\n",
            "Clients: 10/143 -> [ 18  93  88 100 116  35 126  77 112  24]\n",
            "Client 18: 2892 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8771fa3febe485f909e0734d3aa3708",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.ShakespeareDataset'> - (length: 413629)\n",
            "{360449, 253953, 49164, 221202, 172052, 294934, 368663, 327708, 73756, 229410, 8226, 409643, 229420, 196653, 188461, 335916, 73772, 180269, 368703, 41026, 221250, 65606, 24665, 147545, 98395, 245853, 385129, 376941, 172144, 106612, 57464, 114808, 180346, 131199, 368768, 303233, 270464, 131201, 16517, 311435, 368784, 311450, 8348, 90269, 139425, 237731, 319661, 327856, 180401, 336050, 114870, 377016, 327869, 190, 24769, 409794, 180421, 198, 245957, 344265, 123085, 147662, 41165, 327890, 360659, 278739, 360661, 360663, 344289, 32994, 41186, 368874, 262387, 246003, 319733, 205046, 139510, 196859, 82172, 385279, 385285, 172296, 73993, 311569, 311579, 205086, 311582, 327968, 270629, 41254, 65832, 16685, 336175, 164144, 196913, 409911, 385341, 180543, 106818, 98628, 287044, 82250, 352587, 262481, 65877, 16734, 65890, 401764, 82277, 311653, 115051, 409963, 156016, 123254, 24950, 409980, 16764, 254333, 287103, 254338, 147843, 396, 106899, 311702, 352675, 25000, 369072, 25008, 437, 328119, 115132, 254397, 352712, 205259, 254416, 221654, 360920, 311769, 90587, 344540, 123357, 156124, 82399, 131549, 74211, 360941, 221680, 311796, 164347, 352764, 123389, 49663, 188928, 238081, 393728, 156165, 328201, 33294, 262674, 295446, 352791, 8726, 131614, 254497, 197156, 115238, 164399, 66099, 131638, 25148, 205372, 188988, 320063, 311880, 303690, 123467, 377420, 254543, 205397, 352858, 295520, 344674, 197221, 33382, 616, 254569, 238185, 344682, 621, 131695, 189041, 238194, 402033, 352889, 344701, 221822, 189063, 246407, 393865, 393869, 279182, 156302, 74386, 90776, 393882, 352927, 238242, 675, 49829, 336556, 303789, 148141, 107184, 164536, 352957, 320190, 402116, 402117, 131783, 716, 328398, 180944, 246484, 303836, 213726, 279263, 312033, 393954, 189157, 295655, 148199, 123626, 115434, 172781, 131828, 33526, 90871, 230138, 328443, 107260, 262912, 164609, 213761, 180996, 361221, 312070, 246533, 246539, 82701, 271118, 140048, 221975, 17176, 197405, 172830, 377633, 213795, 74533, 99113, 172845, 336687, 172850, 25394, 353078, 361271, 9016, 189241, 377657, 328505, 303930, 238398, 156480, 49987, 90947, 107332, 839, 295752, 336713, 279371, 131917, 344910, 295765, 74585, 295769, 33625, 181086, 410463, 156515, 41838, 254834, 369527, 156536, 172920, 377722, 140156, 385916, 246654, 896, 148355, 25476, 410502, 230279, 197518, 312207, 912, 181138, 287634, 344981, 33687, 41879, 41881, 99224, 172956, 50082, 107428, 385957, 66472, 263081, 66479, 345009, 197553, 17329, 9140, 181173, 279478, 328636, 410559, 336833, 82882, 385994, 9165, 164816, 369624, 156635, 181214, 123875, 123877, 17387, 254955, 369650, 377845, 402422, 123901, 263168, 1031, 328713, 25618, 369683, 181275, 320539, 42016, 17447, 99369, 255024, 42038, 156728, 271416, 279609, 328763, 353340, 287805, 377916, 255037, 222272, 140353, 246842, 132163, 205892, 205893, 205891, 164935, 263235, 83021, 328782, 173133, 189520, 99412, 140373, 66646, 377941, 99418, 296028, 9312, 25698, 42083, 33892, 173156, 156777, 353388, 132204, 9332, 230524, 361596, 312446, 181377, 246914, 255107, 164999, 328843, 205966, 1168, 58516, 320660, 132246, 205977, 386202, 132251, 361630, 83102, 74913, 50339, 214183, 17577, 33973, 50367, 91329, 83138, 42179, 361668, 255173, 222405, 181447, 345288, 312521, 337100, 369870, 1231, 189648, 402655, 378079, 386274, 165092, 386286, 189679, 181489, 378101, 214261, 34041, 189691, 271612, 296197, 9479, 9480, 140554, 99594, 386316, 394506, 394515, 263443, 320789, 25876, 197913, 58651, 206107, 238883, 58660, 197929, 247082, 173357, 132400, 50481, 214322, 91443, 189751, 230712, 124217, 369985, 25922, 91459, 50503, 345418, 50508, 83280, 132436, 345430, 206169, 165209, 320859, 329054, 410974, 116068, 165220, 370027, 9583, 230774, 296311, 386423, 91511, 345467, 238979, 189831, 173452, 402830, 83344, 312729, 271774, 165292, 296368, 337331, 402867, 345533, 9662, 271809, 17860, 198085, 312782, 353742, 58835, 255449, 353758, 402916, 58853, 34284, 280046, 173551, 83440, 304624, 26098, 255476, 386549, 271862, 239095, 50679, 361985, 181767, 361992, 75279, 165394, 132627, 394775, 157208, 280088, 67099, 99872, 42528, 345644, 157228, 296493, 157231, 239152, 190002, 75318, 26167, 321085, 165438, 353853, 1600, 247361, 58949, 17993, 304714, 83531, 312912, 99925, 214614, 83546, 403034, 353887, 378465, 124517, 34405, 247399, 206440, 132716, 190066, 173683, 386676, 271992, 411260, 26237, 255616, 132739, 411270, 345737, 329366, 394904, 67226, 18077, 124576, 378535, 247463, 321193, 157358, 132782, 198323, 272052, 321204, 329400, 83641, 239306, 34511, 26329, 247516, 165597, 206556, 59101, 280289, 26341, 362219, 231147, 329451, 214770, 288502, 403194, 247552, 157440, 141058, 1795, 91913, 83723, 280331, 26380, 50959, 304919, 59162, 141083, 223003, 100123, 18206, 26399, 223007, 42785, 50978, 378656, 272164, 321317, 395046, 280359, 1829, 378667, 255790, 157488, 403255, 231224, 165687, 378681, 272188, 370492, 1857, 370502, 59209, 255823, 1871, 190292, 264022, 173917, 329569, 345959, 354152, 59245, 198513, 26487, 92024, 18297, 264058, 411522, 296841, 264076, 133011, 272278, 59286, 165782, 165788, 329629, 42910, 280481, 75684, 378792, 313263, 42930, 198580, 75701, 206774, 75709, 247745, 231364, 305101, 75727, 108497, 108499, 190420, 67544, 51161, 116698, 83928, 124892, 378845, 133086, 149467, 59363, 247780, 190437, 42982, 239589, 313319, 264176, 149489, 231410, 264179, 354292, 198645, 411637, 370679, 124923, 116731, 231424, 247808, 354307, 43012, 108548, 280583, 149511, 264199, 354317, 34831, 198676, 116760, 59416, 313371, 395294, 174112, 346144, 18467, 43046, 346151, 2087, 67625, 239658, 346150, 395308, 157745, 182325, 256054, 272438, 223290, 108608, 329793, 387140, 346180, 215108, 75849, 133206, 239703, 165977, 297052, 190564, 133222, 34920, 51306, 2154, 313460, 305268, 239734, 182390, 239739, 182396, 34946, 182404, 34949, 34954, 34960, 133265, 43155, 313492, 387226, 354459, 59553, 174241, 247971, 10401, 174243, 92327, 395432, 387243, 395438, 403630, 321710, 10416, 403634, 10422, 256183, 362680, 346298, 305339, 26814, 174274, 215235, 125126, 190662, 125128, 313548, 190672, 198868, 26840, 338138, 313564, 313576, 116971, 100589, 133357, 51440, 125171, 67833, 280827, 321787, 157952, 157963, 387343, 100624, 321811, 370964, 362774, 305433, 125211, 141600, 239913, 280874, 256301, 158002, 182581, 117046, 92480, 207170, 379208, 174413, 117073, 239955, 264532, 403796, 182611, 239961, 256346, 166236, 199010, 321890, 395621, 321894, 354664, 26985, 117106, 403831, 141692, 199037, 59777, 2434, 100737, 133507, 395653, 174472, 108938, 297355, 330127, 305552, 223634, 51603, 338323, 166292, 2456, 100761, 67994, 207258, 27033, 248218, 330142, 215475, 321974, 338361, 256444, 403902, 100801, 215489, 27077, 149973, 100822, 199126, 338394, 403930, 412126, 330213, 322024, 125423, 2547, 248308, 272884, 412150, 92662, 322040, 51711, 322048, 174591, 322050, 240137, 150029, 133648, 2577, 412183, 174615, 141854, 289315, 18984, 371240, 395822, 125488, 346675, 395832, 141890, 2633, 76362, 76365, 289359, 92756, 412249, 387674, 354916, 150119, 289384, 182889, 166506, 354926, 240242, 379507, 395890, 313973, 387698, 191095, 363131, 404093, 215681, 51843, 166533, 289414, 248456, 35465, 101002, 354955, 289437, 2718, 314015, 322208, 51873, 346792, 371372, 379570, 256691, 232115, 84664, 379577, 109244, 232127, 158399, 2756, 264901, 379592, 289487, 76497, 207572, 346836, 60124, 387804, 256735, 68320, 223970, 35556, 346852, 352251, 92903, 142061, 297711, 51961, 19196, 11004, 330496, 109312, 117508, 396040, 27403, 404236, 109328, 150299, 412445, 43806, 150303, 404256, 305953, 133920, 305949, 166702, 27440, 92980, 158517, 355128, 60217, 256830, 314181, 297797, 338760, 68425, 305992, 183127, 330588, 371554, 11112, 215916, 150381, 289647, 43888, 191349, 289658, 93052, 347009, 93057, 297864, 289673, 134027, 387979, 84877, 142222, 297871, 306063, 125847, 232347, 387999, 371620, 166822, 150439, 2985, 117677, 175021, 281520, 371636, 404405, 256952, 60351, 412611, 388036, 281549, 265167, 289744, 338897, 388054, 289760, 150498, 76776, 347112, 257006, 125937, 76786, 388082, 109560, 191497, 142346, 166925, 322573, 101397, 265237, 52248, 134170, 396320, 314400, 3106, 404513, 338980, 109605, 109606, 175141, 158761, 27699, 330806, 35897, 412732, 11327, 52294, 117831, 248907, 306255, 412752, 298072, 175198, 314463, 19552, 265313, 19551, 216172, 330866, 371829, 126070, 93304, 314488, 363645, 3201, 191623, 76936, 109706, 19596, 257164, 109708, 142479, 19601, 248978, 314515, 265367, 191646, 11425, 109732, 199846, 388262, 224424, 388267, 306355, 36023, 216248, 199868, 232636, 109759, 150722, 134341, 257222, 134346, 281804, 347341, 191698, 183510, 249052, 175329, 371938, 388323, 167137, 52456, 232682, 52464, 175345, 322801, 339188, 224503, 175354, 331002, 224509, 371966, 224512, 396548, 208134, 158984, 167177, 208138, 85258, 183565, 44304, 167184, 158995, 52500, 249108, 273684, 281879, 298267, 281886, 126243, 257316, 142628, 93478, 257323, 355632, 388404, 216374, 273720, 191801, 11577, 322879, 27970, 355651, 183618, 265539, 404807, 396622, 314702, 273745, 175446, 208217, 44381, 109918, 175454, 200033, 134500, 363877, 142695, 175469, 396655, 60790, 224636, 85372, 44416, 167300, 159111, 77195, 77196, 232843, 52627, 404883, 322966, 241049, 241050, 306586, 191902, 298401, 413089, 191907, 388516, 355747, 339366, 224680, 339369, 282028, 60848, 339377, 191920, 93619, 282038, 372151, 118198, 126394, 175546, 347581, 298430, 175550, 404928, 257473, 208322, 339396, 93637, 110022, 175557, 85449, 331216, 413136, 306650, 323036, 11741, 404958, 224735, 69087, 126431, 290268, 232931, 339424, 60892, 388583, 404969, 241134, 52726, 44542, 52739, 314887, 413196, 192015, 298519, 355864, 44568, 110108, 192031, 200228, 44587, 331309, 110129, 151090, 36402, 101940, 413238, 85560, 413247, 314943, 396865, 118335, 93764, 134732, 355922, 290390, 110169, 396891, 380508, 151134, 306783, 183904, 159329, 298591, 52841, 216683, 274028, 183916, 28269, 388720, 364149, 396923, 85628, 380540, 413312, 257664, 93825, 306824, 85651, 257685, 380568, 208552, 77482, 175790, 61103, 118449, 192177, 134835, 282295, 249528, 298680, 356028, 36544, 380613, 364231, 265928, 44744, 265934, 192210, 184020, 200412, 339680, 175842, 282339, 184036, 249573, 380646, 233192, 175851, 3822, 3823, 61167, 126709, 388857, 405242, 184061, 61182, 405248, 175872, 77571, 265992, 249609, 159497, 192267, 298764, 93968, 3857, 143121, 159507, 3859, 347925, 233239, 167704, 12058, 257819, 266012, 257822, 110367, 274208, 339745, 306981, 372519, 44843, 413483, 397100, 347947, 167730, 44851, 257848, 397115, 216893, 315199, 397121, 151362, 143171, 339780, 290631, 61257, 216908, 167758, 94037, 20311, 77657, 347995, 266076, 339805, 388971, 126829, 28527, 135027, 397173, 118649, 3962, 61312, 61313, 266116, 405382, 102279, 192393, 192401, 3990, 151449, 290715, 356253, 372639, 225188, 126887, 339879, 364457, 348080, 110517, 143290, 85947, 339899, 348095, 53184, 102339, 298957, 208852, 323542, 45022, 208862, 233440, 266210, 393211, 184298, 298986, 45037, 135153, 225267, 36852, 200694, 4097, 176135, 364552, 217096, 69647, 225296, 110610, 323605, 258071, 348184, 77849, 159770, 159779, 282664, 405548, 94256, 364593, 118836, 389178, 233531, 241726, 184383, 184384, 77890, 274499, 233545, 307276, 135253, 151643, 151645, 340064, 233572, 266346, 299114, 307308, 102508, 36972, 299119, 249964, 249970, 290932, 323704, 36985, 307323, 192635, 77949, 323710, 241792, 356482, 282763, 258191, 274577, 397467, 274590, 200867, 102564, 151718, 53417, 225449, 299183, 364723, 291004, 266430, 274630, 340170, 168141, 250062, 69839, 94417, 241874, 143570, 241873, 4309, 299222, 69849, 37087, 143589, 12522, 291052, 233712, 168176, 258293, 315638, 282877, 176381, 323838, 381183, 37123, 37128, 389384, 282891, 61708, 119053, 340238, 307470, 356626, 61718, 307478, 61721, 250138, 323866, 323870, 110881, 405795, 397603, 389413, 143656, 61737, 28970, 258347, 4398, 225582, 241969, 405814, 4410, 160059, 315708, 340285, 307521, 45381, 397646, 69974, 299353, 53598, 143711, 143715, 12644, 151910, 94567, 348527, 274800, 86385, 266610, 373106, 332153, 70010, 184699, 70014, 45438, 225662, 332160, 233870, 176529, 225683, 127380, 348564, 209308, 29085, 250271, 364960, 356769, 324011, 348593, 127411, 12724, 151990, 266679, 225718, 20924, 340416, 373187, 381383, 233927, 143817, 160201, 53710, 348623, 20944, 324049, 53714, 307667, 397779, 274901, 94672, 53719, 324067, 209380, 242149, 397797, 12771, 283107, 209385, 283111, 160252, 176638, 348673, 324100, 291334, 332297, 299530, 324119, 21016, 315932, 111135, 86564, 119333, 291367, 389672, 365097, 70187, 160304, 21045, 217655, 250424, 299576, 78394, 250430, 152132, 348744, 266826, 365139, 29268, 275033, 381539, 62052, 209508, 348775, 307824, 250480, 62067, 78453, 111222, 201335, 78456, 86653, 12926, 143999, 4734, 250504, 406156, 160409, 324263, 316072, 406186, 275115, 193198, 299699, 266932, 389811, 103102, 152254, 234176, 185025, 201410, 398021, 144072, 135882, 29387, 365261, 316110, 201422, 381648, 209614, 340690, 365274, 242395, 307936, 398052, 168676, 168678, 291560, 62185, 291568, 176880, 86769, 406261, 316151, 168696, 144125, 348927, 357129, 37646, 299791, 275216, 275218, 201491, 37652, 406294, 103191, 135960, 217880, 45852, 299804, 307998, 13089, 324388, 365350, 152367, 201522, 4917, 365367, 332602, 70459, 283450, 242495, 127811, 185166, 111439, 119632, 234320, 152404, 193365, 144214, 193367, 258901, 45908, 242525, 29538, 136039, 267112, 70513, 398194, 160626, 54132, 177013, 185205, 357234, 201594, 13180, 70525, 168830, 291714, 234372, 250762, 226188, 152460, 136079, 234391, 95139, 275363, 316326, 275376, 234417, 218034, 218033, 136116, 119733, 29622, 406459, 201660, 119747, 398276, 340933, 78788, 119748, 308168, 136139, 54219, 365517, 144332, 365521, 70614, 127959, 250840, 226267, 95199, 300000, 54241, 78817, 144357, 13290, 250859, 29676, 308207, 275439, 390129, 103413, 95225, 324603, 177147, 103424, 70657, 160773, 316423, 300041, 152591, 95248, 341009, 259090, 218135, 300060, 332830, 70688, 70689, 275489, 259105, 62502, 398376, 95277, 332845, 324657, 160818, 87090, 119860, 136245, 341047, 62521, 46144, 275530, 275536, 128082, 13405, 398429, 37984, 201825, 373858, 177251, 160887, 382072, 21625, 38010, 210043, 54394, 308350, 38017, 144515, 54403, 152714, 5259, 87181, 275603, 357524, 29846, 300188, 349346, 95395, 349347, 111783, 87211, 87212, 283826, 38074, 160956, 242879, 62660, 316617, 316618, 242908, 87262, 398561, 5346, 382178, 136420, 46307, 267495, 95464, 54511, 120048, 54513, 275698, 316657, 13552, 406775, 234750, 95495, 406797, 300304, 95505, 62738, 185616, 169233, 308502, 283926, 210199, 210201, 333085, 251174, 349478, 144686, 390452, 267577, 185657, 111931, 251194, 300348, 316736, 70977, 398657, 79171, 193860, 177473, 202055, 243018, 136527, 193873, 152918, 283992, 374106, 243041, 308578, 406883, 284004, 234856, 374124, 324975, 284020, 316789, 406905, 38274, 349571, 112002, 5509, 316809, 30092, 308623, 243087, 284059, 349598, 374175, 308639, 406951, 284071, 30124, 62896, 366003, 398776, 185785, 103866, 95674, 366012, 374207, 71107, 292293, 243141, 284103, 185803, 161229, 202190, 374224, 5586, 46552, 112089, 357851, 202203, 398815, 128482, 325093, 398824, 13800, 120298, 341494, 235003, 366076, 284157, 341501, 103931, 38400, 185857, 267783, 316943, 357907, 366101, 275996, 226852, 169512, 22057, 103978, 374313, 300590, 177712, 325171, 308789, 161335, 226872, 144956, 13886, 5699, 153159, 22093, 357969, 366165, 300632, 185945, 112218, 398938, 276063, 317026, 128613, 30317, 382575, 398963, 218745, 46723, 317060, 407174, 226951, 202381, 112274, 235156, 30357, 71320, 349850, 259739, 46753, 227004, 38590, 218815, 120512, 161473, 227011, 5827, 71372, 259791, 325329, 235217, 30420, 243416, 95961, 63198, 95968, 251620, 349924, 95976, 366312, 341739, 210668, 349934, 325360, 169713, 145139, 227060, 333555, 243443, 46842, 136958, 292607, 284416, 169732, 399113, 349963, 218893, 63246, 87826, 309010, 145172, 104220, 5917, 112412, 210732, 194351, 104246, 317239, 366394, 300859, 177980, 325437, 137021, 251712, 38722, 317253, 79685, 145222, 169800, 251721, 161612, 46928, 128849, 120660, 276308, 341846, 128855, 382814, 259937, 96097, 104290, 194402, 104293, 235366, 55147, 251756, 259948, 30574, 38769, 46961, 46966, 96120, 202618, 55162, 399229, 30592, 399237, 112517, 366472, 219025, 55190, 112535, 317337, 366492, 79773, 161699, 128933, 333734, 251817, 128941, 55216, 79794, 194482, 358329, 22462, 374722, 407503, 341979, 210910, 96223, 210912, 145376, 366563, 30692, 276451, 55267, 243684, 6120, 407531, 47084, 366579, 407540, 55284, 325623, 382974, 104446, 120831, 14338, 301068, 399374, 71695, 210961, 88082, 47122, 6166, 170006, 342040, 79904, 161825, 358435, 235561, 129067, 325682, 383026, 38966, 112696, 358457, 88121, 383033, 235580, 309312, 407616, 137281, 292933, 399431, 120904, 366667, 391244, 309327, 63570, 96343, 251998, 55391, 333920, 301152, 161897, 301162, 202869, 383094, 342136, 137337, 366721, 399490, 80005, 39046, 350344, 276617, 276616, 366734, 80014, 137360, 14481, 161938, 399507, 219284, 293015, 260252, 194716, 276637, 153760, 194721, 350372, 301222, 145575, 383144, 137386, 268462, 104625, 219316, 153781, 317623, 121017, 145596, 211136, 399552, 178371, 293072, 96470, 137430, 30938, 47323, 350426, 55518, 145630, 284898, 211174, 194791, 80104, 170218, 47339, 71923, 268533, 366842, 366846, 252160, 219394, 39171, 407813, 104711, 145675, 227597, 309519, 350480, 39185, 211218, 243987, 383255, 358679, 301337, 284954, 252189, 63775, 55586, 407846, 293159, 162090, 121132, 162098, 375091, 186676, 80181, 22837, 407872, 162115, 252239, 407893, 170326, 391510, 129368, 268633, 55645, 391518, 325984, 235872, 219490, 145763, 293222, 317799, 334182, 268649, 268656, 219506, 178549, 186742, 88442, 399738, 96637, 268670, 309634, 145798, 88455, 31112, 342409, 399754, 63883, 334224, 326036, 326041, 276890, 113050, 383393, 407974, 317863, 39335, 178608, 326065, 309683, 14772, 72115, 63927, 113079, 309692, 219580, 195007, 129476, 383428, 31173, 63947, 276939, 408014, 301519, 47568, 358868, 72152, 235994, 408031, 63967, 334305, 195043, 154085, 317935, 137716, 154100, 170491, 203261, 293374, 375296, 301568, 268803, 113157, 375302, 31241, 358922, 55823, 301583, 178705, 268823, 137752, 170520, 96793, 23067, 227866, 145949, 252446, 342559, 342568, 350761, 342570, 88623, 326191, 195123, 211516, 121408, 88640, 301640, 39506, 301650, 391762, 227923, 31320, 47715, 211565, 195187, 154228, 211573, 47735, 334457, 113274, 113278, 326276, 277124, 244358, 318087, 301706, 31371, 64146, 55955, 342675, 203414, 195226, 359073, 203430, 146086, 88745, 236202, 309933, 170670, 6829, 121520, 6838, 252601, 39614, 211651, 375494, 219847, 64200, 383687, 301778, 15059, 96978, 170707, 359127, 178915, 252647, 293611, 178929, 154353, 400124, 195327, 400134, 383755, 408343, 310040, 334617, 105239, 219931, 170777, 15128, 359201, 80677, 88871, 301867, 285484, 203572, 260917, 154422, 375608, 301882, 97083, 138044, 219970, 293701, 375623, 187207, 105291, 138062, 88913, 187217, 219991, 162648, 56153, 293719, 342878, 293728, 342881, 195426, 285539, 351077, 203622, 138090, 310126, 228209, 301941, 195446, 367479, 392055, 228217, 80762, 236411, 252799, 260992, 318337, 203648, 400259, 23430, 48007, 23438, 39823, 293782, 220056, 285594, 195485, 31646, 23455, 236449, 220068, 39849, 334762, 97194, 244656, 170930, 170931, 392116, 252853, 80821, 244664, 211897, 121794, 236484, 277450, 64459, 195533, 154573, 162767, 326611, 228308, 15318, 187353, 302042, 293851, 154587, 31711, 359395, 130020, 228325, 203752, 228333, 351214, 130034, 64502, 220151, 277499, 162812, 7165, 39937, 154625, 138244, 326660, 408580, 318470, 220169, 48137, 375819, 64525, 121873, 343064, 408603, 293916, 154658, 359459, 203815, 367661, 351280, 31793, 400434, 212017, 236597, 236601, 326716, 23618, 212041, 400459, 367692, 310351, 162901, 105558, 80987, 228445, 293982, 89187, 302179, 146533, 64619, 203884, 89198, 56430, 81009, 220277, 105593, 220284, 89213, 212097, 195719, 162952, 392331, 97420, 318604, 179347, 40086, 294039, 97439, 384160, 367785, 220329, 253099, 253105, 72883, 375988, 351411, 7351, 269498, 105658, 408768, 236737, 359620, 113861, 40135, 163015, 212170, 31950, 7374, 23761, 326873, 285915, 302300, 269533, 64734, 23775, 179424, 318688, 163041, 48349, 220389, 228586, 310507, 384238, 113907, 72949, 15609, 359678, 163073, 318722, 7432, 318732, 81170, 146708, 72986, 351516, 105757, 163102, 261405, 285980, 56609, 343327, 367912, 130346, 245038, 245041, 195890, 335159, 7480, 179513, 146754, 376131, 408901, 343382, 286039, 245081, 138588, 286051, 32100, 32099, 310630, 245105, 171382, 187771, 261499, 32126, 73090, 105862, 359815, 187784, 220560, 81296, 245146, 138651, 171421, 269725, 195999, 269727, 89504, 302498, 253350, 343463, 196007, 261545, 228775, 114092, 245165, 335284, 269759, 155075, 179652, 212421, 409031, 196043, 196048, 122320, 376272, 335313, 56790, 146912, 269793, 48612, 64998, 48615, 343528, 130536, 48622, 7665, 81394, 245239, 351739, 155134, 97791, 335361, 237058, 171522, 302595, 237062, 7687, 335368, 409097, 343561, 65034, 130572, 228882, 187927, 212504, 179739, 302622, 146975, 269854, 114209, 130593, 384549, 7718, 343593, 261676, 146990, 204335, 286256, 310834, 7731, 24120, 114234, 253502, 335423, 376382, 278081, 384580, 163401, 147019, 40529, 15956, 220759, 269915, 89691, 196189, 253539, 294504, 48744, 368232, 188014, 179822, 212594, 327282, 212597, 335479, 376439, 212600, 294523, 204418, 147074, 409222, 351880, 56968, 376457, 360076, 16016, 212627, 229019, 7839, 188067, 360101, 204453, 122541, 32430, 106159, 97971, 294583, 138939, 196289, 89796, 57028, 179910, 32456, 138954, 179915, 188107, 147148, 32464, 89810, 155359, 286437, 48871, 278248, 130797, 376558, 368367, 65272, 368386, 343822, 81680, 204561, 245524, 261915, 229152, 327465, 180012, 81710, 130867, 65345, 261955, 409412, 352069, 204611, 343879, 81735, 180046, 393042, 393043, 57172, 384852, 155476, 278359, 360280, 352085, 40795, 24419, 261993, 221036, 89965, 147308, 180076, 32624, 212855, 180088, 319359, 81794, 262026, 229262, 81809, 32660, 8086, 278423, 229276, 147359, 90020, 8102, 32679, 180137, 294830, 368558, 196527, 49075, 106424, 81851, 319426, 237507, 73667, 81862, 114635, 98255, 229333, 196567, 212954, 229343, 335843, 294885, 221163, 98285, 147438, 221167, 90104, 294905, 32763}\n",
            "Client 93: 2892 samples\n",
            "<class '__main__.ShakespeareDataset'> - (length: 413629)\n",
            "{147457, 131082, 32780, 204814, 237585, 286738, 155671, 237605, 262196, 393270, 139322, 376895, 262214, 98378, 122957, 344142, 80, 344148, 286804, 237659, 385117, 303202, 196717, 319600, 409712, 254066, 385139, 73843, 303222, 106615, 401533, 221310, 82047, 82052, 213129, 295052, 270477, 131215, 114833, 295060, 106653, 188574, 344228, 123048, 270507, 401580, 188589, 213165, 180399, 311473, 319666, 98488, 188604, 90306, 139469, 377038, 303312, 213206, 213211, 278748, 221406, 344287, 377055, 98527, 295136, 295139, 8422, 368871, 327910, 303339, 139501, 8432, 360689, 196852, 205047, 360695, 360698, 303354, 73978, 385276, 65791, 319745, 24835, 327940, 131335, 344328, 401674, 98572, 8460, 262414, 8463, 319762, 74002, 246037, 106778, 360736, 336164, 377124, 336166, 205094, 237864, 401709, 74032, 24881, 90418, 106803, 65845, 41273, 311611, 196926, 155970, 33091, 377156, 229706, 246094, 270670, 41300, 278871, 139607, 221532, 303452, 385390, 172403, 221564, 213374, 106880, 205188, 131460, 287110, 139655, 360847, 246161, 82324, 377241, 90521, 197020, 147882, 401847, 115131, 450, 74179, 98766, 344529, 287186, 213462, 139745, 205285, 25064, 172523, 303597, 172527, 311792, 172530, 25082, 303613, 328192, 311809, 66052, 33285, 377356, 49679, 139795, 352789, 205334, 385558, 8725, 344598, 238106, 156188, 123420, 90657, 360994, 279075, 385575, 320041, 311850, 90668, 279089, 385586, 107057, 90677, 229942, 172599, 41532, 205373, 393789, 205379, 16965, 172613, 262729, 41549, 115277, 49744, 123473, 148050, 287314, 254554, 287323, 369247, 336479, 197218, 369251, 205412, 49768, 98922, 115310, 230002, 385653, 123510, 385655, 369272, 115321, 287353, 115322, 205436, 164477, 246399, 287375, 230032, 262800, 180883, 74390, 369303, 238234, 197281, 254629, 189099, 246444, 17067, 205489, 254644, 123577, 699, 262844, 701, 107198, 17094, 254663, 148172, 369357, 320207, 148185, 123612, 197349, 25322, 41713, 361202, 262909, 164615, 107273, 25360, 131858, 230162, 181012, 58133, 385817, 49949, 394016, 353057, 156455, 9000, 295720, 66356, 222006, 197430, 9015, 197432, 74556, 320318, 312127, 58179, 271176, 41801, 238413, 287568, 148311, 279384, 205657, 164696, 271198, 295785, 361322, 115562, 90992, 385914, 91002, 385915, 230270, 385920, 328579, 9096, 50058, 410507, 148366, 181134, 17299, 66452, 344988, 238496, 377765, 107434, 222126, 312245, 377782, 263101, 312259, 222148, 279500, 336845, 50127, 238548, 361432, 985, 9181, 107488, 238561, 148450, 222183, 107496, 99307, 345068, 156652, 377842, 287730, 107508, 304121, 271356, 214013, 320510, 345087, 107524, 402440, 115721, 50186, 91158, 123927, 394263, 410648, 33820, 99357, 386082, 271410, 394295, 386110, 320574, 107589, 66633, 205899, 255052, 181324, 336971, 287822, 50254, 42070, 91225, 181340, 132188, 189536, 99427, 107620, 279656, 361583, 173171, 189555, 205939, 402551, 156794, 279681, 42115, 353411, 222346, 369809, 124056, 312473, 296090, 304282, 50328, 148640, 1194, 222379, 345262, 124080, 353456, 107698, 58548, 140475, 361660, 91324, 25795, 369861, 74954, 140495, 99537, 238801, 214229, 42199, 328921, 107742, 320739, 214245, 361702, 361701, 181483, 34027, 230638, 214255, 107760, 263410, 410866, 42228, 386293, 99573, 50423, 320761, 181505, 25858, 369924, 181508, 173316, 91396, 140552, 1290, 328975, 181520, 263450, 83230, 206127, 238897, 17714, 345394, 206132, 230707, 42296, 329020, 288064, 304450, 369986, 165188, 222532, 34118, 91464, 206157, 197973, 181592, 329049, 1370, 189789, 288096, 296292, 99686, 181609, 34156, 83309, 198000, 75129, 157049, 378237, 91520, 206211, 34186, 296332, 124307, 58783, 279967, 239011, 402852, 206252, 181676, 91565, 222642, 58805, 34232, 288487, 17853, 288189, 198079, 280000, 189887, 91586, 370124, 247249, 239058, 271827, 304597, 9688, 91611, 353755, 116191, 230886, 312806, 34282, 214510, 361966, 17909, 255485, 288253, 181759, 321028, 255493, 247308, 149009, 214548, 91673, 1564, 124445, 271902, 362021, 124456, 132654, 337459, 321080, 91705, 17978, 239169, 206401, 329284, 206419, 239188, 411223, 403032, 353880, 247393, 149091, 321128, 280169, 263786, 99947, 34411, 370291, 231030, 271993, 34429, 124544, 378498, 50825, 59021, 26260, 108180, 263833, 165531, 165533, 222883, 239270, 304812, 42668, 173742, 198326, 140991, 1729, 288455, 231112, 75467, 255699, 173782, 255709, 304863, 362210, 394979, 214755, 67303, 222951, 26345, 296682, 206571, 181996, 141037, 181998, 34536, 59120, 149232, 288490, 403187, 132853, 59127, 173818, 59134, 173826, 26371, 9993, 378635, 67341, 345877, 67350, 337687, 214807, 272150, 173850, 378652, 182045, 75551, 182049, 173859, 321320, 10027, 403244, 362284, 337711, 263985, 108342, 329527, 165686, 59193, 100156, 165693, 157500, 67398, 321351, 411464, 354121, 157515, 370509, 198482, 83796, 141141, 337752, 124763, 67424, 116579, 255844, 411491, 386918, 149353, 305008, 272241, 1907, 370550, 255863, 75643, 296828, 42876, 264063, 395141, 305031, 182152, 206730, 75664, 92051, 247700, 1939, 100245, 346009, 223130, 51099, 264094, 370592, 26530, 337829, 26538, 255917, 239535, 411569, 354229, 403382, 26551, 100282, 124865, 305093, 354248, 403405, 116687, 239574, 354264, 206813, 10205, 190430, 67554, 305124, 296933, 313316, 182252, 239597, 182258, 329715, 223220, 231413, 215029, 100343, 18426, 51198, 83973, 190471, 313352, 51207, 141325, 395279, 411663, 26647, 75800, 198681, 206874, 116761, 67612, 75814, 51241, 313388, 280621, 411692, 321585, 231473, 59446, 395319, 100410, 67642, 362557, 297022, 182336, 67652, 264262, 165958, 26703, 206931, 116823, 256096, 272482, 43112, 165993, 51308, 149626, 362623, 272511, 362629, 59527, 166025, 18572, 346253, 92304, 2208, 43173, 313512, 215209, 166059, 43184, 84144, 379058, 411828, 157883, 321732, 248006, 116936, 288968, 100552, 198859, 362701, 92375, 84184, 264409, 51418, 190683, 157916, 288989, 133342, 231647, 182496, 370913, 338143, 67811, 338150, 67815, 313577, 256233, 92393, 313585, 43250, 248054, 403705, 100604, 26877, 59648, 354561, 59653, 108806, 354567, 141574, 190731, 272652, 59663, 387344, 84242, 231699, 346388, 125206, 108823, 51480, 125209, 125222, 76072, 256297, 100650, 157996, 84268, 321838, 133420, 289068, 280878, 149805, 108861, 387391, 2368, 354625, 125250, 379210, 330059, 182608, 223570, 256341, 371032, 371042, 346469, 125285, 2405, 412011, 158061, 84335, 305525, 26999, 51578, 239995, 395645, 289151, 2436, 223633, 35219, 289173, 264600, 166301, 207261, 395678, 280992, 141731, 403880, 223660, 330157, 387501, 84403, 59829, 240054, 289208, 395704, 240060, 264637, 240062, 18876, 35273, 100809, 18891, 174539, 403921, 256466, 289239, 223704, 207321, 182746, 141790, 117214, 84450, 322020, 166376, 35307, 68078, 354801, 289266, 199153, 313844, 59895, 240119, 182777, 141815, 150011, 68091, 363014, 51720, 289292, 150028, 92687, 141840, 371219, 387605, 182807, 109086, 27170, 379427, 10788, 412200, 379437, 166455, 59960, 322104, 84538, 240184, 84535, 141887, 232009, 256585, 133712, 223825, 133725, 133727, 412260, 100970, 68203, 322159, 141938, 199286, 248440, 150137, 363129, 346747, 338556, 60030, 289413, 223881, 273036, 404112, 264849, 346770, 117396, 60053, 264859, 182940, 305822, 117408, 51874, 10917, 166577, 354994, 84659, 182968, 10939, 215741, 182974, 330431, 355013, 19150, 2769, 371413, 60119, 371416, 199390, 35551, 363234, 346854, 133864, 158440, 248555, 215788, 60141, 199407, 68335, 43762, 27379, 174835, 232178, 166646, 330483, 207611, 363260, 2813, 240382, 2815, 68352, 84732, 355082, 379671, 363288, 273177, 387865, 11038, 363297, 330529, 27428, 174891, 142124, 305965, 109355, 355119, 248623, 199473, 338738, 265016, 207675, 224060, 404285, 387906, 412487, 19273, 297801, 76620, 133966, 330574, 2894, 101198, 346962, 27479, 191321, 199519, 142176, 232289, 117603, 379754, 27503, 297840, 2928, 35700, 183157, 174965, 232313, 109436, 281469, 379773, 330620, 248707, 117638, 322442, 240524, 27534, 297875, 232342, 363418, 191388, 322461, 306076, 265128, 273323, 240560, 355252, 109494, 347072, 347073, 27585, 265153, 60356, 183238, 273351, 248775, 388048, 273369, 175066, 314331, 330718, 166884, 183269, 101351, 232425, 404459, 134128, 191473, 265201, 322550, 257015, 265208, 76798, 379903, 52225, 125956, 166921, 248851, 191507, 125972, 76825, 85021, 35869, 355359, 347171, 52259, 240675, 158755, 330792, 265258, 330799, 85042, 3129, 60474, 142393, 207929, 339006, 199743, 191552, 166976, 257087, 355399, 281671, 191559, 35914, 273483, 248908, 158797, 44110, 166990, 314451, 52309, 330839, 273498, 388187, 117862, 183401, 134250, 273515, 257135, 265337, 281725, 404607, 44159, 35971, 101509, 101519, 191642, 183452, 396445, 339101, 134303, 191649, 396451, 11427, 224423, 232617, 60595, 191667, 19635, 19637, 298169, 306362, 44219, 232635, 257215, 224450, 404678, 142541, 183506, 290003, 85207, 109784, 216282, 322780, 290014, 117986, 77030, 68841, 298218, 199919, 118002, 281843, 101619, 11509, 314614, 158962, 191736, 257275, 412923, 396541, 257279, 216320, 142591, 109826, 36096, 126211, 3339, 44300, 347405, 36110, 150800, 68881, 142611, 412952, 240924, 118047, 183585, 159014, 412969, 257324, 199983, 396592, 240947, 265523, 142645, 126264, 208186, 240957, 175422, 199999, 363839, 109886, 306499, 60743, 19784, 36169, 126284, 167248, 290129, 19807, 216416, 380258, 191843, 306531, 101740, 339310, 134512, 208244, 322937, 200057, 355710, 134527, 191872, 93568, 232841, 306569, 396682, 363917, 404878, 224659, 396693, 36247, 142743, 200093, 191901, 208291, 142756, 224677, 150952, 19882, 191915, 134573, 77229, 101808, 44465, 85430, 339385, 363966, 396735, 167359, 60868, 232903, 241099, 347605, 323031, 93657, 36313, 306653, 126436, 347624, 323051, 28141, 265710, 306671, 273906, 404984, 69117, 69118, 290310, 159238, 273927, 60939, 241164, 101902, 77330, 134676, 28183, 339494, 306728, 142894, 364081, 388668, 388672, 216643, 233029, 298567, 355912, 405063, 290378, 331347, 405076, 192084, 208469, 323160, 331353, 306785, 323174, 3688, 364139, 126571, 290416, 233072, 61044, 347767, 102010, 159360, 257665, 110210, 315012, 134790, 298631, 306823, 306826, 372367, 372371, 405140, 241300, 20118, 257683, 224921, 282271, 323232, 331428, 364204, 224942, 413360, 413361, 69298, 233142, 364216, 396986, 290492, 159425, 151235, 208581, 323284, 175829, 134871, 405214, 380643, 241379, 339688, 216814, 44784, 356082, 208627, 225012, 61172, 397044, 69369, 110330, 339708, 61183, 249601, 192257, 372485, 20231, 28424, 339724, 372492, 274190, 356110, 85781, 69399, 53016, 126745, 208672, 216870, 233254, 323371, 364333, 3885, 94006, 175927, 274232, 364345, 151356, 85820, 216896, 12099, 3909, 216901, 298832, 192336, 241492, 413529, 200539, 200542, 28517, 85863, 315240, 266093, 36723, 44919, 192376, 12153, 282489, 184191, 282499, 225158, 200583, 389003, 339854, 413582, 118670, 266128, 323475, 372631, 356251, 192413, 192414, 389021, 36768, 143265, 225186, 102305, 266148, 389026, 233382, 298919, 389031, 143277, 184242, 20405, 339896, 241598, 110533, 151498, 331723, 397258, 225226, 20431, 372690, 258003, 389081, 126939, 364512, 217056, 200673, 143331, 45024, 249824, 282600, 135145, 307178, 389101, 45039, 348144, 110578, 184318, 233470, 53252, 323591, 290832, 28688, 331794, 405526, 159767, 217114, 176154, 36894, 61472, 266273, 77861, 110637, 176176, 348218, 12350, 217153, 241735, 184393, 315468, 233550, 94288, 266321, 28754, 266326, 28760, 307289, 405594, 389218, 233573, 241766, 364648, 127082, 405613, 258161, 389233, 176243, 45172, 266357, 217210, 217214, 53376, 397442, 340099, 372869, 249991, 94346, 102540, 118928, 250001, 340114, 94355, 389272, 323749, 266406, 53423, 356529, 274610, 331955, 94387, 127157, 397495, 53432, 372927, 45251, 192708, 20685, 4301, 381134, 258256, 397517, 118994, 139255, 12495, 323802, 299228, 4317, 28909, 110830, 217325, 266480, 233713, 135410, 12531, 37106, 233721, 266490, 86268, 184578, 168201, 135436, 37135, 110865, 184594, 405778, 241939, 168215, 217376, 364833, 299302, 12587, 69932, 299310, 45359, 201008, 405807, 151859, 364853, 135478, 209215, 356675, 258372, 217411, 299335, 340296, 340303, 168274, 364882, 373078, 119127, 4441, 381274, 45403, 356697, 4445, 61785, 160094, 364898, 291171, 176483, 217444, 160101, 201062, 307556, 299371, 176491, 348538, 53632, 70018, 20867, 20868, 266626, 184715, 217483, 4494, 70032, 110993, 37268, 348567, 78234, 315804, 70049, 29093, 364971, 86445, 307635, 209332, 274874, 250299, 315841, 389569, 242115, 217540, 364999, 45513, 201162, 160203, 135628, 70095, 184786, 102866, 291284, 324054, 29144, 397786, 324058, 315869, 111076, 102885, 102888, 168425, 315882, 143853, 324078, 405999, 274930, 176627, 201204, 70135, 168439, 70143, 397829, 225798, 78345, 266764, 340492, 283156, 12821, 258582, 291352, 78361, 242202, 78360, 53792, 266785, 160290, 381474, 225833, 168493, 283181, 315952, 242227, 389685, 406077, 225855, 45632, 12867, 45636, 397895, 283208, 119375, 160346, 225886, 12895, 127586, 389731, 291427, 275045, 94822, 283238, 340582, 397923, 152162, 299628, 275054, 94832, 94833, 217715, 365173, 365177, 70265, 168571, 45696, 152192, 332417, 21128, 168584, 53899, 127630, 29332, 111252, 266902, 348822, 4764, 201373, 12960, 406188, 193199, 119480, 94906, 185019, 94909, 291518, 217806, 78547, 299731, 275157, 357078, 398040, 348888, 119514, 307934, 217828, 307941, 365291, 70385, 4857, 307961, 381693, 29439, 70400, 193283, 193285, 307973, 389896, 127759, 193299, 201495, 332569, 176923, 13088, 119585, 357154, 283425, 340778, 54061, 111409, 135986, 340792, 250680, 242492, 4925, 176956, 21315, 119621, 365388, 103245, 136017, 193368, 283481, 86875, 62302, 389983, 234335, 242530, 70499, 95076, 78693, 349029, 242535, 111464, 176999, 332650, 258921, 193386, 193394, 299890, 258932, 168822, 381825, 29570, 54149, 242566, 78730, 144268, 381837, 283536, 357265, 5009, 267162, 316319, 242593, 54180, 226213, 45990, 193447, 119720, 291749, 234411, 209847, 381880, 160700, 168892, 193470, 111548, 54209, 332737, 299974, 250828, 111567, 185297, 365524, 226263, 349144, 283609, 406492, 316380, 152542, 29662, 193504, 37857, 242656, 185318, 308198, 381931, 250862, 209904, 37873, 13299, 381946, 46078, 283647, 152574, 5122, 340995, 95235, 70665, 21515, 365591, 5144, 177176, 275487, 177187, 54309, 46121, 177195, 226360, 218174, 185407, 283710, 332867, 103493, 275527, 308298, 300106, 382028, 169038, 316496, 62551, 87130, 21598, 332899, 70757, 177258, 357484, 373872, 95346, 226419, 308340, 169078, 234614, 300155, 349307, 382078, 29824, 251010, 119939, 103556, 144519, 349325, 160909, 349331, 29845, 291991, 324760, 185497, 70808, 315295, 128158, 218271, 103589, 152743, 283815, 13482, 62637, 169135, 373935, 29876, 308408, 119993, 390328, 332993, 259266, 382147, 177349, 185545, 21707, 120015, 5327, 111825, 275670, 259286, 341211, 54492, 54491, 275679, 259296, 308449, 120038, 79082, 308458, 54507, 398573, 62704, 169201, 292084, 103669, 283900, 70908, 242941, 161023, 292098, 79107, 234757, 275721, 177423, 177437, 144670, 292131, 185637, 38184, 226615, 218423, 300353, 128322, 374082, 103748, 259400, 390483, 169300, 95571, 120155, 267617, 46436, 382311, 62828, 406898, 46454, 398712, 111993, 5500, 136577, 46467, 382341, 316806, 54665, 30090, 308624, 5521, 374161, 284051, 177555, 120211, 349587, 120209, 243097, 275870, 406950, 398765, 259504, 169392, 136630, 226742, 112056, 193978, 243136, 21959, 5583, 234962, 406994, 177623, 38363, 13791, 46559, 169442, 374242, 407013, 38374, 349673, 153065, 62960, 333303, 185847, 407033, 62972, 390656, 316937, 275980, 38413, 333326, 79372, 251408, 390673, 161301, 300566, 325151, 63009, 284194, 259620, 22054, 87593, 120363, 267819, 243245, 292399, 300592, 71217, 300593, 185908, 325173, 38454, 382518, 267832, 259657, 177739, 317004, 104013, 374351, 390739, 144980, 136790, 218711, 22104, 341595, 95836, 136796, 161372, 185947, 398945, 5729, 144996, 202345, 79469, 226927, 243311, 349812, 374390, 226937, 210554, 38527, 333440, 38529, 54919, 276104, 226959, 325266, 128658, 366229, 63127, 235161, 112281, 300700, 112286, 390818, 136870, 267943, 30378, 95915, 259754, 194222, 399023, 243377, 300722, 317105, 22201, 95940, 79560, 202442, 407244, 186060, 218830, 210638, 235215, 87764, 333527, 349914, 210651, 161503, 235236, 128744, 407279, 407281, 366323, 5878, 71415, 358137, 268032, 309000, 325387, 161549, 300813, 276239, 79632, 55059, 153364, 374553, 349978, 218908, 309021, 227103, 5920, 5922, 63267, 5937, 243505, 46902, 284473, 390976, 177994, 63307, 399181, 186193, 71509, 227158, 268121, 186204, 227168, 128870, 38763, 407404, 112492, 374665, 178057, 153486, 161683, 284567, 169880, 350108, 38818, 63404, 47021, 30638, 104367, 38832, 79792, 227249, 14270, 358334, 276419, 227270, 153544, 391114, 22478, 309201, 358355, 391124, 137173, 333782, 333784, 399320, 374755, 137188, 243690, 161779, 260085, 129014, 22520, 120825, 358395, 243711, 260098, 186371, 268291, 227332, 399365, 227335, 358409, 382986, 137229, 71694, 219149, 374800, 22544, 366612, 79894, 145434, 137244, 104477, 251933, 63521, 383012, 6182, 235563, 161838, 284722, 129091, 227395, 391242, 186445, 243793, 6228, 251989, 227414, 366680, 6235, 30815, 243811, 284771, 145509, 260197, 342123, 366706, 14454, 79992, 55416, 178305, 170122, 211083, 6286, 80016, 293012, 276635, 14503, 80041, 96427, 358577, 260273, 80057, 112826, 252094, 22720, 374980, 112839, 39113, 96457, 186571, 22732, 178385, 202976, 391392, 284899, 276707, 342246, 194797, 30958, 407791, 284912, 88301, 153842, 55539, 219389, 112895, 162053, 55557, 112904, 391433, 14607, 227603, 121108, 276757, 39189, 252182, 162072, 88349, 211229, 31009, 14626, 325923, 121122, 293157, 22827, 112940, 252205, 276783, 301361, 301365, 186680, 342331, 31038, 293185, 129348, 112965, 14661, 63817, 55630, 121168, 178513, 350548, 153950, 276838, 55655, 244071, 309609, 358761, 260459, 129388, 391532, 55662, 63854, 350576, 153968, 399727, 301427, 358773, 63864, 162171, 399740, 22907, 162176, 186754, 39300, 72069, 88454, 375184, 334228, 219540, 104859, 334239, 96675, 285094, 342439, 137640, 194983, 72106, 129451, 194989, 178606, 14771, 39348, 367033, 186813, 72125, 211392, 293313, 129474, 195012, 63944, 367049, 408010, 342482, 358870, 203223, 334294, 350687, 47584, 350690, 162276, 6630, 55783, 88555, 195051, 88559, 244209, 14846, 23041, 317956, 31242, 80395, 301580, 334349, 383500, 301584, 367121, 260636, 31260, 55839, 203300, 145958, 350760, 260648, 129578, 260651, 293421, 154158, 96815, 350768, 334386, 309810, 260660, 80445, 219711, 137794, 301637, 186951, 129608, 408138, 211536, 293456, 277074, 80467, 186967, 64095, 170596, 244325, 80486, 31334, 14953, 318059, 195184, 72309, 113271, 55930, 244349, 80509, 187009, 367236, 334468, 187014, 195210, 268939, 252556, 203409, 6804, 162453, 211618, 96933, 154279, 408234, 334507, 367275, 408240, 318144, 367301, 293573, 260808, 113352, 269002, 260814, 64206, 236240, 113363, 367318, 285401, 277213, 342750, 178912, 228066, 187106, 129766, 318183, 350952, 367337, 269033, 47849, 137964, 64237, 244462, 97007, 146160, 293617, 97003, 105207, 219895, 31483, 391932, 31487, 170753, 228101, 146182, 359175, 47881, 236299, 334609, 170770, 383762, 252697, 408346, 342811, 293657, 326431, 269089, 301862, 269096, 375597, 260910, 252719, 97072, 301884, 351037, 375613, 236352, 187202, 23366, 6993, 383827, 195414, 285527, 293720, 310104, 23390, 367456, 326502, 228200, 326506, 342896, 293751, 88954, 162685, 187262, 105345, 260993, 367494, 113544, 162697, 228237, 334734, 277392, 334738, 359314, 97174, 97181, 97182, 318366, 400288, 285601, 105376, 105384, 7093, 162742, 302011, 113596, 179133, 244669, 105407, 80836, 31685, 39878, 244689, 89051, 244702, 170976, 56290, 97250, 105445, 277489, 343025, 64500, 244733, 269309, 277504, 334849, 392195, 31749, 31750, 162826, 56347, 367651, 154659, 244774, 302123, 23600, 318513, 146482, 179256, 277561, 326715, 97341, 138303, 212053, 326749, 113757, 138339, 343150, 121967, 195698, 408692, 7285, 334966, 302201, 105594, 48251, 31873, 302211, 146565, 392337, 56469, 122010, 318620, 203934, 195744, 195749, 294053, 228523, 285871, 212148, 400564, 154815, 130240, 367810, 269510, 56518, 31946, 261326, 154835, 31955, 105690, 48347, 400603, 408797, 23774, 269534, 113888, 351460, 7399, 15592, 146673, 384242, 310516, 81141, 285943, 236792, 56570, 335102, 48388, 326917, 384264, 89357, 15630, 163090, 228628, 384278, 204055, 392476, 187679, 32031, 376101, 367909, 277798, 351530, 146733, 384301, 359726, 105777, 294193, 376115, 32054, 204089, 384313, 163131, 326971, 294205, 367934, 23870, 113986, 56646, 392520, 187720, 220492, 245074, 64857, 335194, 64859, 179558, 351590, 220523, 7535, 294258, 335235, 228740, 138629, 114053, 179591, 236931, 253321, 204171, 155022, 392591, 138643, 327065, 196001, 376226, 15779, 32164, 351657, 294315, 48556, 220591, 245168, 400817, 310706, 327091, 179635, 114098, 81334, 302519, 400826, 196026, 335292, 220605, 196029, 24003, 40389, 171462, 318918, 40395, 343503, 24020, 146905, 64988, 73185, 114146, 351713, 286182, 302570, 163309, 220654, 269808, 56818, 376310, 40439, 359927, 146937, 286201, 89597, 65022, 196098, 269827, 228875, 179727, 65040, 318998, 384537, 73242, 343577, 187932, 359966, 245286, 130606, 97838, 32302, 269880, 392760, 155195, 187968, 327235, 163396, 138821, 269894, 392780, 384589, 147023, 65104, 269906, 212563, 65109, 106070, 343640, 335449, 220763, 286300, 212571, 278110, 351840, 65121, 368226, 97892, 163429, 15976, 114284, 171631, 278135, 228994, 286340, 384650, 106125, 114322, 48788, 409243, 73372, 155293, 65182, 392862, 269984, 327329, 16033, 56996, 122534, 171687, 343723, 384684, 229038, 384691, 245430, 310971, 163516, 122555, 7873, 220865, 212675, 351941, 130758, 179912, 229068, 302797, 261845, 204502, 229080, 204504, 65243, 351963, 237282, 89827, 179945, 212714, 171756, 261869, 65266, 81652, 368374, 89847, 98040, 57081, 392950, 343810, 65283, 65284, 179980, 302861, 237327, 130831, 81681, 155415, 40728, 261913, 392987, 220957, 401190, 188198, 384808, 16170, 204592, 7984, 196403, 188211, 147252, 335674, 81730, 270153, 261962, 221004, 196430, 48974, 221006, 98131, 204635, 376669, 360287, 147296, 114533, 352103, 40808, 8042, 294768, 245617, 343929, 245638, 155527, 139151, 253841, 106388, 245652, 188309, 57240, 229273, 278427, 327595, 319408, 262067, 90037, 81847, 73658, 262075, 229312, 393153, 286656, 49092, 32708, 212934, 360394, 278474, 180175, 139216, 155601, 147416, 352218, 327643, 335836, 344029, 163805, 163804, 245728, 122848, 245732, 319460, 147435, 376812, 385009, 376822, 327671, 393208, 278527}\n",
            "Client 88: 2892 samples\n",
            "<class '__main__.ShakespeareDataset'> - (length: 413629)\n",
            "{368642, 49155, 311301, 278535, 376842, 196619, 73744, 24596, 155669, 221207, 237593, 335898, 385049, 65563, 270365, 8222, 303137, 335906, 155685, 368681, 57392, 311346, 73779, 393271, 409665, 16451, 254019, 139334, 106566, 254023, 90185, 303182, 270416, 204881, 65618, 188505, 393305, 360538, 344160, 172130, 163938, 41060, 352356, 90215, 393319, 221287, 131184, 327793, 41076, 213109, 221309, 172158, 368766, 368767, 73857, 336002, 129, 139399, 295050, 360591, 155792, 32911, 188562, 49307, 155, 155811, 24741, 32934, 344231, 82089, 213162, 344239, 196785, 303282, 139442, 8372, 262326, 147646, 221378, 270534, 90311, 377031, 49352, 344267, 205008, 49360, 401618, 254161, 409812, 147673, 73945, 164059, 221404, 270553, 401631, 409826, 295141, 229609, 229610, 205033, 319728, 82161, 270578, 98547, 336121, 172281, 123134, 8446, 131326, 311553, 221440, 385288, 303370, 147724, 188684, 139537, 319783, 33065, 188715, 254252, 262445, 287022, 360756, 33080, 65848, 16699, 327996, 57661, 8515, 139587, 139588, 41286, 41287, 180551, 237897, 33098, 319818, 360784, 49496, 98652, 49501, 303464, 229736, 270699, 303467, 221550, 33138, 205171, 221566, 336255, 229760, 221571, 287107, 369031, 106889, 303499, 303500, 123278, 393614, 369040, 344465, 41361, 311703, 131481, 401819, 131485, 336286, 352669, 369059, 90532, 336293, 352677, 205221, 237994, 106926, 246191, 115120, 328113, 49589, 156086, 410043, 287163, 246209, 278977, 229827, 41412, 25029, 131523, 57799, 33224, 254410, 57806, 344530, 295385, 106970, 360929, 328176, 41458, 82418, 377332, 172533, 270835, 25083, 16892, 49665, 8705, 123397, 238087, 410120, 311818, 320011, 360975, 369170, 172562, 246299, 344606, 205343, 246310, 57895, 279080, 270890, 270892, 172592, 131633, 90673, 131637, 16951, 131640, 164412, 33341, 352831, 25152, 148034, 213572, 57926, 180811, 16971, 213581, 164430, 205400, 49754, 49755, 41564, 25178, 385630, 287326, 33376, 385632, 352864, 33390, 303729, 221809, 172660, 90749, 205437, 369278, 66188, 49809, 221843, 164507, 287387, 197280, 287396, 41637, 8870, 344745, 41645, 279216, 221875, 107187, 82615, 49848, 33465, 254650, 189112, 123581, 402111, 254657, 410307, 25290, 197322, 123599, 262866, 107222, 17112, 213721, 99035, 74460, 320220, 107227, 164574, 295652, 410342, 66279, 17130, 402159, 246514, 8948, 377592, 115451, 164606, 205573, 41737, 25355, 262930, 197395, 164632, 361241, 344858, 254745, 49946, 140059, 303903, 221990, 230184, 328489, 809, 140075, 41770, 33581, 156456, 156464, 385842, 287546, 181062, 99143, 90952, 123723, 123730, 394070, 254811, 279389, 863, 312160, 320353, 66404, 115557, 353126, 197479, 213863, 410471, 25450, 66406, 172910, 881, 320370, 164721, 369531, 279422, 287616, 377730, 369538, 123780, 131973, 115593, 41867, 99213, 140174, 99218, 254866, 172948, 123796, 230293, 189340, 58269, 263070, 91037, 336800, 361377, 213930, 9133, 345006, 107438, 50098, 377780, 377784, 353211, 328638, 164801, 33735, 394184, 205772, 320462, 205775, 377808, 287694, 181203, 230360, 197600, 295906, 197603, 123882, 74738, 99317, 254967, 328695, 99321, 82937, 295931, 132088, 271357, 91140, 74759, 74761, 132110, 238610, 25624, 246811, 377893, 74791, 263209, 74797, 377901, 222256, 107570, 271413, 222262, 9272, 295994, 320577, 271426, 17473, 345162, 58443, 9296, 123984, 263249, 369745, 214096, 140374, 123992, 361561, 271449, 156765, 214113, 287849, 50284, 164973, 33907, 304245, 271481, 246907, 214144, 99457, 1162, 337038, 238735, 345232, 296083, 25748, 312470, 107674, 156826, 345249, 263336, 17576, 165035, 181421, 107694, 148653, 238768, 230577, 91312, 83118, 246964, 42164, 124082, 410807, 50351, 58553, 17587, 386240, 83137, 107720, 74953, 124107, 107736, 99549, 124126, 361704, 91370, 353516, 230640, 74994, 107770, 394492, 369918, 83203, 115974, 148744, 1291, 279830, 312601, 345379, 214308, 329000, 25899, 304428, 148780, 116011, 247089, 189749, 238904, 156991, 17728, 304449, 402751, 25923, 255301, 66902, 17751, 99674, 386394, 25952, 173408, 312674, 386408, 1385, 34152, 75113, 370028, 107896, 370040, 279929, 394621, 353664, 75136, 206213, 75142, 58760, 329099, 255375, 1425, 361874, 214419, 165268, 255379, 386454, 411034, 107931, 206236, 386459, 394654, 288159, 58785, 107938, 148905, 148906, 247212, 165294, 353713, 230842, 411066, 181692, 124350, 263619, 132548, 91589, 296389, 288201, 214474, 157129, 304589, 67026, 17874, 58836, 214485, 132565, 345559, 26075, 58844, 148966, 42490, 321020, 165384, 58893, 67087, 108048, 345619, 108056, 321055, 304673, 402981, 411173, 271913, 288301, 108078, 9775, 296509, 58942, 116286, 149056, 58947, 26183, 58955, 255568, 157265, 247382, 321111, 255576, 173657, 337496, 75352, 337499, 42584, 222809, 263775, 378464, 271980, 99951, 34418, 190070, 116343, 255606, 345724, 91774, 239231, 173696, 345735, 132744, 140937, 34447, 280212, 157333, 231061, 378520, 42649, 255645, 280226, 173732, 198311, 100011, 288427, 91823, 239280, 26291, 313013, 67254, 75447, 18109, 140990, 50878, 296639, 100038, 116424, 329417, 108243, 100052, 222944, 18146, 100068, 50918, 362217, 280300, 313069, 255727, 394996, 149236, 182004, 222968, 157438, 83714, 280328, 329488, 329489, 173842, 50963, 1812, 1813, 362264, 296729, 42777, 83741, 157472, 100130, 288550, 198439, 42792, 1835, 91948, 329519, 263983, 124721, 1842, 223027, 263989, 206652, 411455, 337727, 296769, 411457, 272195, 108352, 214847, 386883, 1863, 403272, 1866, 239435, 124749, 198477, 51027, 157529, 370527, 370529, 354153, 247664, 206711, 296823, 190330, 345979, 223105, 132994, 354182, 182156, 42893, 124814, 337806, 288657, 329620, 354201, 149403, 190370, 386978, 354213, 247719, 206761, 51115, 92079, 133042, 362419, 329653, 108476, 149446, 124874, 165839, 247765, 362456, 18396, 198622, 2015, 34787, 124900, 174054, 411623, 215017, 149481, 83949, 2038, 165883, 198657, 83970, 321538, 124932, 100356, 264198, 313349, 141321, 387081, 321547, 329741, 223245, 157712, 403474, 116756, 198680, 190495, 133151, 223268, 280613, 362532, 34855, 272424, 34858, 2090, 297004, 149551, 395318, 108598, 43066, 411712, 231490, 67650, 124998, 125002, 247892, 272474, 2139, 133214, 362595, 133219, 67685, 51307, 34930, 10357, 166005, 272504, 223361, 116865, 198785, 141444, 313477, 51331, 34956, 247949, 92300, 379026, 370838, 321689, 59548, 84127, 51362, 141477, 338101, 403640, 125113, 67774, 338111, 125124, 149701, 26822, 166087, 321734, 264393, 346316, 51407, 280784, 26831, 329939, 329940, 157910, 362713, 207066, 239835, 92384, 18657, 321762, 157923, 133348, 370916, 321766, 166113, 239848, 256232, 346344, 215278, 239855, 321780, 10485, 272631, 313594, 67837, 280834, 264452, 313607, 395528, 190729, 35081, 100621, 198928, 84244, 51477, 264470, 346391, 43288, 207128, 67866, 387353, 141596, 297248, 264481, 256291, 84259, 403749, 190764, 166189, 174380, 108848, 403764, 379190, 100670, 239938, 51524, 51525, 321862, 280903, 141641, 43339, 84301, 387407, 264530, 190803, 346454, 215383, 92502, 207194, 35163, 59749, 43370, 76138, 26996, 149877, 272759, 412026, 182655, 125312, 43398, 264583, 10639, 313744, 403857, 362896, 166293, 199066, 223643, 117150, 321950, 321969, 321970, 190904, 289210, 371137, 141764, 330181, 133575, 289225, 10706, 330199, 76250, 51674, 330203, 125405, 289248, 264673, 379364, 27114, 223724, 100853, 330234, 158208, 248322, 10761, 27148, 240141, 354829, 346640, 395793, 363026, 297490, 248344, 109085, 59946, 100906, 199212, 166449, 166450, 76346, 256571, 272956, 84549, 117319, 59977, 59979, 191053, 371280, 133714, 76373, 141912, 59995, 150110, 371295, 100961, 191076, 35431, 207465, 256617, 273010, 191092, 223864, 10873, 51833, 35454, 150145, 35458, 346760, 35470, 207503, 92817, 43667, 27289, 101019, 76446, 174751, 60063, 264867, 141989, 166568, 76459, 133803, 150190, 215729, 412340, 223925, 404150, 166585, 387769, 297659, 371387, 35521, 101058, 207555, 330434, 150211, 355014, 412357, 191181, 68304, 264914, 289493, 322264, 412379, 133852, 92893, 215781, 101096, 60152, 264957, 404231, 346889, 412428, 387855, 404242, 273171, 84756, 2837, 11030, 305942, 109339, 264993, 273191, 387881, 404282, 133953, 273221, 11078, 84807, 404297, 68426, 174923, 199502, 174927, 35664, 199506, 396114, 215891, 199509, 273247, 60256, 133985, 256868, 412518, 240489, 84844, 240494, 158575, 363374, 289668, 125834, 166796, 347020, 117649, 273299, 125844, 134039, 265114, 396191, 306080, 240545, 166816, 240547, 322463, 371630, 379823, 388017, 84913, 134071, 125887, 109507, 93124, 216004, 117712, 175069, 117726, 150495, 3039, 93154, 93155, 44008, 117741, 396270, 84976, 412659, 388090, 224251, 60413, 191486, 281605, 19473, 76827, 109602, 281635, 85030, 150567, 35881, 60458, 388139, 150578, 35891, 44084, 183350, 199739, 109629, 183360, 339008, 379973, 183368, 314442, 134220, 355408, 27728, 76882, 281691, 158815, 183392, 109664, 322657, 35938, 76904, 281706, 52332, 101490, 126067, 257142, 339063, 240758, 60538, 19582, 265343, 76928, 248963, 134276, 273544, 339087, 281743, 109719, 191653, 306343, 265385, 371883, 355500, 273581, 134325, 167094, 363704, 93371, 167117, 232658, 363732, 404693, 93398, 27866, 339164, 85224, 134384, 19697, 101620, 290037, 396537, 314623, 142592, 322816, 208130, 314630, 331015, 158993, 118034, 339224, 363800, 191769, 396574, 224544, 224549, 52518, 3365, 363823, 167217, 265522, 208180, 388407, 249146, 290110, 232766, 60737, 347460, 19782, 183624, 396616, 27980, 216396, 134478, 273742, 36180, 52565, 273749, 19798, 314715, 101724, 380254, 118114, 372068, 109926, 134503, 355690, 19819, 101739, 60782, 347506, 331124, 232820, 306552, 175482, 216448, 273799, 249224, 52617, 339338, 413068, 216462, 109967, 249235, 282004, 290199, 142746, 249248, 363939, 191914, 28076, 331187, 404916, 85427, 249273, 167357, 52669, 363967, 142784, 273862, 118215, 60877, 265680, 372176, 101845, 77271, 314847, 364000, 11752, 134634, 60909, 3580, 273926, 126470, 323080, 134665, 183820, 413202, 167444, 36374, 118295, 364055, 282134, 355866, 192026, 200220, 306718, 282146, 69165, 52782, 77363, 85559, 101943, 314935, 339514, 151100, 298557, 347710, 241224, 3659, 233040, 11859, 126548, 274003, 142936, 233050, 380506, 126559, 372322, 208486, 36455, 20073, 355946, 282221, 405106, 274036, 347764, 314998, 347766, 126584, 20091, 274044, 36477, 183942, 388744, 380560, 298641, 224919, 151194, 347802, 44699, 77475, 167588, 339622, 265898, 52907, 143026, 20149, 265912, 380601, 126650, 52923, 249538, 356037, 331462, 3782, 85702, 3789, 306899, 298707, 306906, 175834, 372448, 12002, 175846, 397032, 356079, 93935, 388849, 126707, 102132, 249591, 413433, 216825, 249600, 356097, 233219, 274185, 208654, 126737, 372499, 69396, 20245, 405269, 216854, 388890, 397093, 167717, 12071, 77608, 110376, 151333, 282413, 331567, 143152, 36658, 175929, 126781, 274237, 175935, 331583, 110408, 36682, 372556, 3917, 266064, 36689, 151383, 85849, 339810, 85859, 200562, 388990, 348033, 307074, 102280, 348046, 12176, 151441, 372626, 184211, 102293, 298902, 20377, 298905, 233371, 167837, 225182, 176031, 176035, 339875, 380840, 266154, 315307, 225196, 28597, 331701, 274359, 290759, 12231, 184265, 380879, 12244, 36821, 331741, 102367, 258019, 167915, 53228, 307181, 94188, 389110, 348160, 290816, 323586, 290820, 192526, 118802, 69651, 364566, 323606, 94232, 86044, 20510, 200734, 348192, 405535, 192544, 12328, 45098, 110640, 45105, 12342, 405558, 241724, 77884, 167999, 307265, 12355, 299080, 69704, 258126, 241746, 77908, 86100, 110678, 12378, 266333, 323677, 20582, 86118, 151663, 356464, 340089, 86137, 4220, 151676, 4227, 12430, 405651, 159893, 315547, 200860, 381085, 176286, 77981, 348328, 192684, 78004, 340149, 282807, 250040, 405714, 151763, 151765, 389334, 250076, 389344, 143585, 94434, 151778, 250088, 151784, 4339, 86262, 119032, 143609, 20729, 86264, 209150, 225534, 127230, 274696, 356616, 28936, 364811, 250124, 348424, 381197, 192778, 340240, 119058, 241942, 315672, 160026, 127264, 37156, 250149, 127274, 28971, 332075, 192813, 381231, 307505, 86328, 102712, 94520, 315707, 127293, 160061, 4416, 291138, 45379, 45380, 307525, 332106, 348493, 151885, 364889, 78171, 12638, 143712, 242025, 61817, 381305, 143739, 20863, 209279, 315775, 184704, 283019, 299406, 143760, 250259, 233877, 37269, 94617, 356765, 291231, 61856, 324003, 242090, 373169, 324023, 348600, 151992, 29116, 102852, 152004, 332232, 192969, 168399, 242129, 332242, 274900, 315865, 78301, 373223, 266727, 274921, 266730, 29167, 45554, 389619, 193012, 406004, 70134, 160246, 225788, 70141, 307721, 29195, 119307, 119310, 283152, 86545, 299538, 45587, 94739, 225814, 389656, 242209, 160291, 381480, 119337, 78379, 94765, 340526, 373293, 258605, 127537, 406066, 266809, 242235, 332352, 62016, 397892, 348741, 127563, 307789, 193104, 266833, 234069, 275032, 70233, 119386, 53851, 258657, 111202, 168545, 209509, 217706, 135787, 193135, 70261, 127606, 217718, 397944, 217719, 21114, 406135, 225916, 275072, 225924, 225927, 94857, 266891, 225933, 21136, 160403, 307867, 160412, 201375, 275106, 324264, 324270, 29366, 266946, 299719, 406216, 250570, 193230, 291538, 13011, 94932, 291542, 275163, 381666, 78564, 250596, 86766, 217838, 37614, 144112, 242418, 258798, 381684, 54006, 406262, 332536, 37626, 324352, 258817, 94981, 201483, 373516, 103181, 406288, 185107, 103202, 348963, 103207, 168750, 160561, 283442, 283444, 340791, 111423, 86849, 70466, 37700, 54090, 29518, 217939, 324435, 267094, 316250, 21339, 250716, 86883, 201582, 144239, 70511, 168819, 406397, 291711, 316287, 234370, 78724, 209799, 258956, 234382, 201614, 250768, 86932, 201621, 193431, 242583, 54175, 95137, 62370, 267172, 13222, 13225, 308139, 29613, 78766, 406445, 86957, 258998, 168894, 177088, 250819, 168900, 234437, 78790, 250824, 234442, 37834, 209866, 365518, 218062, 365520, 29661, 234464, 144359, 242670, 144367, 390130, 209906, 283635, 103412, 340981, 185334, 226297, 234490, 21501, 87044, 218116, 177156, 29703, 341001, 78858, 324625, 332818, 160787, 349203, 160786, 308247, 119834, 341021, 193565, 365599, 341024, 218144, 283679, 70692, 136229, 193572, 152613, 275520, 201797, 259146, 275531, 62540, 95309, 87118, 201805, 267346, 242773, 62552, 341081, 29788, 324705, 37987, 193642, 70768, 316535, 169082, 267390, 46207, 291968, 128130, 332933, 341141, 5271, 185496, 242841, 201883, 70814, 13471, 79008, 234663, 54447, 54454, 128184, 226489, 242874, 341181, 332994, 234691, 251076, 349388, 185549, 218319, 316624, 365781, 5334, 275676, 5345, 169186, 267492, 333028, 292070, 62700, 79085, 201970, 398581, 333046, 79097, 5372, 193789, 390401, 79106, 177410, 226564, 283909, 300292, 324871, 193799, 62731, 177421, 54546, 21781, 324887, 308504, 202009, 87321, 29981, 308510, 226596, 152868, 406823, 316711, 136492, 185645, 292141, 390447, 349493, 161078, 374081, 365889, 251204, 390469, 226630, 111942, 152902, 54600, 406854, 128332, 161101, 169294, 70991, 374095, 185681, 193883, 120156, 382302, 103775, 234853, 87401, 324970, 128367, 243062, 333178, 95611, 62844, 316810, 136590, 349586, 13715, 136596, 300437, 365974, 30104, 308633, 316826, 382364, 95646, 95647, 316833, 382373, 390568, 79272, 128427, 95660, 30125, 79276, 71085, 267695, 243121, 161198, 161209, 153020, 136636, 30141, 120254, 71104, 259517, 136643, 374213, 71109, 54727, 234951, 275915, 112079, 21973, 226776, 234970, 292317, 144862, 308703, 38365, 251362, 398821, 120296, 226792, 259562, 349677, 13808, 390641, 390644, 333301, 71159, 38392, 87544, 30205, 308737, 185860, 202251, 120332, 153100, 341518, 5650, 325145, 79387, 38430, 71200, 128546, 390704, 292401, 398900, 153143, 210492, 218685, 316990, 226885, 366150, 226891, 136780, 177742, 276047, 202320, 87634, 382547, 300630, 71257, 325210, 267868, 366178, 398946, 54891, 120431, 325233, 333426, 63091, 267894, 63097, 341627, 120444, 243328, 235137, 185985, 87683, 267904, 374405, 87688, 71306, 87691, 153239, 358040, 13976, 333464, 349856, 161441, 13984, 22178, 382629, 30383, 374448, 218801, 87730, 63159, 112312, 22202, 161467, 14010, 14016, 128707, 54981, 284360, 276172, 79567, 218831, 161487, 243412, 63197, 284385, 284389, 390893, 333550, 202480, 63219, 194292, 243444, 399095, 128760, 235260, 300799, 177922, 22278, 390923, 300812, 169750, 341783, 284443, 202524, 112413, 5918, 153375, 63264, 71467, 366386, 5946, 87866, 251708, 259902, 210751, 161599, 251713, 55106, 243523, 104254, 227141, 46919, 317258, 112465, 96081, 407380, 251733, 112468, 374615, 374613, 317278, 235358, 14177, 96098, 227174, 292712, 325482, 96112, 284530, 202619, 112524, 358288, 292753, 145297, 300951, 399257, 284588, 325551, 374704, 399282, 219058, 325565, 161727, 391105, 128963, 194500, 79812, 96199, 186314, 169934, 350160, 284627, 366547, 284643, 268263, 63464, 194537, 243691, 382960, 260086, 292854, 358392, 210940, 317438, 317443, 317444, 30726, 309254, 366606, 251931, 71713, 137250, 219172, 14376, 317485, 391220, 96309, 145462, 30777, 243769, 342076, 88124, 112702, 161856, 161864, 383049, 358474, 153680, 55378, 112723, 251988, 153687, 325726, 88161, 55395, 333924, 260198, 284776, 309353, 96360, 317547, 153710, 235642, 333947, 342143, 153734, 235655, 47241, 80011, 276624, 71824, 129171, 366739, 145557, 47254, 80021, 407705, 39066, 309404, 88220, 120994, 63653, 55464, 170154, 333995, 202926, 366769, 366781, 399556, 39111, 47304, 227528, 88265, 350413, 342234, 55515, 235744, 30946, 63721, 55530, 325867, 71917, 301302, 194808, 252155, 276733, 47360, 317703, 80139, 268555, 391441, 309521, 55571, 383254, 104732, 350493, 22815, 301344, 383263, 317735, 170281, 383276, 170285, 375086, 284972, 63794, 260403, 399670, 22844, 153918, 178496, 284993, 194881, 72003, 325956, 47430, 72006, 6473, 293196, 244049, 55634, 203091, 153939, 219477, 22871, 293207, 301405, 14686, 252257, 334181, 334183, 129395, 293241, 211322, 276857, 252286, 186752, 129409, 383362, 285059, 219524, 309636, 285071, 219538, 154008, 121245, 342453, 309690, 137660, 334269, 145856, 195008, 186818, 326087, 80328, 39372, 137677, 285136, 219602, 31186, 162259, 39384, 23003, 80360, 72169, 268778, 186862, 6639, 39408, 342514, 14837, 211445, 260601, 317946, 317948, 285182, 55809, 252419, 23052, 399885, 309774, 268815, 317969, 137747, 23059, 39444, 268834, 55843, 154146, 260645, 399913, 195115, 391723, 236079, 326197, 96823, 358968, 244285, 227901, 236098, 121412, 301642, 145995, 154189, 268877, 137808, 399958, 260696, 285272, 105050, 55899, 268888, 105053, 203353, 121440, 375392, 268898, 129635, 260709, 162409, 236143, 39539, 137843, 39541, 105078, 268918, 350840, 88697, 391803, 23167, 260736, 326274, 80521, 72331, 244366, 14994, 96916, 47764, 301726, 162473, 285353, 408235, 129709, 268975, 105143, 64186, 15035, 47803, 80572, 6844, 39612, 219844, 105158, 391880, 342729, 162509, 367309, 6863, 39632, 211665, 113357, 105171, 219870, 244448, 72416, 187105, 342756, 31461, 113382, 6887, 88804, 146153, 39660, 137970, 97011, 375541, 154361, 359161, 383740, 236284, 88831, 56068, 318213, 211722, 375563, 154384, 113430, 285466, 310043, 383778, 359203, 285475, 310054, 64301, 342833, 228149, 15166, 244547, 23363, 211781, 359239, 179021, 318286, 56145, 367441, 310101, 367446, 23381, 15192, 138074, 228187, 301916, 326491, 113500, 56159, 367457, 56167, 285545, 236396, 220012, 170862, 121712, 15221, 244598, 285564, 31613, 15230, 48002, 121735, 80775, 211853, 261007, 31636, 408473, 23450, 228251, 301980, 211869, 285597, 252833, 195490, 80803, 105380, 220076, 121778, 15283, 269238, 195512, 138170, 105405, 195517, 383938, 367555, 293827, 56258, 269254, 408518, 359369, 375757, 383951, 261073, 236498, 400337, 318420, 400341, 277463, 7131, 343004, 228317, 392167, 7145, 351210, 162795, 261105, 89074, 162802, 179188, 244721, 31737, 39930, 113661, 187390, 244734, 7168, 277508, 130053, 408590, 130062, 400401, 146452, 154653, 326686, 7199, 400413, 310308, 121897, 285740, 228398, 179251, 236608, 326721, 187461, 261191, 293960, 187464, 384072, 228427, 408650, 228430, 171088, 269393, 318547, 359511, 269400, 269401, 293976, 293980, 64607, 40032, 56417, 31842, 72809, 146538, 400489, 334961, 294003, 195703, 154745, 72826, 359546, 384124, 187516, 89214, 236673, 138369, 220291, 171141, 261253, 72848, 23699, 23702, 146582, 15520, 400555, 294067, 359604, 130229, 195766, 72885, 244919, 195770, 400571, 261314, 367811, 376011, 326860, 244943, 40147, 343253, 89302, 400600, 294107, 220384, 277728, 113892, 392420, 204009, 359659, 408813, 408816, 23793, 228600, 23802, 359675, 171263, 122112, 285960, 367881, 105737, 146699, 32015, 72978, 163096, 32027, 318750, 48416, 212256, 130344, 48425, 302386, 154933, 367926, 105783, 15669, 392505, 253243, 392509, 400703, 105795, 89414, 56647, 105799, 32074, 146763, 40269, 204111, 294227, 277843, 40278, 97623, 73055, 392544, 302437, 376167, 269680, 204150, 245115, 64891, 155007, 294272, 359810, 368007, 130441, 376207, 48529, 261521, 261522, 327057, 146838, 130455, 294296, 7574, 15780, 48551, 64936, 146858, 409003, 376237, 351661, 302515, 155060, 318900, 351675, 204221, 122309, 24006, 97735, 228808, 343494, 359878, 261578, 376268, 269785, 155098, 204251, 171486, 40415, 327140, 245225, 335338, 187883, 97777, 409075, 220660, 32248, 122364, 24062, 261635, 212484, 384517, 171528, 351752, 89610, 335372, 204301, 122386, 163353, 228890, 409117, 400927, 327201, 212518, 220713, 32298, 228907, 130610, 409139, 97850, 351804, 130623, 114240, 409152, 130624, 155203, 335430, 253512, 278089, 294472, 360019, 245333, 56921, 278109, 335453, 32355, 15972, 138853, 269923, 106088, 138862, 97904, 360057, 368249, 40571, 220793, 40573, 310909, 32384, 351876, 245382, 138888, 179849, 106121, 130701, 32401, 245401, 212639, 245408, 138912, 196258, 237218, 343717, 147110, 179881, 40624, 65202, 57011, 130750, 171713, 89795, 7880, 81616, 155346, 155347, 360148, 81623, 409320, 48874, 319211, 163564, 384746, 32496, 98033, 204531, 130804, 106235, 270076, 196350, 368391, 327438, 220948, 229142, 179991, 409368, 409369, 401178, 253724, 16157, 130849, 261927, 196393, 40745, 130858, 229167, 343856, 286511, 384819, 311092, 155447, 229176, 73528, 335672, 196411, 319295, 319299, 196420, 24389, 171845, 32582, 393031, 48969, 327498, 311113, 81741, 384846, 73551, 270163, 261974, 16223, 73577, 155501, 278387, 65398, 89976, 171901, 343945, 24457, 65419, 286604, 335757, 368526, 278414, 32654, 106386, 294803, 81813, 335767, 360344, 270232, 81822, 327585, 188328, 40875, 384942, 352185, 253881, 245697, 196548, 319431, 360397, 221133, 335826, 57299, 171990, 278493, 114656, 139239, 172008, 49129, 81899, 114678, 49146, 73724, 90110}\n",
            "Client 100: 2892 samples\n",
            "<class '__main__.ShakespeareDataset'> - (length: 413629)\n",
            "{278530, 360456, 114696, 147467, 294930, 319507, 409620, 122900, 40979, 49172, 65567, 311328, 122917, 286758, 221224, 196656, 286769, 57394, 122931, 262195, 270389, 73778, 352311, 163895, 262206, 245823, 393281, 254020, 122950, 73800, 245834, 163919, 221264, 106577, 32850, 278610, 204884, 114771, 254038, 204883, 82008, 286809, 172124, 172126, 213090, 295018, 245872, 295025, 229498, 270459, 106621, 16514, 270470, 327815, 352391, 204940, 73869, 163985, 360593, 106643, 41109, 155797, 90267, 319647, 385184, 368803, 336036, 73894, 245927, 57513, 385193, 180395, 360620, 196781, 16558, 106670, 221356, 401586, 385202, 229560, 237759, 49344, 262341, 270538, 368846, 377040, 180435, 90324, 196821, 229587, 409813, 216, 409817, 106715, 188641, 123107, 57576, 82153, 90346, 319723, 295148, 327918, 360692, 24821, 188662, 49399, 98559, 256, 123138, 98564, 131333, 311559, 377096, 254228, 196884, 278, 82196, 164122, 221469, 155934, 82205, 41250, 254244, 33060, 57637, 131366, 377128, 155941, 229670, 246059, 360751, 303408, 114994, 262456, 131386, 319803, 278844, 65852, 213312, 188740, 360774, 24904, 344394, 344395, 377163, 106834, 213331, 278869, 344405, 303449, 311643, 246108, 237917, 311651, 106858, 311659, 57708, 352625, 164211, 377204, 336243, 246132, 16763, 90495, 205184, 344451, 8582, 33164, 49549, 8595, 237972, 98716, 57758, 385438, 106913, 418, 41381, 57766, 360875, 303531, 82349, 57779, 278965, 385462, 98742, 311736, 246200, 156095, 33217, 115138, 344518, 205255, 410057, 131531, 328145, 344532, 156118, 401885, 197086, 221670, 188903, 8681, 8684, 254450, 319987, 262643, 287221, 221686, 57848, 213500, 33278, 352769, 410117, 197127, 344584, 287242, 311819, 523, 221713, 320024, 16921, 410144, 393771, 148016, 377402, 572, 410173, 328257, 8772, 131654, 180812, 328268, 25167, 66128, 213585, 246360, 180826, 82522, 156250, 148064, 164450, 221795, 295525, 123496, 279144, 180842, 279150, 156276, 25204, 148092, 328316, 107134, 221838, 107151, 33422, 58004, 328341, 230042, 279198, 295585, 8869, 172711, 377512, 262827, 82609, 33458, 254643, 344762, 115390, 336574, 344773, 344774, 279237, 230089, 189132, 279245, 369360, 180947, 49880, 344793, 172763, 271074, 287464, 107240, 49901, 312046, 115438, 271093, 140023, 17143, 74489, 353019, 361211, 148222, 246527, 8959, 180994, 254723, 295691, 172812, 353035, 74523, 394013, 181023, 164643, 246565, 394022, 205606, 82729, 213807, 279346, 320307, 115508, 303923, 402231, 172855, 17211, 320315, 74560, 172870, 262990, 107345, 82770, 353112, 344921, 394074, 181083, 131932, 58206, 361312, 58212, 295782, 238440, 320362, 131952, 279410, 230258, 279416, 361337, 50044, 25470, 897, 172931, 9095, 312202, 91025, 279446, 25497, 320410, 213916, 189346, 295843, 271275, 287659, 172982, 312247, 410555, 74684, 205760, 82884, 394187, 230349, 254926, 148431, 123858, 377811, 91091, 197591, 50137, 361433, 386011, 99293, 213981, 173023, 148445, 246753, 156644, 320486, 336870, 279540, 9205, 173051, 1024, 254981, 1029, 353291, 279564, 140302, 279567, 320531, 295956, 246805, 42005, 33815, 164887, 99356, 353309, 58397, 123939, 197667, 353322, 279596, 33843, 25653, 58423, 287801, 50233, 91194, 410691, 320583, 255047, 197703, 222282, 279629, 123985, 107603, 312405, 9307, 230497, 353380, 9317, 99432, 164969, 74858, 345194, 91244, 1130, 328816, 132211, 205941, 345209, 25721, 402556, 345221, 173192, 402569, 17544, 312457, 107660, 181390, 369812, 378005, 238741, 402586, 17564, 17565, 165025, 99492, 369828, 33962, 328878, 33970, 361652, 287925, 287927, 345273, 263353, 206016, 140480, 287948, 74958, 74959, 99539, 34004, 279770, 345306, 66785, 206050, 402658, 312547, 17643, 279787, 99565, 58604, 156909, 247024, 222449, 296178, 206066, 402680, 378110, 9471, 42245, 148741, 58632, 17680, 337170, 9492, 9493, 99607, 34075, 230684, 361757, 369950, 34079, 230692, 173356, 206126, 83248, 1336, 271673, 222522, 247096, 394556, 50494, 386367, 238915, 83267, 189766, 353606, 181581, 148813, 140632, 214366, 50528, 263520, 83297, 410984, 50539, 148852, 66938, 50555, 173434, 370057, 247182, 304529, 378262, 312726, 263574, 345494, 312736, 353697, 378274, 304548, 263590, 34217, 157100, 337325, 34223, 337335, 304568, 320952, 386490, 34235, 91588, 329158, 361927, 26056, 361929, 189899, 198093, 271823, 230865, 157138, 99795, 296404, 378325, 296406, 361941, 181720, 288212, 42453, 255455, 394720, 361953, 320998, 140776, 108015, 83439, 402933, 337399, 288251, 239101, 239104, 75265, 288258, 9736, 288265, 337423, 108050, 17938, 42518, 132630, 370200, 296473, 42529, 362020, 173604, 321064, 378418, 34358, 411191, 132667, 239164, 50751, 42564, 271943, 50761, 288338, 1619, 58968, 50778, 140891, 140899, 58983, 353895, 362097, 296561, 124531, 190073, 67197, 83582, 403082, 304782, 99986, 99988, 263828, 108183, 140971, 231084, 370349, 296623, 173745, 50868, 149174, 124605, 206528, 132800, 75460, 403150, 321232, 288470, 222935, 280280, 280285, 116446, 34528, 181985, 272098, 141028, 75493, 304874, 75500, 190194, 18163, 321269, 272118, 91894, 18165, 345847, 280311, 345852, 1802, 304907, 124686, 263954, 59155, 42775, 198426, 239394, 329507, 247588, 313125, 239396, 75559, 304946, 51003, 403263, 255807, 18241, 132929, 190271, 132935, 288584, 190281, 51019, 362320, 395090, 108372, 100181, 91989, 214871, 26459, 116572, 67421, 288603, 321375, 370531, 255846, 165739, 329587, 141174, 255865, 59260, 264060, 288639, 59264, 173954, 173959, 239495, 362377, 116619, 214927, 83857, 214932, 337814, 288663, 100250, 42906, 165790, 214946, 403364, 1957, 75689, 133033, 173997, 26542, 141241, 108474, 198591, 165825, 83906, 92100, 354247, 305096, 206794, 346058, 313295, 255955, 100313, 378842, 75740, 59364, 378852, 83944, 92139, 182255, 165872, 59377, 2034, 255990, 2042, 337918, 100351, 67584, 362497, 231426, 247812, 231432, 26633, 141322, 174091, 395276, 198666, 100366, 206869, 395287, 165914, 124955, 370716, 10271, 206879, 198687, 346143, 272420, 149543, 124969, 329770, 182319, 321584, 346162, 75827, 403511, 297017, 239673, 116798, 321600, 378945, 280641, 403524, 165957, 313415, 395337, 378955, 280655, 92244, 108628, 321622, 403544, 362587, 354403, 133225, 362605, 2157, 247917, 34928, 125041, 346226, 206967, 133243, 100478, 395390, 239745, 387202, 84100, 272522, 141458, 34962, 280728, 182424, 297114, 395422, 2214, 157864, 26796, 247984, 100529, 174263, 256186, 174269, 264383, 157887, 84161, 313535, 116933, 288966, 411849, 256202, 207054, 133336, 387289, 379097, 354523, 256220, 133340, 248029, 166111, 92387, 84196, 18662, 215272, 215274, 67820, 346352, 354544, 411893, 223478, 297207, 215288, 207100, 43261, 297213, 329986, 280835, 43269, 346377, 59661, 330002, 117011, 280854, 157976, 289049, 67865, 100639, 26914, 321826, 321833, 207147, 387381, 166200, 10566, 190793, 35148, 379227, 158047, 67936, 43378, 264565, 330102, 59767, 10616, 215415, 313722, 174459, 354685, 239998, 387456, 240000, 125314, 207239, 305547, 199052, 264589, 289167, 248211, 59797, 117143, 412057, 84379, 272797, 305566, 166310, 215463, 207274, 305579, 149932, 403889, 43448, 199096, 92600, 371131, 371132, 223677, 190911, 231872, 141763, 289224, 387530, 264652, 100816, 35283, 109019, 68062, 281056, 346595, 125415, 18920, 281067, 76272, 362993, 354802, 395766, 51706, 84475, 51712, 240129, 182785, 117251, 84482, 346628, 256521, 133643, 371214, 313872, 338456, 207384, 289304, 240162, 297509, 174629, 51760, 141878, 10814, 27200, 207427, 371270, 158278, 371274, 166476, 51789, 215630, 141903, 264789, 199254, 92759, 248409, 166490, 322144, 223841, 281186, 51809, 92775, 264807, 281193, 297577, 240236, 141933, 404078, 191089, 371314, 92790, 412278, 182910, 35455, 133769, 281232, 92825, 92826, 125598, 223905, 346789, 182955, 371373, 412334, 207538, 297651, 191157, 142006, 215736, 240315, 338622, 281280, 289473, 133828, 363205, 215754, 182986, 363213, 223950, 27342, 379605, 150229, 297685, 35544, 338649, 387802, 346848, 248546, 409238, 183018, 289520, 314097, 223990, 166649, 314105, 158457, 322303, 330503, 43786, 264976, 174864, 133906, 297745, 289552, 19221, 117525, 117526, 404248, 248598, 158485, 191267, 191273, 125740, 84782, 215857, 43826, 150323, 215865, 412473, 224062, 232257, 265026, 11079, 387912, 133960, 224075, 363345, 76630, 35674, 281435, 379741, 19294, 76642, 109412, 215915, 412526, 338799, 297844, 387956, 232315, 27516, 322429, 224126, 166784, 84865, 289667, 306057, 387978, 11147, 142217, 174986, 224146, 191379, 199572, 199571, 158614, 322456, 265119, 224159, 142241, 404386, 76706, 265125, 363431, 224168, 191402, 256938, 166828, 166829, 60335, 207792, 142260, 355257, 150459, 68540, 330686, 388031, 240577, 216003, 388041, 101322, 166857, 232401, 43989, 125909, 355289, 117723, 232415, 273375, 412642, 191460, 404452, 3048, 232426, 363500, 273389, 289774, 297987, 404483, 60421, 109575, 142349, 322577, 265233, 85013, 44054, 191520, 175137, 101408, 199721, 19501, 166958, 232493, 158770, 347188, 134196, 330807, 298042, 93247, 412738, 216143, 232527, 404561, 306259, 117847, 371800, 117849, 68696, 355419, 60510, 117857, 126051, 52326, 167019, 175214, 404599, 306297, 388218, 134270, 330882, 35970, 191620, 117895, 355465, 314506, 158857, 11403, 380046, 134288, 347280, 363666, 330899, 371860, 306335, 404640, 191650, 11432, 36013, 93358, 224429, 60592, 134322, 36020, 19636, 380086, 142522, 208062, 150725, 298182, 355527, 289994, 355530, 339148, 371917, 117970, 265427, 314582, 371927, 109799, 44266, 257259, 126191, 101616, 298225, 314613, 298235, 240893, 404734, 363775, 281858, 216328, 396557, 298256, 224532, 159000, 273694, 306463, 257312, 216355, 388388, 281898, 68908, 208178, 27954, 19764, 339253, 85305, 257340, 273726, 68927, 208193, 322890, 314704, 109908, 322902, 175449, 109914, 347484, 167263, 191839, 28003, 380265, 347505, 134515, 355703, 257400, 126328, 413050, 126332, 331135, 404864, 134529, 257420, 372113, 44433, 93595, 208285, 331166, 298397, 3490, 347555, 306603, 273835, 257451, 273839, 28080, 257457, 224694, 257463, 380345, 363963, 44480, 249287, 306636, 191952, 290258, 232916, 208342, 28121, 404955, 118239, 290271, 265699, 265701, 101863, 3560, 52713, 404968, 282091, 257520, 3573, 339445, 413176, 372217, 388602, 60923, 323069, 36350, 142848, 241155, 36373, 11800, 413210, 364061, 183838, 331295, 159265, 3619, 52771, 298535, 364073, 355887, 3631, 282161, 306738, 36404, 323125, 69175, 93751, 413241, 36412, 339517, 413250, 60998, 273991, 224841, 20041, 257612, 306764, 314959, 314961, 151122, 77396, 52823, 372314, 405083, 52831, 28257, 44646, 11883, 241260, 413292, 167534, 69239, 339576, 315006, 372354, 380547, 331398, 61066, 315030, 200346, 405148, 388768, 372388, 200360, 241325, 200366, 183982, 347824, 126637, 3764, 167606, 3767, 20157, 249537, 85698, 339651, 249542, 397001, 11978, 143051, 380620, 200396, 208590, 36560, 265938, 151253, 126679, 69335, 331482, 159456, 110306, 192227, 44772, 118501, 44775, 134889, 192233, 405228, 134899, 364276, 233207, 52984, 3836, 143101, 216833, 323330, 126723, 85765, 61189, 331528, 3848, 12042, 3856, 184085, 306969, 315162, 225052, 306973, 175912, 315178, 20266, 356141, 298797, 134959, 102193, 28466, 388917, 257845, 110393, 44861, 298814, 77638, 241481, 61259, 94029, 372564, 28501, 184152, 94041, 225113, 53088, 225130, 159595, 36720, 135024, 388979, 266109, 249729, 290690, 126851, 274308, 61317, 44933, 110471, 69516, 290711, 208794, 356254, 389027, 28579, 372645, 217005, 61359, 397238, 356282, 389051, 135103, 143298, 118723, 274375, 151499, 307147, 266187, 339918, 12241, 20433, 331731, 298965, 135128, 28644, 225253, 85990, 110568, 192493, 12270, 151534, 200688, 94193, 135154, 61428, 323572, 184309, 110584, 77817, 86013, 102400, 299014, 217098, 397325, 364563, 299028, 380951, 200732, 339997, 102432, 331809, 94248, 127018, 86059, 282668, 77869, 61488, 4147, 307255, 200760, 364601, 86074, 217148, 36927, 168000, 159809, 307279, 233552, 217170, 77910, 397399, 340054, 94298, 274534, 159850, 258155, 405612, 53355, 159856, 118896, 397436, 348288, 290945, 405638, 356487, 102536, 217223, 86152, 45207, 225431, 258206, 372897, 184483, 241828, 209062, 4262, 340136, 282791, 372907, 209068, 290991, 405680, 151730, 225462, 12470, 102584, 364726, 250039, 356539, 12477, 331966, 61630, 389310, 241857, 192705, 61635, 61632, 340171, 78027, 372940, 94416, 225493, 274653, 307426, 37094, 389352, 119018, 151786, 405740, 307437, 282862, 159984, 94454, 364791, 233722, 12540, 168189, 381182, 37122, 397571, 110855, 323849, 364814, 274707, 176412, 28957, 250143, 192799, 127263, 127270, 151847, 119088, 373041, 258355, 332090, 356668, 127295, 217407, 143680, 69952, 94528, 192837, 381256, 307534, 282960, 340316, 151904, 119136, 233829, 45414, 192872, 323946, 29036, 151933, 291197, 127361, 373122, 209285, 45445, 4487, 209289, 340362, 356748, 176530, 102803, 373148, 78238, 364959, 184737, 250275, 111012, 143782, 151975, 143791, 94648, 324024, 127420, 61891, 356808, 135625, 315856, 356822, 225751, 405985, 389602, 274915, 258530, 70121, 119276, 242166, 86521, 283130, 266745, 209404, 184831, 102911, 20992, 373251, 209416, 127501, 70171, 119324, 225823, 119328, 53793, 37415, 356903, 70193, 274999, 201276, 135741, 37438, 299587, 406085, 127561, 184906, 160334, 176727, 45658, 299610, 168539, 152160, 193125, 168550, 103015, 53866, 381546, 242285, 356973, 201325, 381559, 373377, 258692, 209544, 62089, 86667, 37518, 70290, 37523, 258708, 144021, 94871, 37527, 299675, 176799, 62123, 144044, 307887, 29361, 365239, 332472, 135871, 291520, 332482, 185027, 86723, 78530, 373449, 340683, 37582, 37584, 266962, 21209, 144094, 389855, 29408, 291556, 242410, 234224, 340720, 185083, 86787, 373508, 267026, 250645, 299807, 398113, 258850, 135972, 226086, 365352, 332587, 13105, 103232, 4935, 365383, 381769, 349005, 45904, 226130, 234325, 29528, 62301, 152419, 168806, 21351, 78696, 62312, 299884, 127860, 62330, 250751, 95108, 209798, 406409, 349068, 398221, 177038, 201615, 373645, 250770, 308114, 357269, 62358, 340889, 78749, 13216, 406436, 242597, 185253, 349095, 13221, 349102, 316334, 291763, 234420, 54197, 406454, 299960, 5055, 127935, 259017, 406473, 275405, 86995, 357333, 406488, 250844, 78814, 209890, 365541, 103397, 95207, 152550, 250863, 87035, 365565, 46084, 390149, 95239, 308232, 54291, 119827, 234517, 398355, 136212, 128024, 46108, 226334, 46112, 218145, 357411, 242725, 234535, 62508, 291885, 218157, 283697, 169011, 54325, 267326, 218175, 341057, 144452, 29767, 87115, 46155, 382031, 128080, 382038, 193623, 185432, 398424, 226394, 259158, 5213, 398430, 201830, 373863, 300136, 160878, 242799, 291953, 21621, 177276, 283780, 349321, 87182, 193680, 5265, 79000, 201884, 226462, 136358, 283816, 177322, 46252, 46256, 283825, 177334, 382137, 128191, 324800, 13508, 193734, 242888, 226508, 169164, 103634, 292051, 193750, 120023, 292058, 5339, 5340, 333021, 226526, 29918, 226527, 152797, 79075, 177386, 70892, 292078, 29935, 144625, 193784, 324861, 144639, 62726, 259336, 324874, 382220, 341261, 324879, 357653, 390429, 275742, 136477, 193821, 390434, 259366, 5415, 177454, 13615, 382254, 21809, 70962, 161070, 267576, 292153, 234808, 349503, 333120, 136513, 161094, 283974, 234830, 406863, 177488, 13646, 136529, 79187, 283988, 251219, 62807, 251233, 374114, 152936, 144746, 398700, 284013, 226670, 79227, 365951, 21889, 87426, 103812, 300427, 71051, 365972, 243092, 95636, 365975, 161178, 300442, 406939, 382377, 62890, 202155, 234922, 226733, 259503, 161203, 218548, 218549, 38325, 325048, 177599, 169409, 275906, 308677, 382406, 153032, 357832, 13769, 210385, 366045, 103902, 390622, 38372, 325094, 202222, 144879, 153072, 112113, 185841, 226806, 46583, 300535, 38397, 169473, 349698, 103938, 194058, 136718, 366094, 374289, 177683, 374293, 243223, 300568, 144923, 259613, 308766, 300573, 30241, 185890, 276007, 136746, 169520, 284209, 292404, 63029, 104002, 136771, 177730, 259653, 243272, 357962, 317003, 259659, 333389, 398931, 308820, 284244, 300642, 185956, 226919, 112232, 185960, 251495, 276075, 120430, 194158, 177777, 398961, 5747, 226932, 300661, 153206, 63095, 333431, 128633, 325245, 120445, 46719, 38525, 349826, 292483, 30348, 145039, 267921, 30356, 382619, 153244, 120480, 317094, 161448, 46760, 308910, 13999, 276143, 366263, 284344, 136887, 87735, 54973, 407232, 87747, 202439, 54997, 358105, 235227, 349917, 153310, 317150, 177886, 399076, 390887, 186087, 325354, 145130, 333549, 128750, 399086, 399096, 71419, 112379, 63231, 390916, 210704, 136989, 104223, 349985, 63268, 169766, 333609, 276274, 145202, 300852, 71477, 145207, 79674, 186174, 14148, 161607, 161610, 366411, 22350, 186191, 218965, 276310, 382808, 350043, 55156, 391032, 71547, 350076, 145276, 268159, 63360, 14209, 259976, 145291, 46987, 210830, 300943, 6038, 38807, 243607, 128924, 6047, 112547, 87977, 276402, 260018, 341942, 374713, 268218, 300987, 374720, 178113, 407496, 276425, 71628, 6096, 161747, 399322, 161756, 276454, 268264, 350189, 366577, 301045, 30712, 186363, 366592, 202756, 178181, 325638, 178184, 284683, 161805, 63502, 251919, 71704, 178204, 325660, 55327, 153634, 120869, 120871, 383015, 161833, 88108, 210992, 96306, 153652, 104500, 251961, 219194, 63547, 22588, 63550, 391234, 194632, 178258, 251986, 47190, 211033, 137309, 268383, 292965, 292966, 276582, 30826, 79982, 292977, 186484, 309368, 104570, 104571, 186497, 161921, 104580, 317579, 235660, 333965, 284817, 227474, 112793, 194718, 350371, 55463, 71854, 96434, 252087, 104634, 260291, 22726, 39112, 145609, 30921, 6348, 121040, 301265, 96464, 252112, 301268, 342232, 334041, 80090, 88283, 391385, 14557, 317656, 55522, 55523, 211172, 145638, 293095, 145640, 358634, 350443, 276715, 375024, 268530, 334069, 88317, 342271, 334082, 170245, 309513, 30985, 6410, 121104, 227602, 334099, 47381, 80150, 47385, 375066, 47391, 6433, 235809, 260389, 6437, 71974, 284970, 366895, 6448, 407858, 203076, 129352, 342346, 170318, 317775, 399696, 285010, 129363, 31063, 80222, 121183, 350558, 178533, 244070, 366950, 260456, 285032, 31081, 80230, 145774, 293239, 6521, 350591, 260482, 326020, 211338, 342413, 227725, 301457, 334226, 154004, 252313, 129435, 285087, 31137, 104869, 47529, 154026, 367018, 6572, 342449, 252339, 186816, 309704, 211401, 252364, 383437, 96721, 342483, 129498, 391644, 219616, 358882, 137700, 203238, 63976, 63980, 121332, 203252, 203254, 145912, 276986, 195066, 6651, 178685, 383486, 47615, 219652, 211460, 203270, 367110, 367123, 104979, 408088, 178713, 309790, 178722, 113188, 162343, 301610, 309807, 326192, 244273, 23090, 285240, 121401, 178746, 72253, 154175, 358975, 14914, 6724, 105031, 105032, 186953, 252489, 375376, 31312, 408145, 326226, 162387, 375383, 113241, 23131, 342621, 23137, 408162, 170598, 121446, 113263, 326255, 186992, 309874, 88692, 244341, 195191, 350841, 14973, 285314, 64135, 260746, 285324, 187021, 121487, 121489, 252571, 318108, 367261, 39579, 326303, 375464, 105129, 383659, 244400, 39601, 211642, 170685, 400061, 146115, 56006, 228046, 244436, 96980, 350936, 375517, 170721, 47843, 23270, 31462, 309990, 170731, 97004, 80621, 375533, 269040, 97009, 350962, 359154, 137972, 293627, 211711, 301829, 367368, 178962, 129812, 244502, 375578, 351003, 400158, 260896, 236323, 285477, 39719, 23335, 211753, 88878, 105268, 260916, 80694, 359225, 31547, 260925, 342846, 301885, 6978, 219974, 105287, 375631, 56144, 113489, 47954, 301911, 252767, 64353, 326503, 244586, 318318, 260980, 236405, 211830, 342900, 244603, 367484, 154494, 351102, 359302, 342919, 113547, 15258, 383903, 277409, 64417, 310180, 187301, 236457, 334765, 408493, 138157, 113592, 318395, 310204, 342974, 203710, 326593, 187335, 39879, 72648, 105419, 146382, 302031, 23507, 285657, 130011, 154588, 121823, 375778, 195556, 392168, 310248, 367597, 285680, 269297, 154610, 293882, 334844, 367612, 89086, 211964, 105478, 97289, 187409, 15382, 7191, 31768, 187419, 252958, 343077, 285734, 56360, 7213, 7215, 80944, 375856, 220211, 408628, 367678, 56385, 121922, 40004, 31813, 318534, 302151, 179272, 48201, 269398, 130141, 293983, 408671, 130146, 187491, 64616, 285800, 212085, 154742, 105596, 261245, 171133, 138373, 375951, 318607, 72849, 105619, 351390, 23711, 253094, 375975, 343215, 244912, 351409, 130233, 392382, 384194, 81091, 277708, 212173, 187598, 269516, 81106, 56535, 310489, 89310, 302303, 244959, 244962, 146660, 220388, 408806, 253157, 359657, 48364, 310511, 212212, 146680, 228601, 171256, 376059, 171260, 326909, 7422, 343295, 285945, 400644, 367882, 97546, 40202, 351499, 15636, 204053, 64796, 171294, 261408, 64807, 294185, 343342, 15663, 81202, 212279, 40251, 212284, 318784, 40262, 408907, 408908, 286029, 310613, 48471, 114010, 130395, 212321, 146790, 154983, 114030, 204143, 32111, 154997, 286072, 81275, 32124, 343421, 146813, 359807, 32128, 318850, 105860, 179588, 220556, 171410, 228755, 64918, 97687, 15768, 228760, 48541, 343454, 212383, 228769, 351654, 81323, 187825, 286131, 327092, 409013, 138677, 40377, 15821, 376275, 228820, 122325, 105941, 163287, 368090, 97761, 81378, 359907, 24034, 302569, 261611, 220651, 359917, 245231, 384498, 212488, 24075, 343570, 278037, 376343, 171551, 237087, 138788, 310823, 122409, 351795, 400950, 196150, 73274, 73278, 351809, 171585, 368198, 245321, 212554, 253521, 294486, 220765, 171614, 89701, 302693, 40551, 351848, 360038, 351850, 163449, 253563, 130684, 122503, 286344, 319117, 155277, 138895, 89743, 401038, 73363, 294547, 65174, 351894, 89752, 122518, 155289, 147099, 212635, 130717, 376478, 73375, 48799, 122529, 401055, 286372, 16037, 360106, 278189, 335537, 286392, 253630, 294593, 155330, 188099, 89798, 171719, 327373, 327374, 65232, 204499, 237270, 179927, 294616, 401114, 253659, 351966, 311006, 351968, 130785, 155367, 311016, 237291, 32498, 401139, 294644, 81653, 311030, 294646, 40696, 294649, 32504, 196344, 48893, 278270, 220927, 220928, 40705, 57091, 352013, 212750, 401169, 73491, 73493, 73496, 98074, 130843, 98077, 311071, 65314, 24358, 237357, 327469, 360245, 48953, 311101, 155453, 352065, 294722, 139076, 171846, 114505, 327499, 294739, 229204, 139093, 73556, 302937, 286555, 360284, 163676, 221020, 237407, 73568, 212832, 16227, 73575, 163689, 212845, 278383, 409455, 221048, 221058, 384901, 253833, 49033, 229261, 32666, 49051, 204707, 352164, 163751, 106408, 253868, 24492, 114608, 65459, 81844, 393143, 171959, 278457, 343996, 237501, 270271, 40897, 401347, 311237, 49093, 409543, 163786, 122826, 8140, 24524, 409550, 122836, 278485, 303061, 270297, 131034, 360411, 106458, 40937, 327659, 65516, 286703, 393204, 106485, 32758, 8184, 40954, 253951}\n",
            "Client 116: 2892 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-5a99cfb0e0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m                                           \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                           \u001b[0;34m'Shakesphere LSTM on IID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"green\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                           \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                                           )\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-86b428d1af11>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, rounds, batch_size, lr, ds, data_dict, test_ds, C, K, E, M, plt_title, plt_color, classes, eval_every, tb_logger)\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Client {k}: {len(idxs) if idxs else len(ds_)} samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0mlocal_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClientUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m       \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m       \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-2dea267f9cad>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-c1d7c3656b5c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hc)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 662\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-irvQHuNNTtB"
      },
      "source": [
        "hyperparams = {'rounds': rounds,\n",
        "               'C': C,\n",
        "               'K': K,\n",
        "               'E': E,\n",
        "               'batch_size': batch_size,\n",
        "               'lr': lr,\n",
        "               'M': M,\n",
        "               }\n",
        "\n",
        "log_dict['Shakespeare LSTM on IID'] = {'train_loss': train_loss_multiple_runs, \n",
        "                                'test_loss': test_loss_multiple_runs, \n",
        "                                'test_accuracy': test_accuracy_multiple_runs,\n",
        "                                'history': history,\n",
        "                                'hyperparams': hyperparams,\n",
        "                                }"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QO0GkVyKEgu"
      },
      "source": [
        "## LSTM FedAvg on Non IID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wsHRfwmKGdS",
        "outputId": "6d1e83b0-915d-48e6-a8ff-f54872724d3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_dict, test_ds = noniid_partition(corpus, seq_length=seq_length, val_split=False)\n",
        " \n",
        "total_clients = len(data_dict.keys())  \n",
        "'Total users:', total_clients"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Objective 413629 / 413629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Total users:', 143)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsz18EcKj3v_",
        "outputId": "599a226e-25df-412f-bcad-afd7b30b59f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(data_dict['THE_TRAGEDY_OF_KING_LEAR_NYM']['train_ds'])\n",
        "print(data_dict['THE_TRAGEDY_OF_KING_LEAR_NYM'])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.ShakespeareFedDataset'> - (length: 968)\n",
            "{'train_ds': <class '__main__.ShakespeareFedDataset'> - (length: 968), 'val_ds': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRz4-fZKj-hi",
        "outputId": "9a22f383-886a-4f6e-a319-3f33363957e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_ds)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.ShakespeareDataset'> - (length: 413629)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNJZG5tvKGgd",
        "outputId": "a4164fcf-54f3-4019-dd58-626aca9e3220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "72d12659f553443197727b77b84fec7f",
            "a7bcfb8caf2c46388c6923be55eae2b4",
            "0f0bcd77e2d1431d9d0becdccd8b0575",
            "530c38a866754525b70209b2fdb8f9ad",
            "323d04e8628940a892efbd701ed878c9",
            "79920e9aeea642da9cf0cf7fba5ddf8e",
            "0acc13e842854dfa8f74f4e056e6efe2",
            "22e224d8d6bd4aa0b38d5b2681332fa3"
          ]
        }
      },
      "source": [
        "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
        "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
        "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
        "\n",
        "for exp_num in range(NUM_REPEAT):\n",
        "  print(\"Experiment Run Number: \", exp_num)\n",
        "  # partition dataset\n",
        "  data_dict, test_ds = noniid_partition(corpus, seq_length=seq_length, val_split=False)\n",
        "  total_clients = len(data_dict.keys())  \n",
        "  # number of training rounds\n",
        "  rounds = 2\n",
        "  # client fraction\n",
        "  C = 0.07  # 10 clients\n",
        "  # number of clients\n",
        "  K = total_clients\n",
        "  # number of training passes on local dataset for each roung\n",
        "  E = 1\n",
        "  # batch size\n",
        "  batch_size = 10\n",
        "  # learning Rate\n",
        "  lr = 0.8\n",
        "  # proximal term constant\n",
        "  M = 0.01\n",
        "\n",
        "  shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,\n",
        "                                        embedding_dim=embedding_dim,\n",
        "                                        hidden_dim=hidden_dim,\n",
        "                                        classes=num_classes,\n",
        "                                        lstm_layers=lstm_layers,\n",
        "                                        dropout=dropout,\n",
        "                                        batch_first=True\n",
        "                                        )\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      shakespeare_lstm.cuda()\n",
        "\n",
        "  lstm_non_iid_trained, train_loss, test_accuracy, test_loss, history = training(shakespeare_lstm,\n",
        "                                                rounds, batch_size, lr,\n",
        "                                                None, #  ds empty as it is included in data_dict\n",
        "                                                data_dict,\n",
        "                                                test_ds,\n",
        "                                                C, K, E, M,\n",
        "                                                'Shakespeare LSTM on Non IID', \"green\",\n",
        "                                                corpus, # classes,\n",
        "                                                )\n",
        "\n",
        "  train_loss_multiple_runs[exp_num] = train_loss\n",
        "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
        "  test_loss_multiple_runs[exp_num] = test_loss\n",
        "\n",
        "  del lstm_non_iid_trained\n",
        "  torch.cuda.empty_cache()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment Run Number:  0\n",
            "Objective 413629 / 413629\n",
            "Clients: 10/143 -> [  3  67  60  49  73  86  30  33 127 133]\n",
            "Client 3: 886 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72d12659f553443197727b77b84fec7f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.ShakespeareFedDataset'> - (length: 392)\n",
            "None\n",
            "Client 67: 392 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-806884bb7024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                 \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                                 \u001b[0;34m'Shakesphere LSTM on Non IID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"green\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                                                 \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# classes,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                                                 )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-86b428d1af11>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, rounds, batch_size, lr, ds, data_dict, test_ds, C, K, E, M, plt_title, plt_color, classes, eval_every, tb_logger)\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Client {k}: {len(idxs) if idxs else len(ds_)} samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0mlocal_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClientUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-2dea267f9cad>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batchSize, learning_rate, epochs, idxs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-2d241b8592f5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, idxs)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uANkBpTRKGkv"
      },
      "source": [
        " hyperparams = {'rounds': rounds,\n",
        "               'C': C,\n",
        "               'K': K,\n",
        "               'E': E,\n",
        "               'batch_size': batch_size,\n",
        "               'lr': lr,\n",
        "               'M': M,\n",
        "               }\n",
        "\n",
        "log_dict['Shakespeare LSTM on Non IID'] = {'train_loss': train_loss_multiple_runs, \n",
        "                                'test_loss': test_loss_multiple_runs, \n",
        "                                'test_accuracy': test_accuracy_multiple_runs,\n",
        "                                'history': history,\n",
        "                                'hyperparams': hyperparams,\n",
        "                                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShdScPNuQzUQ"
      },
      "source": [
        "## Pickle Log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwHt7jviQ1AV"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(path + 'Local_Round_FedMed.pkl', 'wb') as file:\n",
        "  pickle.dump(log_dict, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNkwXxO8Q3Ei",
        "outputId": "17e83444-0e78-4c7b-f9db-e61633e84fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "log_dict"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Shakesphere LSTM on IID': {'history': [{'accuracy': 0.22512764969828253,\n",
              "    'f1_macro': 0.013327934807246774,\n",
              "    'f1_weighted': 0.11248259645553993,\n",
              "    'loss': 2.962272966155212,\n",
              "    'train_loss': 3.207810998012416},\n",
              "   {'accuracy': 0.27386662540615814,\n",
              "    'f1_macro': 0.029954878040916653,\n",
              "    'f1_weighted': 0.17872878886765992,\n",
              "    'loss': 2.6773384965629967,\n",
              "    'train_loss': 2.891806939907918}],\n",
              "  'hyperparams': {'C': 0.07,\n",
              "   'E': 1,\n",
              "   'K': 143,\n",
              "   'M': 0.01,\n",
              "   'batch_size': 10,\n",
              "   'lr': 0.8,\n",
              "   'rounds': 2},\n",
              "  'test_accuracy': [[0.23033034194646448, 0.27388596626953426],\n",
              "   [0.22512764969828253, 0.27386662540615814]],\n",
              "  'test_loss': [[2.9268954864840158, 2.6418257244651797],\n",
              "   [2.962272966155212, 2.6773384965629967]],\n",
              "  'train_loss': [[3.21350852694584, 2.850550765879092],\n",
              "   [3.207810998012416, 2.891806939907918]]}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSs9xXfpQ3ML"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(path + 'Local_Round_FedMed.pkl', 'rb') as file:\n",
        "  log_dict = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8ep-MalQ3PO"
      },
      "source": [
        "print([test_acc[-1] for test_acc in log_dict['Shakespeare LSTM on IID']['test_accuracy']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-2I2g0HQ3WA"
      },
      "source": [
        "print([test_acc[-1] for test_acc in log_dict['Shakespeare LSTM on IID']['test_accuracy']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfR3lDa7Q-8s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}