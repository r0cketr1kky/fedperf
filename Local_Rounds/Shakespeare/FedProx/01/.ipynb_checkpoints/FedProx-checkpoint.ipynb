{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tushar-semwal/fedperf/blob/main/Vineeth/Local_Rounds/Shakesphere/FedProx/FedProx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WQ6Rq0UiG6ev"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummaryX in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: unidecode in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (1.19.1)\n",
      "Requirement already satisfied: torch in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (1.7.1+cu101)\n",
      "Requirement already satisfied: pandas in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torchsummaryX) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from torch->torchsummaryX) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from pandas->torchsummaryX) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from pandas->torchsummaryX) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas->torchsummaryX) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummaryX unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yKcpjZLrQQJV"
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    import os\n",
    "    path = '/content/drive/MyDrive/Colab Notebooks/OpenMined/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "except:\n",
    "    path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0_nKpfq2h1R"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DLLNM9X2JbQ8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 26 12:02:59 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 29%   53C    P2   110W / 250W |   2311MiB / 11178MiB |     60%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 29%   52C    P2   115W / 250W |   1584MiB / 11178MiB |     42%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     71868      C   ...3/envs/QSGD-PT/bin/python      781MiB |\n",
      "|    0   N/A  N/A     71906      C   ...3/envs/QSGD-PT/bin/python      781MiB |\n",
      "|    0   N/A  N/A     74743      C   ...3/envs/QSGD-PT/bin/python      747MiB |\n",
      "|    1   N/A  N/A     73633      C   ...3/envs/QSGD-PT/bin/python      791MiB |\n",
      "|    1   N/A  N/A     73673      C   ...3/envs/QSGD-PT/bin/python      791MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import copy\n",
    "from functools import reduce\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchsummaryX import summary as summaryx\n",
    "from torchvision import transforms, utils, datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Check assigned GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "# set manual seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# general reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# gpu training specific\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY4eWzGiL6Mj"
   },
   "source": [
    "## Load the Shakespeare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hf03LRxof7Zj"
   },
   "outputs": [],
   "source": [
    "!rm -Rf data\n",
    "!mkdir -p data scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ngygA4-Fgobx"
   },
   "outputs": [],
   "source": [
    "GENERATE_DATASET = False  # If False, download the dataset provided by the q-FFL paper\n",
    "DATA_DIR = 'data/'\n",
    "# Dataset generation params\n",
    "SAMPLES_FRACTION = 1.  # If using an already generated dataset\n",
    "# SAMPLES_FRACTION = 0.2  # Fraction of total samples in the dataset - FedProx default script\n",
    "# SAMPLES_FRACTION = 0.05  # Fraction of total samples in the dataset - qFFL\n",
    "TRAIN_FRACTION = 0.8  # Train set size\n",
    "MIN_SAMPLES = 0  # Min samples per client (for filtering purposes) - FedProx\n",
    "# MIN_SAMPLES = 64  # Min samples per client (for filtering purposes) - qFFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nUmwJgJygoYD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-26 12:02:59--  http://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5757108 (5.5M) [text/plain]\n",
      "Saving to: ‘data/shakespeare.txt’\n",
      "\n",
      "data/shakespeare.tx 100%[===================>]   5.49M  1.07MB/s    in 5.8s    \n",
      "\n",
      "2021-04-26 12:03:06 (975 KB/s) - ‘data/shakespeare.txt’ saved [5757108/5757108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download raw dataset\n",
    "# !wget https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt -O data/shakespeare.txt\n",
    "!wget --adjust-extension http://www.gutenberg.org/files/100/100-0.txt -O data/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4dCvx80BgoVr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1n46Mftp3_ahRi1Z6jYhEriyLtdRDS1tD\n",
      "To: /home/vineeth/code/OM/Vineeth/Local_Rounds/Shakespeare/FedProx/01/shakespeare.zip\n",
      "2.96MB [00:00, 7.55MB/s]\n",
      "Archive:  shakespeare.zip\n",
      "   creating: shakespeare_paper/\n",
      "   creating: shakespeare_paper/test/\n",
      "  inflating: shakespeare_paper/test/all_data_niid_2_keep_0_test_8.json  \n",
      "   creating: shakespeare_paper/train/\n",
      "  inflating: shakespeare_paper/train/all_data_niid_2_keep_0_train_8.json  \n"
     ]
    }
   ],
   "source": [
    "if not GENERATE_DATASET:\n",
    "    !rm -Rf data/train data/test\n",
    "    !gdown --id 1n46Mftp3_ahRi1Z6jYhEriyLtdRDS1tD  # Download Shakespeare dataset used by the FedProx paper\n",
    "    !unzip shakespeare.zip\n",
    "    !mv -f shakespeare_paper/train data/\n",
    "    !mv -f shakespeare_paper/test data/\n",
    "    !rm -R shakespeare_paper/ shakespeare.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a4pzFvPvhQhq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Length: 90\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "with open('data/shakespeare.txt', 'r') as f:\n",
    "    data = list(unidecode(f.read()))\n",
    "    corpus = list(set(list(data)))\n",
    "print('Corpus Length:', len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cce_-qnxhD4n"
   },
   "source": [
    "#### Dataset Preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Rt13M4IcgoTV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if GENERATE_DATASET:\n",
    "    # Download dataset generation scripts\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/preprocess_shakespeare.py -O scripts/preprocess_shakespeare.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/shake_utils.py -O scripts/shake_utils.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/data/shakespeare/preprocess/gen_all_data.py -O scripts/gen_all_data.py\n",
    "\n",
    "    # Download data preprocessing scripts\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/utils/sample.py -O scripts/sample.py\n",
    "    !wget https://raw.githubusercontent.com/ml-lab/FedProx/master/utils/remove_users.py -O scripts/remove_users.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EIEyRW27goPo"
   },
   "outputs": [],
   "source": [
    "# Running scripts\n",
    "if GENERATE_DATASET:\n",
    "    !mkdir -p data/raw_data data/all_data data/train data/test\n",
    "    !python scripts/preprocess_shakespeare.py data/shakespeare.txt data/raw_data\n",
    "    !python scripts/gen_all_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mq8V6v_4hhhD"
   },
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "H2SjEBKoWDxv"
   },
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, x, y, corpus, seq_length):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.corpus = corpus\n",
    "        self.corpus_size = len(self.corpus)\n",
    "        super(ShakespeareDataset, self).__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__} - (length: {self.__len__()})'\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        input_seq = self.x[i]\n",
    "        next_char = self.y[i]\n",
    "        # print('\\tgetitem', i, input_seq, next_char)\n",
    "        input_value = self.text2charindxs(input_seq).long()\n",
    "        target_value = self.get_label_from_char(next_char)\n",
    "        return input_value, target_value\n",
    "\n",
    "    def text2charindxs(self, text):\n",
    "        tensor = torch.zeros(len(text), dtype=torch.int32)\n",
    "        for i, c in enumerate(text):\n",
    "            tensor[i] = self.get_label_from_char(c)\n",
    "        return tensor\n",
    "\n",
    "    def get_label_from_char(self, c):\n",
    "        return self.corpus.index(c)\n",
    "\n",
    "    def get_char_from_label(self, l):\n",
    "        return self.corpus[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fgJtS62lYAN"
   },
   "source": [
    "##### Federated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5DqL5pTmgn5X"
   },
   "outputs": [],
   "source": [
    "class ShakespeareFedDataset(ShakespeareDataset):\n",
    "    def __init__(self, x, y, corpus, seq_length):\n",
    "        super(ShakespeareFedDataset, self).__init__(x, y, corpus, seq_length)\n",
    "\n",
    "    def dataloader(self, batch_size, shuffle=True):\n",
    "        return DataLoader(self,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XelbyPsDlfgb"
   },
   "source": [
    "## Partitioning & Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOBblyFGlwlU"
   },
   "source": [
    "### IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cSZFWKmsgn1p"
   },
   "outputs": [],
   "source": [
    "def iid_partition_(dataset, clients):\n",
    "  \"\"\"\n",
    "  I.I.D paritioning of data over clients\n",
    "  Shuffle the data\n",
    "  Split it between clients\n",
    "  \n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "\n",
    "  num_items_per_client = int(len(dataset)/clients)\n",
    "  client_dict = {}\n",
    "  image_idxs = [i for i in range(len(dataset))]\n",
    "\n",
    "  for i in range(clients):\n",
    "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
    "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
    "\n",
    "  return client_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-lGwDyhSll9h"
   },
   "outputs": [],
   "source": [
    "def iid_partition(corpus, seq_length=80, val_split=False):\n",
    "\n",
    "    train_file = [os.path.join(DATA_DIR, 'train', f) for f in os.listdir(f'{DATA_DIR}/train') if f.endswith('.json')][0]\n",
    "    test_file = [os.path.join(DATA_DIR, 'test', f) for f in os.listdir(f'{DATA_DIR}/test') if f.endswith('.json')][0]\n",
    "\n",
    "    with open(train_file, 'r') as file:\n",
    "        data_train = json.loads(unidecode(file.read()))\n",
    "\n",
    "    with open(test_file, 'r') as file:\n",
    "        data_test = json.loads(unidecode(file.read()))\n",
    "\n",
    "    \n",
    "    total_samples_train = sum(data_train['num_samples'])\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_test, y_test = [], []\n",
    "    # x_val, y_val = [], []\n",
    "\n",
    "    users = list(zip(data_train['users'], data_train['num_samples']))\n",
    "    # random.shuffle(users)\n",
    "\n",
    "\n",
    "\n",
    "    total_samples = int(sum(data_train['num_samples']) * SAMPLES_FRACTION)\n",
    "    print('Objective', total_samples, '/', sum(data_train['num_samples']))\n",
    "    sample_count = 0\n",
    "    \n",
    "    for i, (author_id, samples) in enumerate(users):\n",
    "\n",
    "        if sample_count >= total_samples:\n",
    "            print('Max samples reached', sample_count, '/', total_samples)\n",
    "            break\n",
    "\n",
    "        if samples < MIN_SAMPLES: # or data_train['num_samples'][i] > 10000:\n",
    "            print('SKIP', author_id, samples)\n",
    "            continue\n",
    "        else:\n",
    "            udata_train = data_train['user_data'][author_id]\n",
    "            max_samples = samples if (sample_count + samples) <= total_samples else (sample_count + samples - total_samples) \n",
    "            \n",
    "            sample_count += max_samples\n",
    "            # print('sample_count', sample_count)\n",
    "\n",
    "            x_train.extend(data_train['user_data'][author_id]['x'][:max_samples])\n",
    "            y_train.extend(data_train['user_data'][author_id]['y'][:max_samples])\n",
    "\n",
    "            author_data = data_test['user_data'][author_id]\n",
    "            test_size = int(len(author_data['x']) * SAMPLES_FRACTION)\n",
    "\n",
    "            if val_split:\n",
    "                x_test.extend(author_data['x'][:int(test_size / 2)])\n",
    "                y_test.extend(author_data['y'][:int(test_size / 2)])\n",
    "                # x_val.extend(author_data['x'][int(test_size / 2):])\n",
    "                # y_val.extend(author_data['y'][int(test_size / 2):int(test_size)])\n",
    "\n",
    "            else:\n",
    "                x_test.extend(author_data['x'][:int(test_size)])\n",
    "                y_test.extend(author_data['y'][:int(test_size)])\n",
    "\n",
    "    train_ds = ShakespeareDataset(x_train, y_train, corpus, seq_length)\n",
    "    test_ds = ShakespeareDataset(x_test, y_test, corpus, seq_length)\n",
    "    # val_ds = ShakespeareDataset(x_val, y_val, corpus, seq_length)\n",
    "\n",
    "    data_dict = iid_partition_(train_ds, clients=len(users))\n",
    "\n",
    "    return train_ds, data_dict, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFvc8mLoouKa"
   },
   "source": [
    "### Non-IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GZ76WsCZot9s"
   },
   "outputs": [],
   "source": [
    "def noniid_partition(corpus, seq_length=80, val_split=False):\n",
    "\n",
    "    train_file = [os.path.join(DATA_DIR, 'train', f) for f in os.listdir(f'{DATA_DIR}/train') if f.endswith('.json')][0]\n",
    "    test_file = [os.path.join(DATA_DIR, 'test', f) for f in os.listdir(f'{DATA_DIR}/test') if f.endswith('.json')][0]\n",
    "\n",
    "    with open(train_file, 'r') as file:\n",
    "        data_train = json.loads(unidecode(file.read()))\n",
    "\n",
    "    with open(test_file, 'r') as file:\n",
    "        data_test = json.loads(unidecode(file.read()))\n",
    "\n",
    "    \n",
    "    total_samples_train = sum(data_train['num_samples'])\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    x_test, y_test = [], []\n",
    "\n",
    "    users = list(zip(data_train['users'], data_train['num_samples']))\n",
    "    # random.shuffle(users)\n",
    "\n",
    "    total_samples = int(sum(data_train['num_samples']) * SAMPLES_FRACTION)\n",
    "    print('Objective', total_samples, '/', sum(data_train['num_samples']))\n",
    "    sample_count = 0\n",
    "    \n",
    "    for i, (author_id, samples) in enumerate(users):\n",
    "\n",
    "        if sample_count >= total_samples:\n",
    "            print('Max samples reached', sample_count, '/', total_samples)\n",
    "            break\n",
    "\n",
    "        if samples < MIN_SAMPLES: # or data_train['num_samples'][i] > 10000:\n",
    "            print('SKIP', author_id, samples)\n",
    "            continue\n",
    "        else:\n",
    "            udata_train = data_train['user_data'][author_id]\n",
    "            max_samples = samples if (sample_count + samples) <= total_samples else (sample_count + samples - total_samples) \n",
    "            \n",
    "            sample_count += max_samples\n",
    "            # print('sample_count', sample_count)\n",
    "\n",
    "            x_train = data_train['user_data'][author_id]['x'][:max_samples]\n",
    "            y_train = data_train['user_data'][author_id]['y'][:max_samples]\n",
    "\n",
    "            train_ds = ShakespeareFedDataset(x_train, y_train, corpus, seq_length)\n",
    "\n",
    "            x_val, y_val = None, None\n",
    "            val_ds = None\n",
    "            author_data = data_test['user_data'][author_id]\n",
    "            test_size = int(len(author_data['x']) * SAMPLES_FRACTION)\n",
    "            if val_split:\n",
    "                x_test += author_data['x'][:int(test_size / 2)]\n",
    "                y_test += author_data['y'][:int(test_size / 2)]\n",
    "                x_val = author_data['x'][int(test_size / 2):]\n",
    "                y_val = author_data['y'][int(test_size / 2):int(test_size)]\n",
    "\n",
    "                val_ds = ShakespeareFedDataset(x_val, y_val, corpus, seq_length)\n",
    "\n",
    "            else:\n",
    "                x_test += author_data['x'][:int(test_size)]\n",
    "                y_test += author_data['y'][:int(test_size)]\n",
    "\n",
    "            data_dict[author_id] = {\n",
    "                'train_ds': train_ds,\n",
    "                'val_ds': val_ds\n",
    "            }\n",
    "\n",
    "    test_ds = ShakespeareFedDataset(x_test, y_test, corpus, seq_length)\n",
    "\n",
    "    return data_dict, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWVOxcAao2_t"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQQQ2mLeo6EA"
   },
   "source": [
    "### Shakespeare LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2mGXTrXRot7R"
   },
   "outputs": [],
   "source": [
    "class ShakespeareLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, classes, lstm_layers=2, dropout=0.1, batch_first=True):\n",
    "        super(ShakespeareLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.classes = classes\n",
    "        self.no_layers = lstm_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=self.classes,\n",
    "                                      embedding_dim=self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim,\n",
    "                            num_layers=self.no_layers,\n",
    "                            batch_first=batch_first, \n",
    "                            dropout=dropout if self.no_layers > 1 else 0.)\n",
    "        self.fc = nn.Linear(hidden_dim, self.classes)\n",
    "\n",
    "    def forward(self, x, hc=None):\n",
    "        batch_size = x.size(0)\n",
    "        x_emb = self.embedding(x)\n",
    "        self.lstm.flatten_parameters()\n",
    "        out, (ht, ct) = self.lstm(x_emb.view(batch_size, -1, self.embedding_dim), hc)\n",
    "        dense = self.fc(ht[-1])\n",
    "        return dense\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (Variable(torch.zeros(self.no_layers, batch_size, self.hidden_dim)),\n",
    "                Variable(torch.zeros(self.no_layers, batch_size, self.hidden_dim)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QsuJlVipMc8"
   },
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "n_Vb0BYpot5I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shakespeare LSTM SUMMARY\n",
      "==========================================================\n",
      "            Kernel Shape   Output Shape  Params  Mult-Adds\n",
      "Layer                                                     \n",
      "0_embedding      [8, 90]    [10, 80, 8]     720        720\n",
      "1_lstm                 -  [10, 80, 256]  798720     794624\n",
      "2_fc           [256, 90]       [10, 90]   23130      23040\n",
      "----------------------------------------------------------\n",
      "                      Totals\n",
      "Total params          822570\n",
      "Trainable params      822570\n",
      "Non-trainable params       0\n",
      "Mult-Adds             818384\n",
      "==========================================================\n",
      "            Kernel Shape   Output Shape  Params  Mult-Adds\n",
      "Layer                                                     \n",
      "0_embedding      [8, 90]    [10, 80, 8]     720        720\n",
      "1_lstm                 -  [10, 80, 256]  798720     794624\n",
      "2_fc           [256, 90]       [10, 90]   23130      23040\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "seq_length = 80 # mcmahan17a, fedprox, qFFL\n",
    "\n",
    "shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,  \n",
    "                                   embedding_dim=8,  # mcmahan17a, fedprox, qFFL\n",
    "                                   hidden_dim=256,  # mcmahan17a, fedprox impl\n",
    "                                   # hidden_dim=100,  # fedprox paper\n",
    "                                   classes=len(corpus),\n",
    "                                   lstm_layers=2,\n",
    "                                   dropout=0.1,\n",
    "                                   batch_first=True\n",
    "                                   )\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  shakespeare_lstm.cuda()\n",
    "\n",
    "hc = shakespeare_lstm.init_hidden(batch_size)\n",
    "\n",
    "x_sample = torch.zeros((batch_size, seq_length),\n",
    "                       dtype=torch.long,\n",
    "                       device=(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')))\n",
    "\n",
    "x_sample[0][0] = 1\n",
    "x_sample\n",
    "\n",
    "print(\"\\nShakespeare LSTM SUMMARY\")\n",
    "print(summaryx(shakespeare_lstm, x_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn7egnzTpeks"
   },
   "source": [
    "## FedProx Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFFAfTOwpk4j"
   },
   "source": [
    "### Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oyYjWa6IpnTY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "367THsiTpo-C"
   },
   "outputs": [],
   "source": [
    "def plot_scores(history, exp_id, title, suffix):\n",
    "    accuracies = [x['accuracy'] for x in history]\n",
    "    f1_macro = [x['f1_macro'] for x in history]\n",
    "    f1_weighted = [x['f1_weighted'] for x in history]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(accuracies, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test Accuracy', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_Accuracy_{suffix}.jpg', format='jpg', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(f1_macro, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test F1 (macro)', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_F1_Macro_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(f1_weighted, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test F1 (weighted)', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_F1_Weighted_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_losses(history, exp_id, title, suffix):\n",
    "    val_losses = [x['loss'] for x in history]\n",
    "    train_losses = [x['train_loss'] for x in history]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_losses, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Train Loss', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Train_Loss_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(val_losses, 'tab:orange')\n",
    "    ax.set(xlabel='Rounds', ylabel='Test Loss', title=title)\n",
    "    ax.grid()\n",
    "    fig.savefig(f'{BASE_DIR}/{exp_id}/Test_Loss_{suffix}.jpg', format='jpg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c640e4NnpksE"
   },
   "source": [
    "### Systems Heterogeneity Simulations\n",
    "\n",
    "Generate epochs for selected clients based on percentage of devices that corresponds to heterogeneity. \n",
    "\n",
    "Assign x number of epochs (chosen unifirmly at random between [1, E]) to 0%, 50% or 90% of the selected devices, respectively. Settings where 0% devices perform fewer than E epochs of work correspond to the environments without system heterogeneity, while 90% of the devices sending their partial solutions corresponds to highly heterogenous system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zuEZYnl5ot2m"
   },
   "outputs": [],
   "source": [
    "def GenerateLocalEpochs(percentage, size, max_epochs):\n",
    "  ''' Method generates list of epochs for selected clients\n",
    "  to replicate system heteroggeneity\n",
    "\n",
    "  Params:\n",
    "    percentage: percentage of clients to have fewer than E epochs\n",
    "    size:       total size of the list\n",
    "    max_epochs: maximum value for local epochs\n",
    "  \n",
    "  Returns:\n",
    "    List of size epochs for each Client Update\n",
    "\n",
    "  '''\n",
    "\n",
    "  # if percentage is 0 then each client runs for E epochs\n",
    "  if percentage == 0:\n",
    "      return np.array([max_epochs]*size)\n",
    "  else:\n",
    "    # get the number of clients to have fewer than E epochs\n",
    "    heterogenous_size = int((percentage/100) * size)\n",
    "\n",
    "    # generate random uniform epochs of heterogenous size between 1 and E\n",
    "    #epoch_list = np.random.randint(1, max_epochs, heterogenous_size)\n",
    "    epoch_list = np.ones(heterogenous_size, dtype=np.int32)\n",
    "    \n",
    "    # the rest of the clients will have E epochs\n",
    "    remaining_size = size - heterogenous_size\n",
    "    rem_list = [max_epochs]*remaining_size\n",
    "\n",
    "    epoch_list = np.append(epoch_list, rem_list, axis=0)\n",
    "    \n",
    "    # shuffle the list and return\n",
    "    np.random.shuffle(epoch_list)\n",
    "\n",
    "    return epoch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ9PZM0Gp9ve"
   },
   "source": [
    "### Local Training (Client Update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "EDJFltwdotzZ"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, dataset, idxs):\n",
    "      self.dataset = dataset\n",
    "      self.idxs = list(idxs)\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.idxs)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "      data, label = self.dataset[self.idxs[item]]\n",
    "      return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HtRzU5Yepddq"
   },
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "  def __init__(self, dataset, batchSize, learning_rate, epochs, idxs, mu, algorithm):\n",
    "    # self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batchSize, shuffle=True)\n",
    "    if hasattr(dataset, 'dataloader'):\n",
    "        self.train_loader = dataset.dataloader(batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    self.algorithm = algorithm\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epochs = epochs\n",
    "    self.mu = mu\n",
    "\n",
    "  def train(self, model):\n",
    "    # print(\"Client training for {} epochs.\".format(self.epochs))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    proximal_criterion = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.5)\n",
    "\n",
    "    # use the weights of global model for proximal term calculation\n",
    "    global_model = copy.deepcopy(model)\n",
    "\n",
    "    # calculate local training time\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    e_loss = []\n",
    "    for epoch in range(1, self.epochs+1):\n",
    "\n",
    "      train_loss = 0.0\n",
    "\n",
    "      model.train()\n",
    "      for data, labels in self.train_loader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "          data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # make a forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # calculate the loss + the proximal term\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "        if self.algorithm == 'fedprox':\n",
    "          proximal_term = 0.0\n",
    "\n",
    "          # iterate through the current and global model parameters\n",
    "          for w, w_t in zip(model.parameters(), global_model.parameters()) :\n",
    "            # update the proximal term \n",
    "            #proximal_term += torch.sum(torch.abs((w-w_t)**2))\n",
    "            proximal_term += (w-w_t).norm(2)\n",
    "\n",
    "          loss = criterion(output, labels) + (self.mu/2)*proximal_term\n",
    "        else:\n",
    "          loss = criterion(output, labels)\n",
    "    \n",
    "        # do a backwards pass\n",
    "        loss.backward()\n",
    "        # perform a single optimization step\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "      # average losses\n",
    "      train_loss = train_loss/len(self.train_loader.dataset)\n",
    "      e_loss.append(train_loss)\n",
    "\n",
    "    total_loss = sum(e_loss)/len(e_loss)\n",
    "\n",
    "    return model.state_dict(), total_loss, (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3crFDN0xqGu6"
   },
   "source": [
    "### Server Side Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "c085xSOoqEHk"
   },
   "outputs": [],
   "source": [
    "def training(model, rounds, batch_size, lr, ds, data_dict, test_ds, C, K, E, mu, percentage, plt_title, plt_color, target_test_accuracy,\n",
    "             classes, algorithm=\"fedprox\", eval_every=1, tb_logger=None):\n",
    "  \"\"\"\n",
    "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
    "  Specifically, this function is used for the server side training and weight update\n",
    "\n",
    "  Params:\n",
    "    - model:           PyTorch model to train\n",
    "    - rounds:          Number of communication rounds for the client update\n",
    "    - batch_size:      Batch size for client update training\n",
    "    - lr:              Learning rate used for client update training\n",
    "    - ds:              Dataset used for training\n",
    "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
    "    - test_data_dict:  Data used for testing the model\n",
    "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
    "    - K:               Total number of clients\n",
    "    - E:               Number of training passes each client makes over its local dataset per round\n",
    "    - mu:              proximal term constant\n",
    "    - percentage:      percentage of selected client to have fewer than E epochs\n",
    "  Returns:\n",
    "    - model:           Trained model on the server\n",
    "  \"\"\"\n",
    "\n",
    "  # global model weights\n",
    "  global_weights = model.state_dict()\n",
    "\n",
    "  # training loss\n",
    "  train_loss = []\n",
    "\n",
    "  # test accuracy\n",
    "  test_accuracy = []\n",
    "\n",
    "  # test loss\n",
    "  test_loss = []\n",
    "\n",
    "  # history\n",
    "  history=[]\n",
    "\n",
    "  # store last loss for convergence\n",
    "  last_loss = 0.0\n",
    "\n",
    "  # total time taken \n",
    "  total_time = 0\n",
    "  start = time.time()\n",
    "\n",
    "  print(f\"System heterogeneity set to {percentage}% stragglers.\\n\")\n",
    "  print(f\"Picking {max(int(C*K),1 )} random clients per round.\\n\")\n",
    "\n",
    "  users_id = list(data_dict.keys())\n",
    "\n",
    "  for curr_round in range(1, rounds+1):\n",
    "    w, local_loss, lst_local_train_time = [], [], []\n",
    "\n",
    "    m = max(int(C*K), 1)\n",
    "\n",
    "    heterogenous_epoch_list = GenerateLocalEpochs(percentage, size=m, max_epochs=E)\n",
    "    heterogenous_epoch_list = np.array(heterogenous_epoch_list)\n",
    "    # print('heterogenous_epoch_list', len(heterogenous_epoch_list))\n",
    "\n",
    "    S_t = np.random.choice(range(K), m, replace=False)\n",
    "    S_t = np.array(S_t)\n",
    "    print('Clients: {}/{} -> {}'.format(len(S_t), K, S_t))\n",
    "    \n",
    "    # For Federated Averaging, drop all the clients that are stragglers\n",
    "    if algorithm == 'fedavg':\n",
    "      stragglers_indices = np.argwhere(heterogenous_epoch_list < E)\n",
    "      heterogenous_epoch_list = np.delete(heterogenous_epoch_list, stragglers_indices)\n",
    "      S_t = np.delete(S_t, stragglers_indices)\n",
    "\n",
    "    # for _, (k, epoch) in tqdm(enumerate(zip(S_t, heterogenous_epoch_list))):\n",
    "    for i in tqdm(range(len(S_t))):\n",
    "    #   print('k', k)\n",
    "      k = S_t[i]\n",
    "      epoch = heterogenous_epoch_list[i]\n",
    "      key = users_id[k]\n",
    "      ds_ = ds if ds else data_dict[key]['train_ds']\n",
    "      idxs = data_dict[key] if ds else None\n",
    "    #   print(f'Client {k}: {len(idxs) if idxs else len(ds_)} samples')\n",
    "      local_update = ClientUpdate(dataset=ds_, batchSize=batch_size, learning_rate=lr, epochs=epoch, idxs=idxs, mu=mu, algorithm=algorithm)\n",
    "      weights, loss, local_train_time = local_update.train(model=copy.deepcopy(model))\n",
    "    #   print(f'Local train time for {k} on {len(idxs) if idxs else len(ds_)} samples: {local_train_time}')\n",
    "    #   print(f'Local train time: {local_train_time}')\n",
    "\n",
    "      w.append(copy.deepcopy(weights))\n",
    "      local_loss.append(copy.deepcopy(loss))\n",
    "      lst_local_train_time.append(local_train_time)\n",
    "\n",
    "    # calculate time to update the global weights\n",
    "    global_start_time = time.time()\n",
    "\n",
    "    # updating the global weights\n",
    "    weights_avg = copy.deepcopy(w[0])\n",
    "    for k in weights_avg.keys():\n",
    "      for i in range(1, len(w)):\n",
    "        weights_avg[k] += w[i][k]\n",
    "\n",
    "      weights_avg[k] = torch.div(weights_avg[k], len(w))\n",
    "\n",
    "    global_weights = weights_avg\n",
    "\n",
    "    global_end_time = time.time()\n",
    "\n",
    "    # calculate total time \n",
    "    total_time += (global_end_time - global_start_time) + sum(lst_local_train_time)/len(lst_local_train_time)\n",
    "\n",
    "    # move the updated weights to our model state dict\n",
    "    model.load_state_dict(global_weights)\n",
    "\n",
    "    # loss\n",
    "    loss_avg = sum(local_loss) / len(local_loss)\n",
    "    print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)))\n",
    "    train_loss.append(loss_avg)\n",
    "    if tb_logger:\n",
    "        tb_logger.add_scalar(f'Train/Loss', loss_avg, curr_round)\n",
    "\n",
    "    # testing\n",
    "    # if curr_round % eval_every == 0:\n",
    "    test_scores = testing(model, test_ds, batch_size * 2, nn.CrossEntropyLoss(), len(classes), classes)\n",
    "    test_scores['train_loss'] = loss_avg\n",
    "    test_loss_current, test_accuracy_current = test_scores['loss'], test_scores['accuracy']\n",
    "\n",
    "    history.append(test_scores)\n",
    "    test_accuracy.append(test_accuracy_current)\n",
    "    test_loss.append(test_loss_current)\n",
    "    \n",
    "    # print('Round: {}... \\tAverage Loss: {} \\tTest Loss: {} \\tTest Acc: {}'.format(curr_round, round(loss_avg, 3), round(test_loss, 3), round(test_accuracy, 3)))\n",
    "\n",
    "    if tb_logger:\n",
    "        tb_logger.add_scalar(f'Test/Loss', test_scores['loss'], curr_round)\n",
    "        tb_logger.add_scalars(f'Test/Scores', {\n",
    "            'accuracy': test_scores['accuracy'], 'f1_macro': test_scores['f1_macro'], 'f1_weighted': test_scores['f1_weighted']\n",
    "        }, curr_round)\n",
    "\n",
    "    # break if we achieve the target test accuracy\n",
    "    # if test_accuracy_current >= target_test_accuracy:\n",
    "    #   rounds = curr_round\n",
    "    #   break\n",
    "\n",
    "    # break if we achieve convergence, i.e., loss between two consecutive rounds is <0.0001\n",
    "    if algorithm == 'fedprox' and abs(loss_avg - last_loss) < 1e-5:\n",
    "      rounds = curr_round\n",
    "      break\n",
    "    \n",
    "    # update the last loss\n",
    "    last_loss = loss_avg\n",
    "\n",
    "  end = time.time()\n",
    "  \n",
    "  # plot train loss\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(train_loss)\n",
    "  ax.plot(x_axis, y_axis)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Train Loss', title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Train_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_loss)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Loss',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  # plot test accuracy\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_accuracy)\n",
    "  ax.plot(x_axis, y_axis)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Accuracy', title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_Accuracy.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  print(\"Training Done! Total time taken to Train: {}\".format(end-start))\n",
    "\n",
    "  return model, train_loss, test_accuracy, test_loss, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXtGLkoAqLIW"
   },
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dQJIJno4qKvc"
   },
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion, num_classes, classes, print_all=False):\n",
    "  #test loss \n",
    "  test_loss = 0.0\n",
    "  correct_class = list(0. for i in range(num_classes))\n",
    "  total_class = list(0. for i in range(num_classes))\n",
    "\n",
    "  test_loader = DataLoader(dataset, batch_size=bs)\n",
    "  l = len(test_loader)\n",
    "  model.eval()\n",
    "  print('running validation...')\n",
    "  for i, (data, labels) in enumerate(tqdm(test_loader)):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "      data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    output = model(data)\n",
    "    loss = criterion(output, labels)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "\n",
    "    # For F1Score\n",
    "    y_true = np.append(y_true, labels.data.view_as(pred).cpu().numpy()) if i != 0 else labels.data.view_as(pred).cpu().numpy()\n",
    "    y_hat = np.append(y_hat, pred.cpu().numpy()) if i != 0 else pred.cpu().numpy()\n",
    "\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "    #test accuracy for each object class\n",
    "    # for i in range(num_classes):\n",
    "    #   label = labels.data[i]\n",
    "    #   correct_class[label] += correct[i].item()\n",
    "    #   total_class[label] += 1\n",
    "\n",
    "    for i, lbl in enumerate(labels.data):\n",
    "    #   print('lbl', i, lbl)\n",
    "      correct_class[lbl] += correct.data[i]\n",
    "      total_class[lbl] += 1\n",
    "    \n",
    "  # avg test loss\n",
    "  test_loss = test_loss/len(test_loader.dataset)\n",
    "  print(\"Test Loss: {:.6f}\\n\".format(test_loss))\n",
    "\n",
    "  # Avg F1 Score\n",
    "  f1_macro = f1_score(y_true, y_hat, average='macro')\n",
    "  # F1-Score -> weigthed to consider class imbalance\n",
    "  f1_weighted =  f1_score(y_true, y_hat, average='weighted')\n",
    "  print(\"F1 Score: {:.6f} (macro) {:.6f} (weighted) %\\n\".format(f1_macro, f1_weighted))\n",
    "\n",
    "  # print test accuracy\n",
    "  if print_all:\n",
    "    for i in range(num_classes):\n",
    "        if total_class[i]>0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % \n",
    "                    (classes[i], 100 * correct_class[i] / total_class[i],\n",
    "                    np.sum(correct_class[i]), np.sum(total_class[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "  overall_accuracy = np.sum(correct_class) / np.sum(total_class)\n",
    "\n",
    "  print('\\nFinal Test  Accuracy: {:.3f} ({}/{})'.format(overall_accuracy, np.sum(correct_class), np.sum(total_class)))\n",
    "\n",
    "  return {'loss': test_loss, 'accuracy': overall_accuracy, 'f1_macro': f1_macro, 'f1_weighted': f1_weighted}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxqXLBd8qbC2"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "c8gl5P3SMq4a"
   },
   "outputs": [],
   "source": [
    "log_dict = {}\n",
    "NUM_REPEAT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "E2CfSkNVqKtL"
   },
   "outputs": [],
   "source": [
    "seq_length = 80  # mcmahan17a, fedprox, qFFL\n",
    "embedding_dim = 8  # mcmahan17a, fedprox, qFFL\n",
    "# hidden_dim = 100  # fedprox paper\n",
    "hidden_dim = 256  # mcmahan17a, fedprox impl\n",
    "num_classes = len(corpus)\n",
    "classes = list(range(num_classes))\n",
    "lstm_layers = 2  # mcmahan17a, fedprox, qFFL\n",
    "dropout = 0.1  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPIpStyNJ-63"
   },
   "source": [
    "## LSTM FedProx on IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gpS1gyJ_H_MA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective 413629 / 413629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Total users:', 143)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, data_dict, test_ds = iid_partition(corpus, seq_length, val_split=True)  # Not using val_ds but makes train eval periods faster\n",
    "\n",
    "total_clients = len(data_dict.keys())\n",
    "'Total users:', total_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYoGsy05H_RC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Run Number:  0\n",
      "Objective 413629 / 413629\n",
      "System heterogeneity set to 50% stragglers.\n",
      "\n",
      "Picking 10 random clients per round.\n",
      "\n",
      "Clients: 10/143 -> [ 31  16 139  86  41 119  47 110  54   8]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2ac00dfe1547d8be070f08015be55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1... \tAverage Loss: 3.23\n",
      "running validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c62fbda59b4ce0a8bb00383a29e98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.938609\n",
      "\n",
      "F1 Score: 0.016658 (macro) 0.124900 (weighted) %\n",
      "\n",
      "\n",
      "Final Test  Accuracy: 0.241 (12454.0/51704.0)\n",
      "Clients: 10/143 -> [ 98  33  55   7  42  16  95  67 126 137]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339207e45eac49a19264fa10c02969ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # partition data\n",
    "  train_ds, data_dict, test_ds = iid_partition(corpus, seq_length, val_split=True)  # Not using val_ds but makes train eval periods faster\n",
    "  total_clients = len(data_dict.keys())\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.07  # 10 clients\n",
    "  # number of clients\n",
    "  K = total_clients\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 1\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr = 0.8\n",
    "  # proximal term constant\n",
    "  mu = 0.001\n",
    "  # percentage of clients to have fewer than E epochs\n",
    "  percentage = 50\n",
    "  # target test accuracy\n",
    "  target_test_accuracy= 101\n",
    "\n",
    "  shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,  \n",
    "                                    embedding_dim=embedding_dim,  \n",
    "                                    hidden_dim=hidden_dim,\n",
    "                                    classes=num_classes,\n",
    "                                    lstm_layers=lstm_layers,\n",
    "                                    dropout=dropout,\n",
    "                                    batch_first=True\n",
    "                                    )\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      shakespeare_lstm.cuda()\n",
    "\n",
    "  lstm_iid_trained, train_loss, test_accuracy, test_loss, history = training(shakespeare_lstm,\n",
    "                                          rounds, batch_size, lr,\n",
    "                                          train_ds,\n",
    "                                          data_dict,\n",
    "                                          test_ds,\n",
    "                                          C, K, E, mu, percentage,\n",
    "                                          'Shakespeare LSTM on IID', \"green\",\n",
    "                                          target_test_accuracy,\n",
    "                                          corpus, # classes\n",
    "                                          algorithm=\"fedprox\"\n",
    "                                          )\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss\n",
    "\n",
    "  del lstm_iid_trained\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-irvQHuNNTtB"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               'mu': mu,\n",
    "               'percentage': percentage,\n",
    "               'target_accuracy': target_test_accuracy,\n",
    "               }\n",
    "\n",
    "log_dict['Shakespeare LSTM on IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'history': history,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QO0GkVyKEgu"
   },
   "source": [
    "## LSTM FedProx on Non IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wsHRfwmKGdS"
   },
   "outputs": [],
   "source": [
    "data_dict, test_ds = noniid_partition(corpus, seq_length=seq_length, val_split=False)\n",
    " \n",
    "total_clients = len(data_dict.keys())  \n",
    "'Total users:', total_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNJZG5tvKGgd"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "  # partition dataset\n",
    "  data_dict, test_ds = noniid_partition(corpus, seq_length=seq_length, val_split=False)\n",
    "  total_clients = len(data_dict.keys())  \n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.07  # 10 clients\n",
    "  # number of clients\n",
    "  K = total_clients\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 1\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr = 0.8\n",
    "  # proximal term constant\n",
    "  mu = 0.001\n",
    "  # percentage of clients to have fewer than E epochs\n",
    "  percentage = 50\n",
    "  # target test accuracy\n",
    "  target_test_accuracy= 101\n",
    "\n",
    "  shakespeare_lstm = ShakespeareLSTM(input_dim=seq_length,\n",
    "                                        embedding_dim=embedding_dim,\n",
    "                                        hidden_dim=hidden_dim,\n",
    "                                        classes=num_classes,\n",
    "                                        lstm_layers=lstm_layers,\n",
    "                                        dropout=dropout,\n",
    "                                        batch_first=True\n",
    "                                        )\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      shakespeare_lstm.cuda()\n",
    "\n",
    "  lstm_non_iid_trained, train_loss, test_accuracy, test_loss, history = training(shakespeare_lstm,\n",
    "                                                rounds, batch_size, lr,\n",
    "                                                None, #  ds empty as it is included in data_dict\n",
    "                                                data_dict,\n",
    "                                                test_ds,\n",
    "                                                C, K, E, mu, percentage,\n",
    "                                                'Shakespeare LSTM on Non IID', \"green\",\n",
    "                                                target_test_accuracy,\n",
    "                                                corpus, # classes,\n",
    "                                                algorithm=\"fedprox\"\n",
    "                                                )\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss\n",
    "\n",
    "  del lstm_non_iid_trained\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uANkBpTRKGkv"
   },
   "outputs": [],
   "source": [
    " hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               'mu': mu,\n",
    "               'percentage': percentage,\n",
    "               'target_accuracy': target_test_accuracy,\n",
    "               }\n",
    "\n",
    "log_dict['Shakespeare LSTM on Non IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'history': history,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShdScPNuQzUQ"
   },
   "source": [
    "## Pickle Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwHt7jviQ1AV"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(path + 'Local_Round_FedProx_1.pkl', 'wb') as file:\n",
    "  pickle.dump(log_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qNkwXxO8Q3Ei"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shakespeare LSTM on IID': {'history': [{'accuracy': 0.229576048274795,\n",
       "    'f1_macro': 0.01410987907380752,\n",
       "    'f1_weighted': 0.1072855232627884,\n",
       "    'loss': 2.945877161978495,\n",
       "    'train_loss': 3.2154537119352637},\n",
       "   {'accuracy': 0.28075197276806435,\n",
       "    'f1_macro': 0.03308986518645829,\n",
       "    'f1_weighted': 0.19057556655441088,\n",
       "    'loss': 2.6583698517800705,\n",
       "    'train_loss': 2.9242430789424505},\n",
       "   {'accuracy': 0.3040383722729383,\n",
       "    'f1_macro': 0.0446558330172086,\n",
       "    'f1_weighted': 0.22118017704326612,\n",
       "    'loss': 2.5208534795803015,\n",
       "    'train_loss': 2.7149140799523717},\n",
       "   {'accuracy': 0.3271120222806746,\n",
       "    'f1_macro': 0.05742818373051288,\n",
       "    'f1_weighted': 0.2511246864148333,\n",
       "    'loss': 2.437701902927379,\n",
       "    'train_loss': 2.613596709223044},\n",
       "   {'accuracy': 0.3339200061890763,\n",
       "    'f1_macro': 0.061310703055567385,\n",
       "    'f1_weighted': 0.261986286900409,\n",
       "    'loss': 2.3595442486569254,\n",
       "    'train_loss': 2.530100675996903},\n",
       "   {'accuracy': 0.3449442983134767,\n",
       "    'f1_macro': 0.06964373168091562,\n",
       "    'f1_weighted': 0.2723267200599347,\n",
       "    'loss': 2.3127243815930325,\n",
       "    'train_loss': 2.480962580129154},\n",
       "   {'accuracy': 0.35852158440352777,\n",
       "    'f1_macro': 0.07335831238750212,\n",
       "    'f1_weighted': 0.28502285416857476,\n",
       "    'loss': 2.257425538878516,\n",
       "    'train_loss': 2.4118973463650066},\n",
       "   {'accuracy': 0.3756189076280365,\n",
       "    'f1_macro': 0.09410854721418492,\n",
       "    'f1_weighted': 0.31391673479700827,\n",
       "    'loss': 2.2065132919404413,\n",
       "    'train_loss': 2.385480844471629},\n",
       "   {'accuracy': 0.37517406777038526,\n",
       "    'f1_macro': 0.09602560734190223,\n",
       "    'f1_weighted': 0.3195349818148712,\n",
       "    'loss': 2.1710953861382767,\n",
       "    'train_loss': 2.346716892941859},\n",
       "   {'accuracy': 0.387204084790345,\n",
       "    'f1_macro': 0.10258351304359688,\n",
       "    'f1_weighted': 0.3298043604954096,\n",
       "    'loss': 2.136222803249607,\n",
       "    'train_loss': 2.291886988702651},\n",
       "   {'accuracy': 0.3940894321522513,\n",
       "    'f1_macro': 0.10859215844154517,\n",
       "    'f1_weighted': 0.34341758651422816,\n",
       "    'loss': 2.1009953447688057,\n",
       "    'train_loss': 2.263399662761685},\n",
       "   {'accuracy': 0.4028508432616432,\n",
       "    'f1_macro': 0.11871844414877207,\n",
       "    'f1_weighted': 0.3589184528258818,\n",
       "    'loss': 2.0778202349402193,\n",
       "    'train_loss': 2.233103191131213},\n",
       "   {'accuracy': 0.4092139873123936,\n",
       "    'f1_macro': 0.12260883337252271,\n",
       "    'f1_weighted': 0.3614399325405916,\n",
       "    'loss': 2.0512168737465286,\n",
       "    'train_loss': 2.2056159558014254},\n",
       "   {'accuracy': 0.4155191087730156,\n",
       "    'f1_macro': 0.12252583494669952,\n",
       "    'f1_weighted': 0.36825147397892116,\n",
       "    'loss': 2.0288264543087826,\n",
       "    'train_loss': 2.1788539365799595},\n",
       "   {'accuracy': 0.4164861519418227,\n",
       "    'f1_macro': 0.12378379609783076,\n",
       "    'f1_weighted': 0.3678777417592666,\n",
       "    'loss': 2.0140666528630145,\n",
       "    'train_loss': 2.1800280296291388},\n",
       "   {'accuracy': 0.42356490793749035,\n",
       "    'f1_macro': 0.12919539218480822,\n",
       "    'f1_weighted': 0.37501361395262517,\n",
       "    'loss': 1.9861979573485506,\n",
       "    'train_loss': 2.15751846483593},\n",
       "   {'accuracy': 0.4292898034968281,\n",
       "    'f1_macro': 0.13247714645974512,\n",
       "    'f1_weighted': 0.38254773698836214,\n",
       "    'loss': 1.9690044254073782,\n",
       "    'train_loss': 2.132662549647882},\n",
       "   {'accuracy': 0.43489865387590904,\n",
       "    'f1_macro': 0.13540144704786952,\n",
       "    'f1_weighted': 0.3893768402873,\n",
       "    'loss': 1.9443349130077017,\n",
       "    'train_loss': 2.10605744909119},\n",
       "   {'accuracy': 0.43863144050750424,\n",
       "    'f1_macro': 0.1372081010678118,\n",
       "    'f1_weighted': 0.39661859195261684,\n",
       "    'loss': 1.9332322759878593,\n",
       "    'train_loss': 2.0962221944171366},\n",
       "   {'accuracy': 0.4402754138944763,\n",
       "    'f1_macro': 0.1410120559129463,\n",
       "    'f1_weighted': 0.3936531494919698,\n",
       "    'loss': 1.9249311106623317,\n",
       "    'train_loss': 2.0794748306068316},\n",
       "   {'accuracy': 0.44648383103821754,\n",
       "    'f1_macro': 0.1437700330440433,\n",
       "    'f1_weighted': 0.4040509700779938,\n",
       "    'loss': 1.908300166467469,\n",
       "    'train_loss': 2.063129079867448},\n",
       "   {'accuracy': 0.4472574655732632,\n",
       "    'f1_macro': 0.13721880597895247,\n",
       "    'f1_weighted': 0.40288340432104736,\n",
       "    'loss': 1.889607617524632,\n",
       "    'train_loss': 2.0405065142154113},\n",
       "   {'accuracy': 0.4522474083243076,\n",
       "    'f1_macro': 0.14984458202831274,\n",
       "    'f1_weighted': 0.40938287253106115,\n",
       "    'loss': 1.877078344684331,\n",
       "    'train_loss': 2.042180588987771},\n",
       "   {'accuracy': 0.45396874516478414,\n",
       "    'f1_macro': 0.1424196395560156,\n",
       "    'f1_weighted': 0.41119285751641454,\n",
       "    'loss': 1.8627182743105009,\n",
       "    'train_loss': 2.032246755062503},\n",
       "   {'accuracy': 0.45545799164474704,\n",
       "    'f1_macro': 0.15357582469872372,\n",
       "    'f1_weighted': 0.4216953053179387,\n",
       "    'loss': 1.8547064933326984,\n",
       "    'train_loss': 2.021057012850318},\n",
       "   {'accuracy': 0.45861055237505804,\n",
       "    'f1_macro': 0.1595344073513451,\n",
       "    'f1_weighted': 0.41712190489613954,\n",
       "    'loss': 1.8415066640862698,\n",
       "    'train_loss': 1.9918117963138293},\n",
       "   {'accuracy': 0.46197586260250656,\n",
       "    'f1_macro': 0.15742847843726146,\n",
       "    'f1_weighted': 0.4237430801551726,\n",
       "    'loss': 1.8281156467649935,\n",
       "    'train_loss': 1.9878445130207396},\n",
       "   {'accuracy': 0.46669503326628503,\n",
       "    'f1_macro': 0.15552461770471043,\n",
       "    'f1_weighted': 0.4291164773766292,\n",
       "    'loss': 1.8205676258391923,\n",
       "    'train_loss': 1.983861561443136},\n",
       "   {'accuracy': 0.4690352777347981,\n",
       "    'f1_macro': 0.16628452392785242,\n",
       "    'f1_weighted': 0.43491023474557844,\n",
       "    'loss': 1.8072886781004143,\n",
       "    'train_loss': 1.956285445303508},\n",
       "   {'accuracy': 0.4706212285316417,\n",
       "    'f1_macro': 0.16440692644926896,\n",
       "    'f1_weighted': 0.4336652643710841,\n",
       "    'loss': 1.8000268821176426,\n",
       "    'train_loss': 1.9509441256090316},\n",
       "   {'accuracy': 0.47238124709887047,\n",
       "    'f1_macro': 0.1713971405371037,\n",
       "    'f1_weighted': 0.4351795643987495,\n",
       "    'loss': 1.7950894533331303,\n",
       "    'train_loss': 1.9486597040289417},\n",
       "   {'accuracy': 0.4772744855330342,\n",
       "    'f1_macro': 0.16429928051804465,\n",
       "    'f1_weighted': 0.4376472382334621,\n",
       "    'loss': 1.7751810199545206,\n",
       "    'train_loss': 1.9330927159178632},\n",
       "   {'accuracy': 0.4754564443756769,\n",
       "    'f1_macro': 0.17221762458364806,\n",
       "    'f1_weighted': 0.43595599689542625,\n",
       "    'loss': 1.7786706729077175,\n",
       "    'train_loss': 1.9213324057847714},\n",
       "   {'accuracy': 0.47889911805663005,\n",
       "    'f1_macro': 0.1745592479033687,\n",
       "    'f1_weighted': 0.44669342313702176,\n",
       "    'loss': 1.762508023218411,\n",
       "    'train_loss': 1.9093002051336594},\n",
       "   {'accuracy': 0.48110397648151015,\n",
       "    'f1_macro': 0.17401417692901266,\n",
       "    'f1_weighted': 0.4421012957454072,\n",
       "    'loss': 1.7605084009017808,\n",
       "    'train_loss': 1.9031112337075329},\n",
       "   {'accuracy': 0.48383103821754603,\n",
       "    'f1_macro': 0.17674503933337526,\n",
       "    'f1_weighted': 0.44650578002741,\n",
       "    'loss': 1.746351403040855,\n",
       "    'train_loss': 1.9051751459321398},\n",
       "   {'accuracy': 0.4839470833978029,\n",
       "    'f1_macro': 0.18162539025694538,\n",
       "    'f1_weighted': 0.45304442086762936,\n",
       "    'loss': 1.7425762241873122,\n",
       "    'train_loss': 1.8866287404405955},\n",
       "   {'accuracy': 0.4880280055701687,\n",
       "    'f1_macro': 0.18489727410639548,\n",
       "    'f1_weighted': 0.4567706440083699,\n",
       "    'loss': 1.7334972820759889,\n",
       "    'train_loss': 1.8741322055603296},\n",
       "   {'accuracy': 0.48822141420393006,\n",
       "    'f1_macro': 0.18708498930516154,\n",
       "    'f1_weighted': 0.45714066281531024,\n",
       "    'loss': 1.7322478961673902,\n",
       "    'train_loss': 1.8536192943281489},\n",
       "   {'accuracy': 0.4910258393934705,\n",
       "    'f1_macro': 0.19276628293850265,\n",
       "    'f1_weighted': 0.4628732742053413,\n",
       "    'loss': 1.7190827960783939,\n",
       "    'train_loss': 1.8564001791210092},\n",
       "   {'accuracy': 0.49230233637629583,\n",
       "    'f1_macro': 0.17793091391376098,\n",
       "    'f1_weighted': 0.45907012010692455,\n",
       "    'loss': 1.7171245214821715,\n",
       "    'train_loss': 1.8558745828571819},\n",
       "   {'accuracy': 0.49462323998143276,\n",
       "    'f1_macro': 0.18998453128836462,\n",
       "    'f1_weighted': 0.46041896871129606,\n",
       "    'loss': 1.7092243691342324,\n",
       "    'train_loss': 1.8527488435699735},\n",
       "   {'accuracy': 0.4925150858734334,\n",
       "    'f1_macro': 0.18437639915429355,\n",
       "    'f1_weighted': 0.45688119984805275,\n",
       "    'loss': 1.7052670795676252,\n",
       "    'train_loss': 1.855961117684264},\n",
       "   {'accuracy': 0.49936175150858736,\n",
       "    'f1_macro': 0.19361029655286746,\n",
       "    'f1_weighted': 0.4697179285511094,\n",
       "    'loss': 1.6938223283315395,\n",
       "    'train_loss': 1.8391061980096957},\n",
       "   {'accuracy': 0.49682809840631287,\n",
       "    'f1_macro': 0.19877170197582741,\n",
       "    'f1_weighted': 0.46484792054402435,\n",
       "    'loss': 1.6932658368732267,\n",
       "    'train_loss': 1.8267579586921392},\n",
       "   {'accuracy': 0.49965186445922943,\n",
       "    'f1_macro': 0.19450644500232814,\n",
       "    'f1_weighted': 0.4677145955264156,\n",
       "    'loss': 1.684427272995296,\n",
       "    'train_loss': 1.8312063494617348},\n",
       "   {'accuracy': 0.5010250657589355,\n",
       "    'f1_macro': 0.19976972750585445,\n",
       "    'f1_weighted': 0.47185250401874856,\n",
       "    'loss': 1.676134370629372,\n",
       "    'train_loss': 1.8300503147052367},\n",
       "   {'accuracy': 0.5027850843261643,\n",
       "    'f1_macro': 0.2029644196151876,\n",
       "    'f1_weighted': 0.4744493037448495,\n",
       "    'loss': 1.6719755107485323,\n",
       "    'train_loss': 1.803456683728952},\n",
       "   {'accuracy': 0.5049512610242921,\n",
       "    'f1_macro': 0.20457491648396417,\n",
       "    'f1_weighted': 0.4743668233842905,\n",
       "    'loss': 1.665942495456794,\n",
       "    'train_loss': 1.8010892673358216},\n",
       "   {'accuracy': 0.5039842178554851,\n",
       "    'f1_macro': 0.20428292626155453,\n",
       "    'f1_weighted': 0.4766999230412708,\n",
       "    'loss': 1.6643714508692786,\n",
       "    'train_loss': 1.8139491167615063}],\n",
       "  'hyperparams': {'C': 0.07,\n",
       "   'E': 1,\n",
       "   'K': 143,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.8,\n",
       "   'mu': 0.001,\n",
       "   'percentage': 50,\n",
       "   'rounds': 50,\n",
       "   'target_accuracy': 101},\n",
       "  'test_accuracy': [[0.2408711124864614,\n",
       "    0.2734217855485069,\n",
       "    0.29415519108773014,\n",
       "    0.30724895559337767,\n",
       "    0.3231084635618134,\n",
       "    0.341288875135386,\n",
       "    0.3633761411109392,\n",
       "    0.3714219402754139,\n",
       "    0.3777657434627882,\n",
       "    0.3838194336995204,\n",
       "    0.3867592449326938,\n",
       "    0.3982477177781216,\n",
       "    0.4028895249883955,\n",
       "    0.40671901593687143,\n",
       "    0.40867244313786166,\n",
       "    0.42319743153334366,\n",
       "    0.4249574501005725,\n",
       "    0.4281873742843881,\n",
       "    0.43354479343957913,\n",
       "    0.4358076744545877,\n",
       "    0.4418033421011914,\n",
       "    0.4440662231161999,\n",
       "    0.44793439579142813,\n",
       "    0.4505647532105833,\n",
       "    0.45433622156893083,\n",
       "    0.4540267677549126,\n",
       "    0.4601965031719016,\n",
       "    0.46077672907318584,\n",
       "    0.4634844499458456,\n",
       "    0.46822296147300013,\n",
       "    0.4684357109701377,\n",
       "    0.4718397029243385,\n",
       "    0.46969286708958685,\n",
       "    0.4759593068234566,\n",
       "    0.4771584403527773,\n",
       "    0.4792085718706483,\n",
       "    0.4782415287018412,\n",
       "    0.48398576512455516,\n",
       "    0.4855910567847749,\n",
       "    0.48723503017174685,\n",
       "    0.48638403218319665,\n",
       "    0.4897106606838929,\n",
       "    0.49230233637629583,\n",
       "    0.4915480427046263,\n",
       "    0.49448785393779976,\n",
       "    0.4945845582546805,\n",
       "    0.4956289648769921,\n",
       "    0.49692480272319356,\n",
       "    0.4973309608540925,\n",
       "    0.500541544174532],\n",
       "   [0.229576048274795,\n",
       "    0.28075197276806435,\n",
       "    0.3040383722729383,\n",
       "    0.3271120222806746,\n",
       "    0.3339200061890763,\n",
       "    0.3449442983134767,\n",
       "    0.35852158440352777,\n",
       "    0.3756189076280365,\n",
       "    0.37517406777038526,\n",
       "    0.387204084790345,\n",
       "    0.3940894321522513,\n",
       "    0.4028508432616432,\n",
       "    0.4092139873123936,\n",
       "    0.4155191087730156,\n",
       "    0.4164861519418227,\n",
       "    0.42356490793749035,\n",
       "    0.4292898034968281,\n",
       "    0.43489865387590904,\n",
       "    0.43863144050750424,\n",
       "    0.4402754138944763,\n",
       "    0.44648383103821754,\n",
       "    0.4472574655732632,\n",
       "    0.4522474083243076,\n",
       "    0.45396874516478414,\n",
       "    0.45545799164474704,\n",
       "    0.45861055237505804,\n",
       "    0.46197586260250656,\n",
       "    0.46669503326628503,\n",
       "    0.4690352777347981,\n",
       "    0.4706212285316417,\n",
       "    0.47238124709887047,\n",
       "    0.4772744855330342,\n",
       "    0.4754564443756769,\n",
       "    0.47889911805663005,\n",
       "    0.48110397648151015,\n",
       "    0.48383103821754603,\n",
       "    0.4839470833978029,\n",
       "    0.4880280055701687,\n",
       "    0.48822141420393006,\n",
       "    0.4910258393934705,\n",
       "    0.49230233637629583,\n",
       "    0.49462323998143276,\n",
       "    0.4925150858734334,\n",
       "    0.49936175150858736,\n",
       "    0.49682809840631287,\n",
       "    0.49965186445922943,\n",
       "    0.5010250657589355,\n",
       "    0.5027850843261643,\n",
       "    0.5049512610242921,\n",
       "    0.5039842178554851]],\n",
       "  'test_loss': [[2.9386091945102373,\n",
       "    2.668818671443635,\n",
       "    2.5265537014035973,\n",
       "    2.4513012370365277,\n",
       "    2.38581426404088,\n",
       "    2.3157380672868295,\n",
       "    2.269713234402494,\n",
       "    2.218631155513378,\n",
       "    2.1778345345832903,\n",
       "    2.1481534954879224,\n",
       "    2.12569147603635,\n",
       "    2.0941872766525886,\n",
       "    2.068124132610439,\n",
       "    2.0500337248067173,\n",
       "    2.0381097448181342,\n",
       "    2.005226672212166,\n",
       "    1.9877314712219927,\n",
       "    1.9724977287796284,\n",
       "    1.9548684881255665,\n",
       "    1.9431392741649673,\n",
       "    1.9239985280565464,\n",
       "    1.9136297895359666,\n",
       "    1.8992445039805403,\n",
       "    1.887311548418846,\n",
       "    1.8733693820513864,\n",
       "    1.8614845898393764,\n",
       "    1.8454134301995042,\n",
       "    1.84267725525751,\n",
       "    1.8305175288919138,\n",
       "    1.81920750896946,\n",
       "    1.8108616785360863,\n",
       "    1.7992209919729636,\n",
       "    1.7963564364974776,\n",
       "    1.7853034708960753,\n",
       "    1.7746908700215536,\n",
       "    1.7662242978705205,\n",
       "    1.7664018119557823,\n",
       "    1.7521143284824154,\n",
       "    1.7466832455844217,\n",
       "    1.7379904004021656,\n",
       "    1.7376916724407467,\n",
       "    1.7297460195227579,\n",
       "    1.7207449372179384,\n",
       "    1.7170021719256459,\n",
       "    1.7098913412197039,\n",
       "    1.7045757575852571,\n",
       "    1.6966323014818514,\n",
       "    1.695543396284793,\n",
       "    1.691258796377898,\n",
       "    1.6808367596944105],\n",
       "   [2.945877161978495,\n",
       "    2.6583698517800705,\n",
       "    2.5208534795803015,\n",
       "    2.437701902927379,\n",
       "    2.3595442486569254,\n",
       "    2.3127243815930325,\n",
       "    2.257425538878516,\n",
       "    2.2065132919404413,\n",
       "    2.1710953861382767,\n",
       "    2.136222803249607,\n",
       "    2.1009953447688057,\n",
       "    2.0778202349402193,\n",
       "    2.0512168737465286,\n",
       "    2.0288264543087826,\n",
       "    2.0140666528630145,\n",
       "    1.9861979573485506,\n",
       "    1.9690044254073782,\n",
       "    1.9443349130077017,\n",
       "    1.9332322759878593,\n",
       "    1.9249311106623317,\n",
       "    1.908300166467469,\n",
       "    1.889607617524632,\n",
       "    1.877078344684331,\n",
       "    1.8627182743105009,\n",
       "    1.8547064933326984,\n",
       "    1.8415066640862698,\n",
       "    1.8281156467649935,\n",
       "    1.8205676258391923,\n",
       "    1.8072886781004143,\n",
       "    1.8000268821176426,\n",
       "    1.7950894533331303,\n",
       "    1.7751810199545206,\n",
       "    1.7786706729077175,\n",
       "    1.762508023218411,\n",
       "    1.7605084009017808,\n",
       "    1.746351403040855,\n",
       "    1.7425762241873122,\n",
       "    1.7334972820759889,\n",
       "    1.7322478961673902,\n",
       "    1.7190827960783939,\n",
       "    1.7171245214821715,\n",
       "    1.7092243691342324,\n",
       "    1.7052670795676252,\n",
       "    1.6938223283315395,\n",
       "    1.6932658368732267,\n",
       "    1.684427272995296,\n",
       "    1.676134370629372,\n",
       "    1.6719755107485323,\n",
       "    1.665942495456794,\n",
       "    1.6643714508692786]],\n",
       "  'train_loss': [[3.229539238722327,\n",
       "    2.9037168048559217,\n",
       "    2.7097505321806072,\n",
       "    2.598454573865913,\n",
       "    2.5318418939949567,\n",
       "    2.473061734895489,\n",
       "    2.4380387181727885,\n",
       "    2.396288518904403,\n",
       "    2.357554556180003,\n",
       "    2.309799821796424,\n",
       "    2.2770614716728037,\n",
       "    2.2642764760127205,\n",
       "    2.2074596115373804,\n",
       "    2.2170810267926906,\n",
       "    2.1776554154203804,\n",
       "    2.1586650103206955,\n",
       "    2.1447700557083835,\n",
       "    2.1299086083515055,\n",
       "    2.10994614588192,\n",
       "    2.0965147126368135,\n",
       "    2.0943503652432645,\n",
       "    2.0594843713038524,\n",
       "    2.060571697506832,\n",
       "    2.0352458849796613,\n",
       "    2.0207534258440654,\n",
       "    2.024928347945708,\n",
       "    2.0041133252561174,\n",
       "    1.9916581297625644,\n",
       "    1.9747934908457974,\n",
       "    1.9752265950577281,\n",
       "    1.9625054420988342,\n",
       "    1.9524165666346565,\n",
       "    1.946618645247407,\n",
       "    1.9472715576809225,\n",
       "    1.9141972823220503,\n",
       "    1.9141427199664125,\n",
       "    1.9207264707996963,\n",
       "    1.891756613565967,\n",
       "    1.906434552101509,\n",
       "    1.8751872689953981,\n",
       "    1.872935836264454,\n",
       "    1.8752876700011611,\n",
       "    1.8577959257228247,\n",
       "    1.8475179157244301,\n",
       "    1.8374529924238534,\n",
       "    1.8436943104220131,\n",
       "    1.851063499419356,\n",
       "    1.8262676608729411,\n",
       "    1.8073910722408553,\n",
       "    1.8209342040554373],\n",
       "   [3.2154537119352637,\n",
       "    2.9242430789424505,\n",
       "    2.7149140799523717,\n",
       "    2.613596709223044,\n",
       "    2.530100675996903,\n",
       "    2.480962580129154,\n",
       "    2.4118973463650066,\n",
       "    2.385480844471629,\n",
       "    2.346716892941859,\n",
       "    2.291886988702651,\n",
       "    2.263399662761685,\n",
       "    2.233103191131213,\n",
       "    2.2056159558014254,\n",
       "    2.1788539365799595,\n",
       "    2.1800280296291388,\n",
       "    2.15751846483593,\n",
       "    2.132662549647882,\n",
       "    2.10605744909119,\n",
       "    2.0962221944171366,\n",
       "    2.0794748306068316,\n",
       "    2.063129079867448,\n",
       "    2.0405065142154113,\n",
       "    2.042180588987771,\n",
       "    2.032246755062503,\n",
       "    2.021057012850318,\n",
       "    1.9918117963138293,\n",
       "    1.9878445130207396,\n",
       "    1.983861561443136,\n",
       "    1.956285445303508,\n",
       "    1.9509441256090316,\n",
       "    1.9486597040289417,\n",
       "    1.9330927159178632,\n",
       "    1.9213324057847714,\n",
       "    1.9093002051336594,\n",
       "    1.9031112337075329,\n",
       "    1.9051751459321398,\n",
       "    1.8866287404405955,\n",
       "    1.8741322055603296,\n",
       "    1.8536192943281489,\n",
       "    1.8564001791210092,\n",
       "    1.8558745828571819,\n",
       "    1.8527488435699735,\n",
       "    1.855961117684264,\n",
       "    1.8391061980096957,\n",
       "    1.8267579586921392,\n",
       "    1.8312063494617348,\n",
       "    1.8300503147052367,\n",
       "    1.803456683728952,\n",
       "    1.8010892673358216,\n",
       "    1.8139491167615063]]},\n",
       " 'Shakespeare LSTM on Non IID': {'history': [{'accuracy': 0.1863215980362786,\n",
       "    'f1_macro': 0.004832561639912748,\n",
       "    'f1_weighted': 0.05852668947822855,\n",
       "    'loss': 3.541277015299172,\n",
       "    'train_loss': 4.028409997998531},\n",
       "   {'accuracy': 0.1863215980362786,\n",
       "    'f1_macro': 0.004832561639912748,\n",
       "    'f1_weighted': 0.05852668947822855,\n",
       "    'loss': 3.1582205124370106,\n",
       "    'train_loss': 3.313756086308982},\n",
       "   {'accuracy': 0.2325540941465253,\n",
       "    'f1_macro': 0.015248910919589725,\n",
       "    'f1_weighted': 0.11998061266182376,\n",
       "    'loss': 2.955816364318744,\n",
       "    'train_loss': 3.202403197131841},\n",
       "   {'accuracy': 0.28418875692182805,\n",
       "    'f1_macro': 0.03053596007631583,\n",
       "    'f1_weighted': 0.18564376524372594,\n",
       "    'loss': 2.6764137984573257,\n",
       "    'train_loss': 2.8988880691485894},\n",
       "   {'accuracy': 0.32349217700551813,\n",
       "    'f1_macro': 0.05530936866882759,\n",
       "    'f1_weighted': 0.2521498929042927,\n",
       "    'loss': 2.4416337281323544,\n",
       "    'train_loss': 2.631476512339693},\n",
       "   {'accuracy': 0.3339196149869053,\n",
       "    'f1_macro': 0.0546761831200306,\n",
       "    'f1_weighted': 0.25783891885116567,\n",
       "    'loss': 2.397187000782826,\n",
       "    'train_loss': 2.5334295300900807},\n",
       "   {'accuracy': 0.3559728248789586,\n",
       "    'f1_macro': 0.06716749493769687,\n",
       "    'f1_weighted': 0.28344282418349775,\n",
       "    'loss': 2.289366889592316,\n",
       "    'train_loss': 2.525124887320602},\n",
       "   {'accuracy': 0.3748272562985011,\n",
       "    'f1_macro': 0.08340221412933602,\n",
       "    'f1_weighted': 0.31761869765524264,\n",
       "    'loss': 2.216128868888827,\n",
       "    'train_loss': 2.47293614962726},\n",
       "   {'accuracy': 0.3859311731109329,\n",
       "    'f1_macro': 0.0898348042354646,\n",
       "    'f1_weighted': 0.33246085306653483,\n",
       "    'loss': 2.15632232240057,\n",
       "    'train_loss': 2.279606122282062},\n",
       "   {'accuracy': 0.3935560559351353,\n",
       "    'f1_macro': 0.09237714745745994,\n",
       "    'f1_weighted': 0.3409723651263457,\n",
       "    'loss': 2.118251015465651,\n",
       "    'train_loss': 2.2716156528429674},\n",
       "   {'accuracy': 0.4016834658909709,\n",
       "    'f1_macro': 0.10004661227432585,\n",
       "    'f1_weighted': 0.35695993188341485,\n",
       "    'loss': 2.0874401883775673,\n",
       "    'train_loss': 2.209248577426911},\n",
       "   {'accuracy': 0.40207968920629705,\n",
       "    'f1_macro': 0.10138401225777886,\n",
       "    'f1_weighted': 0.3600616490392522,\n",
       "    'loss': 2.069012484195234,\n",
       "    'train_loss': 2.29757801058389},\n",
       "   {'accuracy': 0.4099268436464142,\n",
       "    'f1_macro': 0.10491681895251909,\n",
       "    'f1_weighted': 0.3650355514999187,\n",
       "    'loss': 2.037599367768542,\n",
       "    'train_loss': 2.180904526220531},\n",
       "   {'accuracy': 0.4177739980865313,\n",
       "    'f1_macro': 0.10975336843022539,\n",
       "    'f1_weighted': 0.3733282970993257,\n",
       "    'loss': 2.0052707982629867,\n",
       "    'train_loss': 2.1755037173997254},\n",
       "   {'accuracy': 0.4238043236661287,\n",
       "    'f1_macro': 0.12125869556042694,\n",
       "    'f1_weighted': 0.380810624926623,\n",
       "    'loss': 1.9780862461720279,\n",
       "    'train_loss': 2.1841618622610266},\n",
       "   {'accuracy': 0.43048213612686875,\n",
       "    'f1_macro': 0.12813699986361227,\n",
       "    'f1_weighted': 0.3895883016966567,\n",
       "    'loss': 1.9657646903350983,\n",
       "    'train_loss': 2.0843548653249138},\n",
       "   {'accuracy': 0.4335842747663732,\n",
       "    'f1_macro': 0.12938752400837147,\n",
       "    'f1_weighted': 0.3938604610602743,\n",
       "    'loss': 1.9484004053254385,\n",
       "    'train_loss': 2.1099414554546416},\n",
       "   {'accuracy': 0.43668641340587766,\n",
       "    'f1_macro': 0.13320417631063372,\n",
       "    'f1_weighted': 0.3957053826444363,\n",
       "    'loss': 1.9382443186054266,\n",
       "    'train_loss': 2.087300038358987},\n",
       "   {'accuracy': 0.4375658358862356,\n",
       "    'f1_macro': 0.13300641106551697,\n",
       "    'f1_weighted': 0.3979293817763579,\n",
       "    'loss': 1.9326151902326079,\n",
       "    'train_loss': 2.111812862315708},\n",
       "   {'accuracy': 0.44151840505619605,\n",
       "    'f1_macro': 0.13868042624958263,\n",
       "    'f1_weighted': 0.4044891948896369,\n",
       "    'loss': 1.917780861354846,\n",
       "    'train_loss': 2.0076064563373004},\n",
       "   {'accuracy': 0.4450167670110266,\n",
       "    'f1_macro': 0.13687678419756313,\n",
       "    'f1_weighted': 0.4064613536381396,\n",
       "    'loss': 1.9116229900045205,\n",
       "    'train_loss': 1.9664013122480752},\n",
       "   {'accuracy': 0.4481672255670342,\n",
       "    'f1_macro': 0.14151320464649775,\n",
       "    'f1_weighted': 0.41276893143191484,\n",
       "    'loss': 1.8953368885197752,\n",
       "    'train_loss': 1.993506332723203},\n",
       "   {'accuracy': 0.45139499598944693,\n",
       "    'f1_macro': 0.1446126256727173,\n",
       "    'f1_weighted': 0.41771923672854117,\n",
       "    'loss': 1.8889162495310519,\n",
       "    'train_loss': 2.0263197208844907},\n",
       "   {'accuracy': 0.45218744262009913,\n",
       "    'f1_macro': 0.14083262437137045,\n",
       "    'f1_weighted': 0.4157169836299316,\n",
       "    'loss': 1.8835785415696822,\n",
       "    'train_loss': 2.005306660870946},\n",
       "   {'accuracy': 0.45347275239908386,\n",
       "    'f1_macro': 0.14286816712772238,\n",
       "    'f1_weighted': 0.4178826169109198,\n",
       "    'loss': 1.8658169419699784,\n",
       "    'train_loss': 1.8782613764679688},\n",
       "   {'accuracy': 0.45575345245803417,\n",
       "    'f1_macro': 0.1425708927394263,\n",
       "    'f1_weighted': 0.41515376457260555,\n",
       "    'loss': 1.8602481828140542,\n",
       "    'train_loss': 1.9699712537835445},\n",
       "   {'accuracy': 0.46013123689322266,\n",
       "    'f1_macro': 0.14506373344897475,\n",
       "    'f1_weighted': 0.4215054473039036,\n",
       "    'loss': 1.8488903603666256,\n",
       "    'train_loss': 1.9057027746768473},\n",
       "   {'accuracy': 0.4611362911564889,\n",
       "    'f1_macro': 0.1481505925704368,\n",
       "    'f1_weighted': 0.42361325231275215,\n",
       "    'loss': 1.8419945930136747,\n",
       "    'train_loss': 1.7141371348029906},\n",
       "   {'accuracy': 0.4625762246682838,\n",
       "    'f1_macro': 0.14948482020363624,\n",
       "    'f1_weighted': 0.42630010781523126,\n",
       "    'loss': 1.8330364606879457,\n",
       "    'train_loss': 1.9211740334335499},\n",
       "   {'accuracy': 0.4656203794079844,\n",
       "    'f1_macro': 0.15386225360725378,\n",
       "    'f1_weighted': 0.43621858772573313,\n",
       "    'loss': 1.826349980825824,\n",
       "    'train_loss': 1.888338174445017},\n",
       "   {'accuracy': 0.46763048793451684,\n",
       "    'f1_macro': 0.15372296904352353,\n",
       "    'f1_weighted': 0.4334820217173412,\n",
       "    'loss': 1.8190817132278128,\n",
       "    'train_loss': 1.935676060798404},\n",
       "   {'accuracy': 0.468558230331378,\n",
       "    'f1_macro': 0.1529326519971228,\n",
       "    'f1_weighted': 0.43469803999250983,\n",
       "    'loss': 1.819151155944745,\n",
       "    'train_loss': 1.8256194372633758},\n",
       "   {'accuracy': 0.46920571721252063,\n",
       "    'f1_macro': 0.1545583883504647,\n",
       "    'f1_weighted': 0.4376926477997921,\n",
       "    'loss': 1.8112044715609006,\n",
       "    'train_loss': 1.8043030060983352},\n",
       "   {'accuracy': 0.47059733080781235,\n",
       "    'f1_macro': 0.1547880502747398,\n",
       "    'f1_weighted': 0.43710189132980243,\n",
       "    'loss': 1.8033829476353014,\n",
       "    'train_loss': 1.9501884000854717},\n",
       "   {'accuracy': 0.47213390415261364,\n",
       "    'f1_macro': 0.15598018816979836,\n",
       "    'f1_weighted': 0.4379673174811342,\n",
       "    'loss': 1.8013793816097772,\n",
       "    'train_loss': 1.8279309646137096},\n",
       "   {'accuracy': 0.4748784754099945,\n",
       "    'f1_macro': 0.15772506008950493,\n",
       "    'f1_weighted': 0.4423215463532424,\n",
       "    'loss': 1.7903727468377535,\n",
       "    'train_loss': 1.8578730578011076},\n",
       "   {'accuracy': 0.47598983348956775,\n",
       "    'f1_macro': 0.1578159194259566,\n",
       "    'f1_weighted': 0.4388417905911121,\n",
       "    'loss': 1.784555622137769,\n",
       "    'train_loss': 1.793281885856103},\n",
       "   {'accuracy': 0.4772461513186505,\n",
       "    'f1_macro': 0.15895479568291263,\n",
       "    'f1_weighted': 0.446808464513353,\n",
       "    'loss': 1.7842214791258661,\n",
       "    'train_loss': 1.789649466008465},\n",
       "   {'accuracy': 0.4802516501251486,\n",
       "    'f1_macro': 0.16153458678419394,\n",
       "    'f1_weighted': 0.4479504021609703,\n",
       "    'loss': 1.769451356542879,\n",
       "    'train_loss': 1.678780337668678},\n",
       "   {'accuracy': 0.4804932497076645,\n",
       "    'f1_macro': 0.16077110554020463,\n",
       "    'f1_weighted': 0.4490600132078177,\n",
       "    'loss': 1.7640411596310106,\n",
       "    'train_loss': 1.869746479958494},\n",
       "   {'accuracy': 0.4800680344424365,\n",
       "    'f1_macro': 0.1617702806350876,\n",
       "    'f1_weighted': 0.4451511251707689,\n",
       "    'loss': 1.7614974193502861,\n",
       "    'train_loss': 1.8942427570574345},\n",
       "   {'accuracy': 0.48217478280197534,\n",
       "    'f1_macro': 0.1609351995628439,\n",
       "    'f1_weighted': 0.44652178485771615,\n",
       "    'loss': 1.7558274197412767,\n",
       "    'train_loss': 1.8004472152385418},\n",
       "   {'accuracy': 0.4852092735583753,\n",
       "    'f1_macro': 0.1617296673869088,\n",
       "    'f1_weighted': 0.4493260074681667,\n",
       "    'loss': 1.7456295391327992,\n",
       "    'train_loss': 1.8028088084446032},\n",
       "   {'accuracy': 0.4854412091575906,\n",
       "    'f1_macro': 0.16899410525755185,\n",
       "    'f1_weighted': 0.45093209805448037,\n",
       "    'loss': 1.7389914183218633,\n",
       "    'train_loss': 1.7176981581339388},\n",
       "   {'accuracy': 0.4885240198304937,\n",
       "    'f1_macro': 0.17079712684396084,\n",
       "    'f1_weighted': 0.45713088167064797,\n",
       "    'loss': 1.7342223215927086,\n",
       "    'train_loss': 1.7490714125668343},\n",
       "   {'accuracy': 0.48897822704562366,\n",
       "    'f1_macro': 0.17003696782387975,\n",
       "    'f1_weighted': 0.4584152298351719,\n",
       "    'loss': 1.7260962984331674,\n",
       "    'train_loss': 1.7986765742191135},\n",
       "   {'accuracy': 0.4932110517313026,\n",
       "    'f1_macro': 0.17337295000438818,\n",
       "    'f1_weighted': 0.45893438700737726,\n",
       "    'loss': 1.7181326206019116,\n",
       "    'train_loss': 1.7061970242548639},\n",
       "   {'accuracy': 0.4942547619277714,\n",
       "    'f1_macro': 0.18024013552386164,\n",
       "    'f1_weighted': 0.46375209298134357,\n",
       "    'loss': 1.7124297059771092,\n",
       "    'train_loss': 1.778847258259124},\n",
       "   {'accuracy': 0.49439972167728097,\n",
       "    'f1_macro': 0.17425120760973403,\n",
       "    'f1_weighted': 0.4575653782433824,\n",
       "    'loss': 1.7083235402209402,\n",
       "    'train_loss': 1.6717533768770145},\n",
       "   {'accuracy': 0.4969026933521459,\n",
       "    'f1_macro': 0.17640614697435372,\n",
       "    'f1_weighted': 0.46558871835228255,\n",
       "    'loss': 1.7004717388246806,\n",
       "    'train_loss': 1.823586519267081}],\n",
       "  'hyperparams': {'C': 0.07,\n",
       "   'E': 1,\n",
       "   'K': 143,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.8,\n",
       "   'mu': 0.001,\n",
       "   'percentage': 50,\n",
       "   'rounds': 50,\n",
       "   'target_accuracy': 101},\n",
       "  'test_accuracy': [[0.19266117108149636,\n",
       "    0.25445268030576845,\n",
       "    0.33862597485431545,\n",
       "    0.351411424761058,\n",
       "    0.3640712428848923,\n",
       "    0.370546111696319,\n",
       "    0.3878543057877596,\n",
       "    0.39151695545870097,\n",
       "    0.3946480860481073,\n",
       "    0.40488224436348175,\n",
       "    0.4129226784696116,\n",
       "    0.4127583907535008,\n",
       "    0.4160634730423186,\n",
       "    0.422731621519758,\n",
       "    0.4290905225315771,\n",
       "    0.4292934661808904,\n",
       "    0.433429651033563,\n",
       "    0.4383292905669859,\n",
       "    0.4449587831112228,\n",
       "    0.4486407607487654,\n",
       "    0.4524290422026151,\n",
       "    0.45627530755626855,\n",
       "    0.45894256694724433,\n",
       "    0.45845936778221247,\n",
       "    0.4615615064217169,\n",
       "    0.46482793277733214,\n",
       "    0.46729224851899454,\n",
       "    0.47107086598954356,\n",
       "    0.47312929443257923,\n",
       "    0.475158730925713,\n",
       "    0.477739014466983,\n",
       "    0.4782028856654136,\n",
       "    0.4788697005131575,\n",
       "    0.48163359973713965,\n",
       "    0.48357606038056766,\n",
       "    0.48649458333736,\n",
       "    0.48656223122046444,\n",
       "    0.489741681726374,\n",
       "    0.4899832813088899,\n",
       "    0.49065976013993445,\n",
       "    0.4918677580525141,\n",
       "    0.4922446534012389,\n",
       "    0.4950762005083255,\n",
       "    0.49728925268417135,\n",
       "    0.4955883916232593,\n",
       "    0.49865187432956115,\n",
       "    0.49830397093073825,\n",
       "    0.49995651207514713,\n",
       "    0.49925104129420067,\n",
       "    0.5010485421881191],\n",
       "   [0.1863215980362786,\n",
       "    0.1863215980362786,\n",
       "    0.2325540941465253,\n",
       "    0.28418875692182805,\n",
       "    0.32349217700551813,\n",
       "    0.3339196149869053,\n",
       "    0.3559728248789586,\n",
       "    0.3748272562985011,\n",
       "    0.3859311731109329,\n",
       "    0.3935560559351353,\n",
       "    0.4016834658909709,\n",
       "    0.40207968920629705,\n",
       "    0.4099268436464142,\n",
       "    0.4177739980865313,\n",
       "    0.4238043236661287,\n",
       "    0.43048213612686875,\n",
       "    0.4335842747663732,\n",
       "    0.43668641340587766,\n",
       "    0.4375658358862356,\n",
       "    0.44151840505619605,\n",
       "    0.4450167670110266,\n",
       "    0.4481672255670342,\n",
       "    0.45139499598944693,\n",
       "    0.45218744262009913,\n",
       "    0.45347275239908386,\n",
       "    0.45575345245803417,\n",
       "    0.46013123689322266,\n",
       "    0.4611362911564889,\n",
       "    0.4625762246682838,\n",
       "    0.4656203794079844,\n",
       "    0.46763048793451684,\n",
       "    0.468558230331378,\n",
       "    0.46920571721252063,\n",
       "    0.47059733080781235,\n",
       "    0.47213390415261364,\n",
       "    0.4748784754099945,\n",
       "    0.47598983348956775,\n",
       "    0.4772461513186505,\n",
       "    0.4802516501251486,\n",
       "    0.4804932497076645,\n",
       "    0.4800680344424365,\n",
       "    0.48217478280197534,\n",
       "    0.4852092735583753,\n",
       "    0.4854412091575906,\n",
       "    0.4885240198304937,\n",
       "    0.48897822704562366,\n",
       "    0.4932110517313026,\n",
       "    0.4942547619277714,\n",
       "    0.49439972167728097,\n",
       "    0.4969026933521459]],\n",
       "  'test_loss': [[3.1552519277604354,\n",
       "    2.8022230195171063,\n",
       "    2.363501682538122,\n",
       "    2.307331243881989,\n",
       "    2.271521553354121,\n",
       "    2.224738602497604,\n",
       "    2.147768388257429,\n",
       "    2.1270984703741713,\n",
       "    2.106865762291018,\n",
       "    2.0675022663680696,\n",
       "    2.032825218420059,\n",
       "    2.015762331348034,\n",
       "    2.011586565968702,\n",
       "    1.9867116122617343,\n",
       "    1.9730379162974128,\n",
       "    1.9653936606451523,\n",
       "    1.9457465933821652,\n",
       "    1.925436945151035,\n",
       "    1.9107198179662714,\n",
       "    1.8933967064100152,\n",
       "    1.880548554997531,\n",
       "    1.8651960882853063,\n",
       "    1.8524726179191071,\n",
       "    1.8461399465487993,\n",
       "    1.8316807360378933,\n",
       "    1.8201307742056543,\n",
       "    1.8082097587982948,\n",
       "    1.8027372924566134,\n",
       "    1.7920497018435169,\n",
       "    1.782672423544173,\n",
       "    1.7753312953555733,\n",
       "    1.7715808152369081,\n",
       "    1.7634772728259425,\n",
       "    1.7535029757334715,\n",
       "    1.7464630758071022,\n",
       "    1.7369491496307727,\n",
       "    1.7316247038269976,\n",
       "    1.7273491531216205,\n",
       "    1.7260200289882168,\n",
       "    1.7197946993281672,\n",
       "    1.7167956200012988,\n",
       "    1.7147095290136491,\n",
       "    1.704363350614685,\n",
       "    1.7005959629006784,\n",
       "    1.6993397573006954,\n",
       "    1.6911354253414592,\n",
       "    1.6888316729763273,\n",
       "    1.6850777975120812,\n",
       "    1.6810615969400975,\n",
       "    1.6823281877616443],\n",
       "   [3.541277015299172,\n",
       "    3.1582205124370106,\n",
       "    2.955816364318744,\n",
       "    2.6764137984573257,\n",
       "    2.4416337281323544,\n",
       "    2.397187000782826,\n",
       "    2.289366889592316,\n",
       "    2.216128868888827,\n",
       "    2.15632232240057,\n",
       "    2.118251015465651,\n",
       "    2.0874401883775673,\n",
       "    2.069012484195234,\n",
       "    2.037599367768542,\n",
       "    2.0052707982629867,\n",
       "    1.9780862461720279,\n",
       "    1.9657646903350983,\n",
       "    1.9484004053254385,\n",
       "    1.9382443186054266,\n",
       "    1.9326151902326079,\n",
       "    1.917780861354846,\n",
       "    1.9116229900045205,\n",
       "    1.8953368885197752,\n",
       "    1.8889162495310519,\n",
       "    1.8835785415696822,\n",
       "    1.8658169419699784,\n",
       "    1.8602481828140542,\n",
       "    1.8488903603666256,\n",
       "    1.8419945930136747,\n",
       "    1.8330364606879457,\n",
       "    1.826349980825824,\n",
       "    1.8190817132278128,\n",
       "    1.819151155944745,\n",
       "    1.8112044715609006,\n",
       "    1.8033829476353014,\n",
       "    1.8013793816097772,\n",
       "    1.7903727468377535,\n",
       "    1.784555622137769,\n",
       "    1.7842214791258661,\n",
       "    1.769451356542879,\n",
       "    1.7640411596310106,\n",
       "    1.7614974193502861,\n",
       "    1.7558274197412767,\n",
       "    1.7456295391327992,\n",
       "    1.7389914183218633,\n",
       "    1.7342223215927086,\n",
       "    1.7260962984331674,\n",
       "    1.7181326206019116,\n",
       "    1.7124297059771092,\n",
       "    1.7083235402209402,\n",
       "    1.7004717388246806]],\n",
       "  'train_loss': [[3.59939519056406,\n",
       "    2.9916141570819654,\n",
       "    2.6252085887690284,\n",
       "    2.4268019608040348,\n",
       "    2.4236669331311536,\n",
       "    2.38638985723156,\n",
       "    2.2999324779862045,\n",
       "    2.2358494068545944,\n",
       "    2.1855053720334214,\n",
       "    2.2096586862660317,\n",
       "    2.20527842842287,\n",
       "    2.1936475919819385,\n",
       "    2.0767672276761786,\n",
       "    2.0756926383935603,\n",
       "    2.0747204571729894,\n",
       "    2.0530188000663925,\n",
       "    2.040957220241617,\n",
       "    2.0593446337914534,\n",
       "    1.9855141053712237,\n",
       "    2.0224412628228423,\n",
       "    2.0517241761983285,\n",
       "    2.0030345857398566,\n",
       "    1.9414889939071827,\n",
       "    1.929568940282079,\n",
       "    1.9092354646899448,\n",
       "    1.7184363917334124,\n",
       "    1.9316685260724618,\n",
       "    1.880254217980331,\n",
       "    1.8660751896969292,\n",
       "    1.8628415874426474,\n",
       "    1.671621683971512,\n",
       "    1.8727843269217623,\n",
       "    1.832639259632235,\n",
       "    1.7732961293345522,\n",
       "    1.7726621161507718,\n",
       "    1.820012302669566,\n",
       "    1.7765900163214279,\n",
       "    1.840645990398341,\n",
       "    1.8148940655793726,\n",
       "    1.7602281311755181,\n",
       "    1.726941909886585,\n",
       "    1.7810242795688278,\n",
       "    1.7110707174014053,\n",
       "    1.8690803196327708,\n",
       "    1.798371645818293,\n",
       "    1.7664924968070008,\n",
       "    1.6896978366570081,\n",
       "    1.7426717047077624,\n",
       "    1.7408833094624885,\n",
       "    1.6602468399671384],\n",
       "   [4.028409997998531,\n",
       "    3.313756086308982,\n",
       "    3.202403197131841,\n",
       "    2.8988880691485894,\n",
       "    2.631476512339693,\n",
       "    2.5334295300900807,\n",
       "    2.525124887320602,\n",
       "    2.47293614962726,\n",
       "    2.279606122282062,\n",
       "    2.2716156528429674,\n",
       "    2.209248577426911,\n",
       "    2.29757801058389,\n",
       "    2.180904526220531,\n",
       "    2.1755037173997254,\n",
       "    2.1841618622610266,\n",
       "    2.0843548653249138,\n",
       "    2.1099414554546416,\n",
       "    2.087300038358987,\n",
       "    2.111812862315708,\n",
       "    2.0076064563373004,\n",
       "    1.9664013122480752,\n",
       "    1.993506332723203,\n",
       "    2.0263197208844907,\n",
       "    2.005306660870946,\n",
       "    1.8782613764679688,\n",
       "    1.9699712537835445,\n",
       "    1.9057027746768473,\n",
       "    1.7141371348029906,\n",
       "    1.9211740334335499,\n",
       "    1.888338174445017,\n",
       "    1.935676060798404,\n",
       "    1.8256194372633758,\n",
       "    1.8043030060983352,\n",
       "    1.9501884000854717,\n",
       "    1.8279309646137096,\n",
       "    1.8578730578011076,\n",
       "    1.793281885856103,\n",
       "    1.789649466008465,\n",
       "    1.678780337668678,\n",
       "    1.869746479958494,\n",
       "    1.8942427570574345,\n",
       "    1.8004472152385418,\n",
       "    1.8028088084446032,\n",
       "    1.7176981581339388,\n",
       "    1.7490714125668343,\n",
       "    1.7986765742191135,\n",
       "    1.7061970242548639,\n",
       "    1.778847258259124,\n",
       "    1.6717533768770145,\n",
       "    1.823586519267081]]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "aSs9xXfpQ3ML"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(path + 'Local_Round_FedProx_1.pkl', 'rb') as file:\n",
    "  log_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "N8ep-MalQ3PO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.500541544174532, 0.5039842178554851]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['Shakespeare LSTM on IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_-2I2g0HQ3WA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5010485421881191, 0.4969026933521459]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['Shakespeare LSTM on Non IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfR3lDa7Q-8s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "FederatedAveraging",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "QSGD",
   "language": "python",
   "name": "qsgd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
