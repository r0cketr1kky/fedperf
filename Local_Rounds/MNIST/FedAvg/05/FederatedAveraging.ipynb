{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tushar-semwal/fedperf/blob/main/Vineeth/Local_Rounds/FedAvg/FederatedAveraging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKcpjZLrQQJV",
    "outputId": "5fca5a43-8803-4d05-99e7-310c60b2eb17"
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    import os\n",
    "    path = '/content/drive/MyDrive/Colab Notebooks/OpenMined/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "except:\n",
    "    path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0_nKpfq2h1R"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLLNM9X2JbQ8",
    "outputId": "c88c97b3-b806-4e29-f4cd-02a6743f4f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 12 23:23:12 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 17%   32C    P0    54W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 17%   32C    P0    56W / 250W |      0MiB / 11178MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Check assigned GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "# set manual seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# general reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# gpu training specific\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY4eWzGiL6Mj"
   },
   "source": [
    "## Load the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "G649tjTXLL8F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Using downloaded and verified file: ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# create transforms\n",
    "# We will just convert to tensor and normalize since no special transforms are mentioned in the paper\n",
    "transforms_mnist = transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                       ])\n",
    "\n",
    "mnist_data_train = datasets.MNIST('./data/mnist/', train=True, download=True, transform=transforms_mnist)\n",
    "mnist_data_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=transforms_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dm9usjn2vFkL",
    "outputId": "a76539d2-3f37-4485-e5ac-7633e785c18c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0 1 2 3 4 5 6 7 8 9] \tType: <class 'numpy.ndarray'>\n",
      "Classes Test: [0 1 2 3 4 5 6 7 8 9] \tType: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "classes = np.array(list(mnist_data_train.class_to_idx.values()))\n",
    "classes_test = np.array(list(mnist_data_test.class_to_idx.values()))\n",
    "num_classes = len(classes_test)\n",
    "print(\"Classes: {} \\tType: {}\".format(classes, type(classes)))\n",
    "print(\"Classes Test: {} \\tType: {}\".format(classes_test, type(classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lvJt3Ofv2SO",
    "outputId": "d3626726-b3da-426f-9712-7a7be680d33b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"Image Shape: {}\".format(mnist_data_train.data[0].size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCOONkg-zV7Y"
   },
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "R9MK03TZw6Qs"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "\timg = img/2 + 0.5 #unnormalize the image\n",
    "\tplt.imshow(img, cmap='gray') # convert from tensor to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "gMJ0Kx4Kw-_H"
   },
   "outputs": [],
   "source": [
    "def visualize(dataset):\n",
    "  figure = plt.figure(figsize=(25,4))\n",
    "  for i in range(20):\n",
    "    axis = figure.add_subplot(2, 20/2, i+1, xticks=[], yticks=[])\n",
    "    data = dataset.data[i]\n",
    "    data = data.numpy()\n",
    "\n",
    "    target = dataset.targets[i]\n",
    "    target = target.numpy()\n",
    "    imshow(data)\n",
    "    axis.set_title(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "8bPOwKg10Ro7",
    "outputId": "52916fa2-c981-44e5-92a7-43886e91b271"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(mnist_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "RKoh5Cf70UYu",
    "outputId": "91e5ef2a-5e61-454b-a4f3-c64ff266071a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABXEAAAD7CAYAAAAsAtcsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABFKUlEQVR4nO3dedxN5drA8es2FDJPRYVwiCRjI0KdChEhIvUmVNJxUkoZQ3NUp0Q6KUM5ypCpnjopSqIQHXMUUspMj3lY7x90n/u+j7Xbz3723mvt5/l9Px+f97q69t7rOq/V2mvfrXUt5XmeAAAAAAAAAADCKUfQDQAAAAAAAAAA/LGICwAAAAAAAAAhxiIuAAAAAAAAAIQYi7gAAAAAAAAAEGIs4gIAAAAAAABAiLGICwAAAAAAAAAhxiIuAAAAAAAAAIRYtljEVUqlO3+OK6VeDrovhJtS6kyl1BtKqU1Kqd+VUsuUUk2C7gvhppTqoZRarJQ6rJR6K+h+kDqUUkWVUtOUUvtPHXc6BN0TUoNS6i9KqUNKqQlB94Lw43sKmcHxBhmhlKqilPpUKbVXKbVeKdUq6J4QfkqpuaeOM3+s36wNuieEX3Y53mSLRVzP8/L/8UdEzhGRgyLyXsBtIfxyichPInK1iBQSkX4i8q5SqlyQTSH0fhGRoSIyJuhGkHJGiMgRETlbRDqKyEil1EXBtoQUMUJEvgm6CaQMvqeQGRxvEBWlVC4RmS4is0SkqIh0E5EJSqlKgTaGVNHDWMepHHQzCLfsdLzJFou4jtYisk1Evgi6EYSb53n7Pc8b5HneRs/zTnieN0tEfhSR2kH3hvDyPG+q53nvi8jOoHtB6lBKnSUnv5/6e56X7nnefBGZISKdgu0MYaeUai8ie0RkTsCtIEXwPYVYcbxBBl0oIqVF5AXP8457nvepiHwpnNsAiL9sc7zJjou4d4jIOM/zvKAbQWpRSp0tIpVEZGXQvQDIciqJyDHP89YZ/2y5iHAlLnwppQqKyGAR6RV0LwCyNo43iBMlItWCbgIp4Sml1A6l1JdKqYZBN4OUlCWPN9lqEVcpVVZO3ho/NuhekFqUUrlF5G0RGet53pqg+wGQ5eQXkX3OP9srIgUC6AWpY4iIvOF53pagGwGQ5XG8QUatlZN3wPZWSuVWSl0nJ3+L5wu2LaSAR0SkvIicKyKjRWSmUqpCsC0h5LLN8SZbLeLKyUup53ue92PQjSB1KKVyiMh4OTmrskfA7QDImtJFpKDzzwqKyO8B9IIUoJSqISLXisgLAbcCIIvjeINYeJ53VERaikgzEflVRB4UkXdFhP8QgIg8z1vked7vnucd9jxvrJy8Lb5p0H0hvLLT8SZX0A0k2e0i8nTQTSB1KKWUiLwhJx801PTUwQEA4m2diORSSv3F87zvT/2zS4TxLfDXUETKicjmk19Vkl9EciqlqnqeVyvAvgBkPQ2F4w1i4Hned3LyajgREVFKLRDuikXGeXLy1njAV3Y53mSbK3GVUlfKycvx3wu6F6SUkSJSRUSae553MOhmEH5KqVxKqTwiklNO/sDJc+ppmYAvz/P2i8hUERmslDpLKXWViNwkJ+8CAE5ntIhUEJEap/6MEpHZInJ9cC0hFfA9hRhwvEFMlFLVTx1j8imlHhKRUiLyVsBtIcSUUoWVUtf/8d2klOooIg1EJC3o3hBu2eV4k20WceXkA82mep7HramIyqkZynfLyZPVX5VS6af+dAy2M4RcPxE5KCJ9ROS2U3G/QDtCquguInnl5DyniSJyr+d5XImL0/I874Dneb/+8UdOjuQ45Hne9qB7Q+jxPYUM4XiDTOgkIlvl5LnNNSLyV8/zDgfbEkIut4gMFZHtIrJDRO4XkZbOw3+B08kWxxvleV7QPQAAAAAAAAAAfGSnK3EBAAAAAAAAIOWwiAsAAAAAAAAAIcYiLgAAAAAAAACEGIu4AAAAAAAAABBiLOICAAAAAAAAQIjlysiLlVJeohpBhu3wPK9E0E1Eg/0mPDzPU0H3EA32mVDhWINYsN8gFuw3iAX7DWLBfoNYsN8gw/gNjhj4Hmu4Ejd1bQq6AQDZAscaxIL9BrFgv0Es2G8QC/YbxIL9BkAy+B5rWMQFAAAAAAAAgBBjERcAAAAAAAAAQoxFXAAAAAAAAAAIMRZxAQAAAAAAACDEWMQFAAAAAAAAgBBjERcAAAAAAAAAQoxFXAAAAAAAAAAIMRZxAQAAAAAAACDEWMQFAAAAAAAAgBDLFXQDQDI99NBDVp43b14dV69e3aq1adPG93NGjhxp5V999ZWOx48fn5kWAQAAAAAAAAtX4gIAAAAAAABAiLGICwAAAAAAAAAhxjgFZHmTJk3ScaQRCa4TJ0741u6++24rv/baa3U8b948q7Z58+aot4nso1KlSjpes2aNVevZs6eOX3755aT1hOQ466yzrPy5557TsXtsWbJkiZW3bdtWx5s2bUpAdwAAAEBqKVKkiJWXKVMmqve559MPPPCAjlesWGHV1q1bp+Ply5dntEUgLrgSFwAAAAAAAABCjEVcAAAAAAAAAAgxFnEBAAAAAAAAIMSYiYssx5yBKxL9HFx3LulHH32k4/Lly1u15s2bW3mFChV03LFjR6v21FNPRbV9ZC81a9bUsTt/ecuWLcluB0lUqlQpK+/atauO3X2hdu3aVn7jjTfqeMSIEQnoDkGqVauWlU+dOlXH5cqVS/j2r7vuOitfvXq1jn/66aeEbx/hYp7rzJgxw6r16NFDx6NGjbJqx48fT2xjiFnJkiV1/O6771q1BQsW6Hj06NFWbePGjQnty1WoUCErb9CggY7T0tKs2tGjR5PSE4DgNWvWzMpbtGih44YNG1q1ihUrRvWZ5pxbEZGyZcvq+Mwzz/R9X86cOaP6fCDeuBIXAAAAAAAAAEKMRVwAAAAAAAAACDHGKSBLqFOnjo5btWrl+7qVK1dauXkLxo4dO6xaenq6js844wyrtnDhQiu/5JJLdFysWLEoOkZ2V6NGDR3v37/fqk2bNi3J3SDRSpQooeOxY8cG2AnC7Prrr7fySLfxJYI7Kqhz5846bt++fVJ7QfK55y+vvvqq72tfeeUVHY8ZM8aqHTx4ML6NIWZFihSxcvM82B1Z8Ntvv+k42eMTROx+lixZYtXM71B3zND69esT2xgiKliwoI7dEXLVqlXT8bXXXmvVGIOBP5hjCUVE7rvvPh2bI8dERPLmzWvlSqlMb79SpUqZ/gwgmbgSFwAAAAAAAABCjEVcAAAAAAAAAAgxFnEBAAAAAAAAIMQCn4nbpk0bKzfnnvzyyy9W7dChQzp+++23rdqvv/6qY2YjZT+lSpXSsTsbx5z/5c4b3Lp1a1Sf/+CDD1p51apVfV87e/bsqD4T2Ys5F0xEpEePHjoeP358sttBgv3tb3+z8pYtW+r40ksvjflzGzRooOMcOez/Drt8+XIdf/755zFvA8mVK9d/T8WaNm0aYCf/O4eyV69eOj7rrLOsmjvLG6nPPL6IiJx33nm+r504caKOzfNzBK948eI6njRpklUrWrSojt2Zx/fff39iG/sT/fr10/EFF1xg1e6++24d8zsvWB07drTyJ554Qsfnn3++7/vM2bkiIjt37oxvY0hZ7ndNz549E77NNWvW6Nh9Zg5ST8WKFXVsfgeK/O/zkho2bKjjEydOWLVRo0bp+Msvv7RqYfru4UpcAAAAAAAAAAgxFnEBAAAAAAAAIMQCH6fw7LPPWnm5cuWiep95W42IyO+//67jIC6J37Jli47d/02LFy9OdjvZzsyZM3VsXk4vYu8bu3btiunz27dvb+W5c+eO6XOQfV144YVWbt6a7N7uiNT3wgsvWLl7u06sbr755tPGIiKbNm3Scbt27ayae5s8wqNRo0Y6vuKKK6yaez6RaEWKFLFyc3RQvnz5rBrjFFLfmWeeaeV9+/aN+r3mGCDP8+LWEzKvVq1aOjZvG3UNHjw4Cd34u+iii6zcHF02bdo0q8Z5UrDM291ffPFFq1asWDEdRzoWvPzyy1ZujhUTif03GsLDvY3dHIvg3pqelpam48OHD1u1vXv36tg913BHO3388cc6XrFihVVbtGiRjr/99lurdvDgQd9tIJzM0YTu8cP8TeTuhxlx2WWX6fjYsWNWbe3atTqeP3++VTP39SNHjsS8/WhxJS4AAAAAAAAAhBiLuAAAAAAAAAAQYiziAgAAAAAAAECIBT4Tt2vXrlZevXp1Ha9evdqqValSRcfmvCcRe+bT5ZdfbtV++uknHZ9//vlR9+bOwdi+fbuOS5Uq5fu+zZs3WzkzcZPLnAuZGb1799ZxpUqVIr7WnLljxsAfHn74YSs391OOEVnDBx98oOMcOeLz30h37txp5enp6TouW7asVbvgggt0/PXXX1u1nDlzxqUfZJ4500tEZOLEiTresGGDVXvyySeT0tMfbrrppqRuD8G6+OKLrbx27dq+r3XPiT/88MOE9ISMK1mypJW3bt3a97V33XWXjs3fNclizsH95JNPfF/nzsQ1n2+B5HvooYd0XLRo0Zg+w53Vf8MNN1j5E088oWN3fm4yZkwiNuaMWnM+rYjIJZdcouNWrVr5fsbChQut3Fzn2bhxo1UrU6aMlZvPJYrX8ycQHHMt8L777rNq5jGkYMGCvp/x888/W/kXX3xh5T/++KOO3d/n5jNELr30UqtmHvuaNm1q1ZYvX67jUaNG+fYWL1yJCwAAAAAAAAAhxiIuAAAAAAAAAIRY4OMU5syZEzE3paWl+daKFCmi4xo1alg187LounXrRt3boUOHrHzdunU6dkc9mJdXu7dDIjXceOONVj548GAdn3HGGVZt27ZtVv7oo4/q+MCBAwnoDqmmXLlyVl6nTh0rN48n+/fvT0ZLiLOrr77ayitXrqxj95auaG/xcm/BcW9N27t3r44bN25s1fr27ev7uffee6+OR44cGVUvSIx+/fpZuXkront7qTk+I1HM8xd3n+bWxKwt0m33LvdYhPAYNmyYld922206Nn8DiYi89957SenJT/369XV89tlnW7W33npLxxMmTEhWSzgNd1zTnXfe6fva7777Tse//fabVbv22mt931eoUCErN0c2vP3221bt119/9W8WSeX+Jn7nnXd0bI5PELFHQkUan+JyRyiY3LGVSG2vvfaalZtjN4oXL+77PnfN8D//+Y+OH3vsMavmrumZrrzySis3fy+NGTPGqplrjO6xbsSIETqeMmWKVUvE6CKuxAUAAAAAAACAEGMRFwAAAAAAAABCjEVcAAAAAAAAAAixwGfixsvu3bt1/Nlnn/m+LtLM3T9jzg4zZ/CK2HM4Jk2aFPM2EBx3Zqk788fk/h3PmzcvIT0hdbmzJV2JmI+DxDNnHf/rX/+yapFmN5k2bdpk5ebspMcff9yqRZqx7X5Ot27ddFyiRAmr9uyzz+o4T548Vu2VV17R8dGjR323h9i1adNGx02bNrVq69ev1/HixYuT1tMfzFnK7gzcuXPn6njPnj1J6gjJ0qBBg4j1I0eO6DjSzG0Ey/M8Kzf/Pf7ll1+smvl3mih58+bVsTubsHv37jp2++7cuXNiG0PU3OfLFChQQMdffPGFVTPPd93zi1tvvVXH7r5QoUIFKz/nnHN0PH36dKvWpEkTHe/atStS60iA/Pnz69h8DoyI/UyZHTt2WLXnn39exzwzJvtyjwsPP/ywjrt06WLVlFI6dn8rm8/0eO6556xarM+XKVasmJXnzJlTx4MGDbJq5vO53LnhycaVuAAAAAAAAAAQYiziAgAAAAAAAECIZZlxColQsmRJK3/11Vd1nCOHvf49ePBgHXObR+p4//33dXzdddf5vm7cuHFW3q9fv0S1hCzi4osvjlg3b29H6siV679fm9GOTxCxR660b9/eqrm3n0XLHafw1FNP6Xj48OFWLV++fDp2970ZM2boeMOGDTH1gsjatm2rY/PvQsQ+t0gGcySIiEjHjh11fPz4cas2dOhQHTNqI2u48sorTxufjnl74rJlyxLVEhKoWbNmVv7xxx/r2B2RYt6qmhHu+KiGDRvq+PLLL/d93+TJk2PaHhLvzDPPtHJz9MULL7zg+75Dhw5Z+Ztvvqlj83tQRKR8+fK+n+Peep+MMSDw17JlSx336dPHqm3evFnH9evXt2p79+5NaF9IDeZ3gohI7969dWyOTxAR+fnnn3VsjjIVEfn6669j2r45IkFE5Pzzz9exu8bzwQcf6Ngdn2py+x4/fryOkzF+jCtxAQAAAAAAACDEWMQFAAAAAAAAgBBjERcAAAAAAAAAQoyZuBHcd999Vl6iRAkd796926qtXbs2KT0hc0qVKmXl5jw4d/6TOafSnAsoIpKenp6A7pDqzNlvd955p1X79ttvrfzf//53UnpCMBYvXmzlnTt31nGsM3D/jDnb1pxzKiJSt27dhGwTp1eoUCErjzQXMtY5lLHq1q2blZuznVevXm3VPvvss6T0hOTJyLEg2fsmYvPSSy9ZeaNGjXRcunRpq9agQQMduzP9WrRoEdP23c8x56e6fvjhBx0/9thjMW0PiXfrrbf61tw5y+bzRSKpU6dO1NtfuHChlfO7K1iR5qebv2+2bNmSjHaQYtyZtO7zF0zHjh3T8WWXXWbV2rRpo+MLL7zQ9zMOHjxo5VWqVPHN3d9kZ599tu/nmn777TcrT/YzJLgSFwAAAAAAAABCjEVcAAAAAAAAAAgxxik4rrrqKh336dPH93UtW7a08hUrViSqJcTRlClTrLxYsWK+r50wYYKON2zYkLCekHVce+21Oi5atKhVS0tLs/JDhw4lpSckTo4c/v8d1L0FKBnMW1rd3iL1OmjQIB136tQp7n1lR+54nnPPPVfHEydOTHY7lgoVKvjWOJfJ+iLd0rxnzx4rZ5xCaliyZImVV69eXcc1atSwajfccIOOe/fubdW2b9+u47Fjx0a9/fHjx1v58uXLfV+7YMECHXNuHV7u95Q5asMdyWLe1nzxxRdbtVatWum4SJEiVs093pj1rl27WjVzH1u1alWk1pEA5m3sLvOYMnDgQKs2ffp0HS9btizufSE1fPrpp1ZujuoyfzuLiJQpU0bH//jHP6xapFE95ogGd3xDJJHGJ5w4ccLKp02bpuO//e1vVm3r1q1RbzMeuBIXAAAAAAAAAEKMRVwAAAAAAAAACDEWcQEAAAAAAAAgxJiJ62jatKmOc+fObdXmzJmj46+++ippPSFzzDlOtWrV8n3d3Llzrdyd6wP8mUsuuUTH7tyeyZMnJ7sdJMA999yjY3dWUtCaN2+u45o1a1o1s1e3b3MmLuLj999/t3JzFpw5r1LEnp+9a9euhPRTsmRJHUeabTd//vyEbB/BqVevnpV36NDB97V79+618i1btiSkJyTW7t27dWzOHnTzRx55JC7bK1++vJWb89ndOZgPPfRQXLaJxPrkk0+s3Dw2uHNvzRm1kWZWup953333WfmsWbN0/Je//MWqmfMnzfMwJEeJEiV07J5Dms8AGDBggFXr16+fjkeNGmXVFi5cqGNzDqqIyPr163W8cuXKiL1ddNFFOnbXZ/gOC4eDBw9auTkru3DhwlbNfCaV+awqEZGdO3fqePPmzVbN3A/N3+MiIpdeemnGGj5l9OjRVv7YY4/p2J3pnWxciQsAAAAAAAAAIcYiLgAAAAAAAACEGIu4AAAAAAAAABBi2X4mbt68ea38hhtu0PGRI0esmjkj9ejRo4ltDDErVqyYlZvzS9w5xyZ3bld6enpc+0LWc84551h5/fr1dbx27VqrNm3atKT0hMQy584GwZxLVrVqVatmHusi2b59u5XzfRZ/7vyvDRs26Lh169ZWbfbs2ToePnx4TNurVq2albszKsuVK6fjSDMLwzbnGZnnnhPlyOF//ca///3vRLeDLMidg2keY9y5u+73D8LJnc9+yy236Nh9xkOhQoV8P+fll1/WsbsvHDp0yMqnTp2qY3MupojI9ddfr+MKFSpYNfP7FYnx/PPP67hXr15Rv8/8vunevbtVc/N4cI8v5vNu2rdvH/ftIfPc2bLuv/uxGDdunJVHmonrPsPC3L/feustq3b8+PFM9xYvXIkLAAAAAAAAACHGIi4AAAAAAAAAhFi2H6fQu3dvK69Zs6aO09LSrNqCBQuS0hMy58EHH7TyunXr+r72/fff17E5LgOIxv/93/9ZecmSJXX84YcfJrkbZAd9+/bV8X333Rf1+zZu3KjjO+64w6pt3rw5030hMvP7RSll1Zo1a6bjiRMnxvT5O3bssHJ3ZELx4sWj+hz31jGkvjZt2vjW3NsYX3vttQR3g6ygbdu2Vn777bdbuXl76s6dO5PSExLrk08+0bF7TOnQoYOO3WOKOWrDHZ/gGjJkiI6rVKli1Vq0aHHazxT533MaxJ95i/ukSZOs2jvvvKPjXLnspaXzzz9fx5FG+cSLOXJMxN5X+/XrZ9WGDh2a8H6QPA8//LCOMzI645577rHyWM/Dk40rcQEAAAAAAAAgxFjEBQAAAAAAAIAQYxEXAAAAAAAAAEIs283ENWfPiYj079/fyvft26fjwYMHJ6UnxFevXr2ifm2PHj10nJ6enoh2kIWVLVvWt7Z79+4kdoKs6oMPPrDyypUrx/Q5q1at0vH8+fMz1RMybs2aNTq+5ZZbrFqNGjV0XLFixZg+f/LkyRHrY8eO1XHHjh19X3fw4MGYto9wOe+883Rszqt0bdmyxcoXL16csJ6QdTRp0iRifdasWTpeunRpottBkpnzcU+Xx8r8/nHnrpozcRs1amTVihYtquNdu3bFpRfYjh8/rmP3e6JSpUq+77vmmmt0nDt3bqs2aNAgHUd6fk1mmM8gqF27dkK2gWB06dLFys2Zx+5sZtfKlSt1PHXq1Pg2liRciQsAAAAAAAAAIcYiLgAAAAAAAACEWLYYp1CsWDEd/+Mf/7BqOXPmtHLz1tWFCxcmtjEEzrwF5+jRozF/zt69e30/x7x9pFChQr6fUbhwYSuPdiyEeYuLiMgjjzyi4wMHDkT1GYjNjTfe6FubOXNmEjtBspi3ZuXI4f/fQSPdbjp69GgrL126tO9r3W2cOHHiz1o8rebNm8f0PiTesmXLThvH0w8//BDV66pVq2blK1asSEQ7SLArr7xSx5GOU++//34SukFW436/7d+/38qHDRuWzHaQBb377rtWbo5TaNeunVUzR+MxCjFc5syZ41szR0m54xSOHTum4zfffNOqvf7661b+97//XceRxgch9V166aU6dr9n8ufP7/s+d2TmPffco+PDhw/Hqbvk4kpcAAAAAAAAAAgxFnEBAAAAAAAAIMRYxAUAAAAAAACAEMuSM3HdObdpaWk6vuCCC6zahg0brLx///6Jawyh891338Xlc9577z0db9261aqdffbZOnbnOCXCr7/+quMnnngi4dvLburVq6fjc845J8BOEISRI0fq+Nlnn/V93axZs6w80izbjMy5jfa1o0aNivozkfWZs5zN2MUM3KzBfBaEa8eOHTp+6aWXktEOsgBzhqB5Xisism3bNitfunRpUnpC1uWe65jnWzfddJNVGzhwoI7/9a9/WbV169YloDvEw8cff6xj9/dqrlz/XaLq2rWrVatYsaKVN2zYMKrtbdmyJYMdImzM53sUKFDA93XunHZzpraIyJdffhnfxgLAlbgAAAAAAAAAEGIs4gIAAAAAAABAiGXJcQoVKlSw8tq1a/u+tlevXlbujldA6vnggw+s3L3tJhHatm0b0/uOHTum40i3Sc+YMcPKFy9e7PvaL774IqZeEJ1WrVrp2B3d8u233+r4888/T1pPSJ6pU6fquHfv3latRIkSCd/+9u3bdbx69Wqr1q1bNx27Y12QvXmed9oYWdP111/vW9u8ebOO9+7dm4x2kAWY4xTcY8js2bN93+fe8lqkSBEdm/siEMmyZct0PGDAAKv23HPP6fjJJ5+0ap06ddLxwYMHE9McYmKew7777rtW7ZZbbvF9X6NGjXxrx48ft3Lz2NSnT5+MtoiAud8fDz/8cFTve/vtt6187ty58WopNLgSFwAAAAAAAABCjEVcAAAAAAAAAAgxFnEBAAAAAAAAIMSyzEzcsmXL6vjjjz/2fZ07w3DWrFkJ6wnBuPnmm63cnJ+SO3fuqD/noosu0nG7du2ift+YMWOsfOPGjb6vnTJlio7XrFkT9TaQPPny5bPypk2b+r528uTJOnbnMiFr2LRpk47bt29v1Vq2bKnjnj17JmT7TzzxhI5HjBiRkG0g68mTJ49vjTmBqc89t3GfDWE6dOiQjo8ePZqwnpB9uOc7HTt21PEDDzxg1VauXKnjO+64I7GNIUsaN26cld999906dn8DDh48WMffffddYhtDhpjnHn//+9+tWv78+XVcp04dq1ayZEkrN39njx8/3qoNGjQoc00i6cy/+1WrVlm1SOs45r/f7v6UFXElLgAAAAAAAACEGIu4AAAAAAAAABBiWWacQrdu3XRcpkwZ39fNmzfPyj3PS1hPCIdnn30205/RoUOHOHSCVOTebrp7924dz5gxw6q99NJLSekJ4fD555/75u5YH/M7qnnz5lbN3I9Gjx5t1ZRSVu7eWgRE484779Txnj17rNqQIUOS3A3i7cSJE1a+ePFiHVerVs2qrV+/Pik9Ifvo0qWLld911106fuONN6waxxtk1vbt26382muv1bE7wu6RRx7RsTnmA+Hy22+/Wbl5ntypUyerdvnll1v5448/ruNt27YloDskU+PGjXV83nnnWbVI63bm6B5zbFRWxZW4AAAAAAAAABBiLOICAAAAAAAAQIixiAsAAAAAAAAAIZayM3Hr1atn5ffff39AnQDIytyZuFdeeWVAnSCVpKWlRcyBZPrmm290PHz4cKv22WefJbsdxNnx48etvG/fvjp2Z8gtWbIkKT0ha+nRo4eOBw8ebNXc+fAjR47UsfkcARGRI0eOJKA7ZGebN2/W8SeffGLVWrRooeOqVataNZ4xkBrGjx8fMUfWYs5NjzQD97nnnrPy7HYuy5W4AAAAAAAAABBiLOICAAAAAAAAQIil7DiF+vXrW3n+/Pl9X7thwwYdp6enJ6wnAACAsGnevHnQLSCJfvnlFx137tw5wE6QVcyfP1/HjRs3DrATwF+bNm2sfPny5TquWLGiVWOcAhA+RYsW1bFSyqpt27ZNxy+++GKyWgolrsQFAAAAAAAAgBBjERcAAAAAAAAAQoxFXAAAAAAAAAAIsZSdiRuJOf9GROSaa67R8a5du5LdDgAAAAAASJB9+/ZZ+QUXXBBQJwBiMXz48NPGIiJDhgzR8datW5PWUxhxJS4AAAAAAAAAhBiLuAAAAAAAAAAQYsrzvOhfrFT0L0aiLfE8r07QTUSD/SY8PM9TQfcQDfaZUOFYg1iw3yAW7DeIBfsNYsF+g1iw3yDD+A2OGPgea7gSFwAAAAAAAABCjEVcAAAAAAAAAAgxFnEBAAAAAAAAIMRyZfD1O0RkUyIaQYaVDbqBDGC/CQf2GcSC/QaxYL9BLNhvEAv2G8SC/QaxYL9BRrHPIBa++02GHmwGAAAAAAAAAEguxikAAAAAAAAAQIixiAsAAAAAAAAAIcYiLgAAAAAAAACEWLZZxFVKFVVKTVNK7VdKbVJKdQi6J6QGpVR7pdTqU/vOBqVU/aB7QrgppaoopT5VSu1VSq1XSrUKuieEH99TyCilVA+l1GKl1GGl1FtB94PUoZSaq5Q6pJRKP/VnbdA9Idw4t0FGGceXP/4cV0q9HHRfCD+l1ASl1Fal1D6l1DqlVJege0LqUEr95dQ5zoSge0mEbLOIKyIjROSIiJwtIh1FZKRS6qJgW0LYKaX+KiLPiMidIlJARBqIyA+BNoVQU0rlEpHpIjJLRIqKSDcRmaCUqhRoY0gFfE8ho34RkaEiMiboRpCSeniel//Un8pBN4Pw4twGsTCOL/lF5BwROSgi7wXcFlLDUyJSzvO8giLSQkSGKqVqB9wTUscIEfkm6CYSJVss4iqlzhKR1iLS3/O8dM/z5ovIDBHpFGxnSAGPi8hgz/MWep53wvO8nz3P+znophBqF4pIaRF5wfO8457nfSoiXwrHG0TA9xRi4XneVM/z3heRnUH3AiBL49wGmdVaRLaJyBdBN4Lw8zxvped5h/9IT/2pEGBLSBFKqfYiskdE5gTcSsJki0VcEakkIsc8z1tn/LPlIsIVTvCllMopInVEpMSp28a2KKVeUUrlDbo3pBwlItWCbgKhxvcUgGR7Sim1Qyn1pVKqYdDNIOVwboOMuENExnme5wXdCFKDUupVpdQBEVkjIltF5IOAW0LIKaUKishgEekVdC+JlF0WcfOLyD7nn+2Vk7fHA37OFpHcItJGROqLSA0RqSki/QLsCeG3Vk5eadBbKZVbKXWdiFwtIvmCbQshx/cUgGR6RETKi8i5IjJaRGYqpbjKCX44t0HMlFJl5eT+MjboXpA6PM/rLifPg+uLyFQRORz5HYAMEZE3PM/bEnQjiZRdFnHTRaSg888KisjvAfSC1HHw1P992fO8rZ7n7RCR4SLSNMCeEHKe5x0VkZYi0kxEfhWRB0XkXRHJ0l8myDS+pwAkjed5izzP+93zvMOe542Vk7fGc36D0+LcBpnUSUTme573Y9CNILWcGt8yX0TOE5F7g+4H4aWUqiEi14rICwG3knC5gm4gSdaJSC6l1F88z/v+1D+7RERWBtgTQs7zvN1KqS1ycgaP/sdB9YPU4Xned3LyigMREVFKLRCuPkBkfE8BCJInJ2+PB06Lcxtkwu0i8nTQTSCl5RJm4iKyhiJSTkQ2K6VETt7lmFMpVdXzvFoB9hV32eJKXM/z9svJS/AHK6XOUkpdJSI3icj4YDtDCnhTRO5XSpVUShURkQfk5JN5AV9KqepKqTxKqXxKqYdEpJSIvBVwWwgxvqcQC6VULqVUHhHJKSdPVPOceoo84EspVVgpdf0f+4tSqqOINBCRtKB7Q3hxboNYKKWulJNjW94LuhekhlO/u9srpfIrpXIqpa4XkVslCz+oCnExWk4u9Nc49WeUiMwWkeuDaykxssUi7indRSSvnJznNFFE7vU8jyuc8GeGiMg3cvIqudUi8q2IPBFoR0gFneTkAP5tInKNiPzVeMIq4IfvKWRUPzk5+qePiNx2KmZuO/5MbhEZKiLbRWSHiNwvIi2dBysCLs5tEIs7RGSq53mMh0K0PDk5OmGLiOwWkedF5O+e580ItCuEmud5BzzP+/WPP3JyVN0hz/O2B91bvCkeEAkAAAAAAAAA4ZWdrsQFAAAAAAAAgJTDIi4AAAAAAAAAhBiLuAAAAAAAAAAQYiziAgAAAAAAAECI5crIi5VSPAUtPHZ4nlci6CaiwX4THp7nqaB7iAb7TKhwrEEs2G8QC/YbxIL9BrFgv0Es2G+QYfwGRwx8jzVciZu6NgXdAIBsgWMNYsF+g1iw3yAW7DeIBfsNYsF+AyAZfI81LOICAAAAAAAAQIixiAsAAAAAAAAAIcYiLgAAAAAAAACEGIu4AAAAAAAAABBiLOICAAAAAAAAQIixiAsAAAAAAAAAIcYiLgAAAAAAAACEGIu4AAAAAAAAABBiLOICAAAAAAAAQIjlCroBIJnOPPNMK//yyy91XLNmTas2c+ZMHbds2TKhfQEAAAAAAAB+uBIXAAAAAAAAAEKMRVwAAAAAAAAACLEsM06hXr16Ov7qq6+sWuXKlXV84403WrVmzZpZ+ezZs323sWDBAh3Pnz8/pj6RfOYIhRdeeMGq1ahRQ8ee51m1JUuWJLQvAABiNWjQIB0PHDjQqs2dO9fKGzVqlISOEEa1a9e2cnM8VOvWra2aeb4sIqKU0rF7jrR06VIdr1692qo9+eSTOl6zZk3GGgYAhFb+/Pmt/LzzztNx9+7dfd83ZswYK1+2bFlc+wKyE67EBQAAAAAAAIAQYxEXAAAAAAAAAEKMRVwAAAAAAAAACLGUmolbsGBBHb/99ttWrXHjxjo+ePCgVTvjjDN07M5xcdWvX9+3Zn7ugQMHrNq9996r48mTJ0fcBpLrb3/7m467detm1T799FMdDxgwwKotXLgwsY0ByJaKFCli5eZs7iZNmli13r17W/mJEyd07H7XbNq0ScfDhg2zar/99ltMvSK8rr76at9aw4YNfXN3Xi5Sg3v+cuGFF+o40rlrrVq1rNycbWvOvHVrIiKjR4/W8bRp06zaxx9//CcdAwCyAnP9xD0v7devX1Sfcc8991j5pEmTdNyzZ0+rtmvXroy2CMTFv/71Lx3PnDnTqrnrj0HiSlwAAAAAAAAACDEWcQEAAAAAAAAgxFJqnMIzzzyj42bNmvm+Lm/evFa+evVqHW/fvt2q7du3z/dz3NvMzG2623jjjTd0vG7dOqv23Xff+W4DiXfOOef41j755BMdMz4BQLzkzp3byh988EEd33fffVatVKlSvp9jjk8QsW93bt26te/7ihcvbuWdO3f2bxYpyR2ZEO1rGaeQmkaNGmXl5rHAHfG1Zs0aHb/00ku+Nfec2B2ZgOzFPE7cfPPNVs38vildurRVW7p0qZW/9957On766afj2CGAIDz66KM67tOnT0yfkTNnTivv0KGDjs2xmCIid955p44Z3YNEypHDvqbV3BdXrVqV7HaixpW4AAAAAAAAABBiLOICAAAAAAAAQIixiAsAAAAAAAAAIRbqmbgXXXSRlbdp08b3tVu2bNHx7bffbtXWr1+v4z179li19PR03890Z2QMGDBAx/369bNqBQsW1PHAgQOtWpcuXXS8e/du3+0hMQoUKKDjo0ePWjVzJi6QUTVq1LDyIUOG6Lhp06ZWzT2emLNOJ0+ebNX69u2r461bt1q1Ro0a6XjOnDlW7eDBg1F0jWS4++67rXzo0KExfc68efOsvEGDBlG9z/0eZCZu9jZo0KCgW0AmTZ061cpbtmypY3POrYhI3bp1k9ESUpD5nAh3n7r00kt17D4XxPydtXbtWqtWpkwZKze/7zZt2mTVJk6cmMGOkRlNmjSx8vfff1/H7uz+SMzzyxkzZvi+zv37NmdyX3bZZVZtx44dVj5//vyo+0Fybdy40bdmzmcfMWKEVVu5cqWO3f1t8ODBOnafXzN9+nQdm89EEhF59tlnrdydCQ9kRM2aNa3cfaZIWHElLgAAAAAAAACEGIu4AAAAAAAAABBioR6nYN4GLyJSrFgxHZuX7ovYl9rPnTs3Lts3b3cWsW9HPOOMM6zaQw89pONWrVpZtTFjxuh49uzZcekN/kqXLm3ld911l44XLFhg1ZYuXZqUnpC63Nt/rr76ah2/+eabVq1UqVI6do9R7vHErLdu3dqqmbetnX/++VatYcOGOr7jjjus2oQJE/6nfySPOQKof//+MX1Gnz59rNy8FVHEvv2sd+/eMW0DQOq59957rbx27do6Llu2rFUzb2/fvHlzYhtDqLm3hpq/Q9yRUOa+4o4EWrRokY737t1r1dzzFPNW6LZt21q1SZMm+da+/fZbHX///fdWzT2nQnTcY0NGRiiY8ubNq+N27dpF/b4HHnjAd9vuebG5j7ljxlatWqVj99Z+d7wH4s8c3+N67733dNyzZ8+oP3P58uU6njZtmlUrWrSojt3z6QoVKli5OS7MHZuI1FOpUiUdP//881bt/vvv17E7uiUR/vOf/yR8G7HiSlwAAAAAAAAACDEWcQEAAAAAAAAgxFjEBQAAAAAAAIAQC/VM3DPPPNO3NnbsWCsfMWJEotuxPPbYY1Zuzge64IILrNrNN9+sY2biJl6/fv2CbsFy+eWX69idG2YyZwOJiKxbty5hPSF6tWrVsvK0tDTf127dulXHPXr0sGoHDhzwfZ87s2z//v06fvnll63akSNHTrs9JJ85A1dE5KmnntKxO4fQnOfnznFq0aKFjlevXm3V3JlxAwYM0LE7Q2zGjBm+2//uu+90XL16dUHqe/zxx3U8cODAiK81Z/qbMVLH9u3brXz06NE6Hjp0qFUz//1nJm725s5ON+fg/vLLL1atcuXKOjbPNf7MTz/9ZOXmrNvDhw9btaZNm+r4nXfe8f3M/PnzW7n5rABE74033rByc2ZoxYoVrVqkY0WePHl0fNNNN0W9/SpVqui4RIkSVi1HDvtasiuuuOK0sevQoUNW/txzz+n4z74LERvz31v3vNT9/onW/PnzdezuU+b5dL169axahw4dfD/zzjvvtPJjx47F1BuCY66b3HjjjVbNXP+L10xc9zho+vnnn+OyjUTgSlwAAAAAAAAACDEWcQEAAAAAAAAgxEI9TmHIkCG+tUWLFiWxkz/30Ucf6fiee+6xauZl4Ui8Zs2a+dbc24riZeTIkb7bL1KkiI7z5s3r+xn79u2z8hdeeEHHkf5dQPyZt8mbt6i75syZY+WPPvqojpcuXRr19kqXLm3l06dP13HhwoWtmnnbmLt9JJc7asP8d9+9TdC8NfXVV1+1aitXrox6m+atkF9//bVVe+utt3T84IMPWrWLL75Yx+Zt2CIi3bp1i3r7CA9uG83ezGOMUsqqmbcwu7VI3HEukcYAIbzat2+v4169elm1Xbt26djcT0QyNkIhkg0bNui4atWqVm3cuHG+7zPPfdxb5hEb85xBJD6/g8zfJ3+mWrVqOv7rX/8a8bXmbfK1a9f2fZ052kFEpGfPnjoePny4Vdu7d29UfSKyTz75RMeNGze2auYIuFgtWLDAyh9++GEdu6Mozd/VIvZ+M3PmTKv27rvvZro3JJe7f5kSMd7A/Q20Z88eHWfkt3yycSUuAAAAAAAAAIQYi7gAAAAAAAAAEGIs4gIAAAAAAABAiIVuJm758uV17M6JNOfa/Oc//0laT9H49NNPdezOxEXi5cuXT8e5ctm7tTk/xZwZ+WfMz3FnX06bNs3KzznnHB27szC3b9+uY3OmkPu5ZcqUsWrmjBZ3htimTZsi9o7M6d+/v46LFy9u1czZTO6sufXr18e0PXNmmIhIzZo1fV+blpYW0zYQf02aNLFyz/N0fOLECas2d+5cHQ8bNiwh/fTp08e3N3Mfq1OnTkK2DyBxSpQoYeVdunTRsXnsEREZO3asjt2ZuOZr3Zp7bvP222/71hBe1atX17F7TmrOYE9PT094L1u2bIn6tb///ruO3X0aqWnFihWnjU/HfL7Iueeea9XM85u77rrLqhUsWFDH7vMABgwYEH2z8GXOS480s9Rlfk+Zs2tFRF577bWoPmPixIlW3r17d9/X/uUvf4m6N4RDgQIFrPyaa67RsTvT2H0WSDzkzp3bys3fb8eOHYv79uKFK3EBAAAAAAAAIMRYxAUAAAAAAACAEAvdOIXbbrtNx+ZoBRGRKVOm6HjBggVJ6wnhZ96ucfbZZ1u10aNHR/UZ7vgOc5xBv379Ir73l19+0fH48eOt2quvvqrjSLeVzZgxw8qbNm2q41KlSlk1xinE1+uvv27lbdu21fH+/futmnlLV6zjE0Ts2zceffRRq2be4jpv3jyr5uZIrmLFiun40ksvjfp97nEh0dztPfPMM0ndPoDMM0couMd+cwTT0qVLrZp56+v8+fN9P79r165WXrt2bSu/+eabdeze3m4e/8ztiYgcOHDAd5tIvAoVKvjWkv1dcP3111t53rx5fV/r3jqL7OXQoUM63rBhg1Uz91t3nII5hiMjY/MQvcWLF/vWzPEtefLksWqvvPKKjt3b1q+++uo4dfdf5nqAiMjatWt1/O9//9uqmWM6EZyqVatauTlKZdGiRVbNHVUXq8KFC+u4SpUqVs3dT8KKK3EBAAAAAAAAIMRYxAUAAAAAAACAEGMRFwAAAAAAAABCLHQzcdu3b69jd1bJSy+9lOx2kCJq1qzpW/v++++j+gx37u3dd9+tY3cW3KeffmrlDzzwgI5XrlwZ1fZc0faJ+KtTp46Vm3/f6enpVm3VqlUxbcOdBTVkyBAd169f33f7gwcPjml7SAxzZmS5cuV8X/fFF19Y+ezZsxPVUoYVKVLEys2Z21u3bk12OwB8VK5c+bSxiMjUqVN1bM5xzwj3mQHFixe3cvM5FS1btrRqX3/9tY7d70WznzVr1sTUG6KXL18+K2/VqpXva81nOCTKGWecoeMnn3zSt+aeX61YsSKxjSFl3XTTTb61AgUK6LhNmzZW7dlnn01YT9nJ+++/r2N3Lqn5m9h9Lo0559j9HZQI5qx4EZFJkybp2J3Vbj77Zvr06VaNue7JU69ePd9aop4D065dOx2bzzoREfn8888Tss1440pcAAAAAAAAAAgxFnEBAAAAAAAAIMRCN07B5N6CNX/+/IA6QdiVLl06pvdVqlRJx+al9a7XX3/dynv27GnlR44ciWn7kSxduvS0MVKDe6t99+7drbxXr16+7zVvaV+2bFk820ImmeMUIhk4cKCV7969OxHtxOT888+38mrVqumYcQpZ06BBg4JuATEwz3tz5syZ8O3t2LHDyl988cXTxiL2rahdu3a1aubtiE2aNLFqS5YsyWSX+DPJ2FdM7m3SjRs31nH58uV93zdmzBgr37RpU3wbQ8py95tI32H79u3Tsft7DfFh/v94woQJvq9zR6R07NhRx7fccotVK1q0qI6bNm2a2Rb/lDt2xvzf4Y5y6dChg45jHZMIf2eeeaaO3d/Hu3bt0rE57k1E5J///KeO3dEdZ511lo4bNGgQcftKKd9anjx5Ir43LLgSFwAAAAAAAABCjEVcAAAAAAAAAAgxFnEBAAAAAAAAIMQCn4lrzq8Q+d+5SkA0ChQooONIc05c999/v44LFy5s1d555x0d33vvvbE3FyXzf4OIyNGjR3WciJm7+K9Vq1ZZ+cUXX6zjYsWKWbVvv/02qs8sXry4lbtzmz3P833vnDlzdLxnz56otofkMGdqRTrWzJs3LxntRC1Hjv/+N9sTJ04E2AmArGD06NE6njp1qlUzj3+zZ8+2aub51LRp0xLUXfZy7NgxK9+4caOO3fn81113nY6XL18e0/bcOYWdOnWy8qeeeiqqz3nrrbdi2j6yvubNm1u5u15gMufghun5A7CP/+53gTm72/0NbHJnn7q/n7Zt2+b73scff1zHnTt3tmrm+bz5bAgRkeHDh+v4kUcesWo8qyTzzLmzF1xwge/rZs6caeXm75fVq1dbNfN778MPP4y4/Wuuuea0vYiIPPnkkzreuXOnVRs3blzEz00mrsQFAAAAAAAAgBBjERcAAAAAAAAAQoxFXAAAAAAAAAAIscBn4t5yyy1WXqFCBR3v2LEj2e3ErEWLFr41d1YV4s+cjxNp1qjLnOvlvs+d+ZUI5pzUu+66y6q5M+aQOF26dLHyggUL6rhp06ZWzZyXmxHuMeL222/XcevWra3aqFGjYtoGEq9u3bo6zsixJmjmHKlU6htA+Lnn6+bc22HDhlm11157Tcdly5a1ai+++GL8m8sG3OcmXH311Tp2Z/4/88wzOjbn44qITJkyRcdVq1a1aubMyvr161s1d2blvn37dFyoUCGrtnnzZh3/9NNPAvyhYsWKOh46dKjv6/bv32/lb7zxRsJ6QuaYzwepVKmSVVuwYIGOIz3/IzPPBunZs6eOJ02aZNVGjhypY3cm7rXXXqtjd8Z3kyZNYu4HJx0+fFjH33//vVUrWbKkjs35tCIiY8eO1XGkWch/xvweOu+886ya+Uyiu+++26oxExcAAAAAAAAAEBUWcQEAAAAAAAAgxAIfp5CqateubeU33nij72sfe+yxRLeDGJmXyV911VVWzcwfffRRqzZ69Ggr37lzZ0zbN0cmHDhwwKq5tyAicQ4ePGjlzZs313HDhg2tWp06dXw/Z+XKlTr+8MMPrdqIESOsvE2bNjpet26dVduwYUPkhoFMSE9Pt/JYj18AcDqff/65jt1bT+fNm6fj559/3qoxTiE+tmzZouPbbrvNqvXt21fHjRs3tmpmbt5SKiLy448/6nju3LlWbeLEiVY+a9YsHbvje+bMmaPjXbt2nbZ/ZA/mrfYi9vHgrLPO8n3fgAEDrHzNmjXxbQwxM38/idjHdHOEoIhI+/btdTx9+vSE9iVij28QEalXr56Oly5datXKly+v4yuuuMKq3XDDDTpOS0uLZ4vZxqFDh3RsjqkTEcmV67/Lk/H6jjj33HOtvEiRIjpevny5Vbvjjjt07K7NhAlX4gIAAAAAAABAiLGICwAAAAAAAAAhxiIuAAAAAAAAAIQYM3EzwJyD26tXL6tWuHBhHX/55ZdW7aOPPkpoX9mRO1enVKlSMX2OOQuyVq1aVm3GjBk6HjJkiFUz5+GI2DORf//9d99av379rFrNmjV1PHToUKu2cOHCiL0jOdzZb24erXvuucfKzTlx33zzjVXbvn17TNsA/nD77bf71gYNGmTl7iwwpAbzWOTO7naZf+fu3z+QSDt27LDy+fPn6/jCCy9MdjvZjnkuK2LP63ef72E6cuSIlUf6nqhUqZKVn3HGGb6vnTx5sm8N2UufPn2svEWLFr6v/eGHH3T80ksvJawnZE7+/Pmt3Py97h4XpkyZomNzPq1Icn4Dm7/Xb731Vqv21Vdf6bhAgQJW7ZFHHtExM3Ezb9++fQnfhrtuY87cNme4i4h89913Ce8nHrgSFwAAAAAAAABCjEVcAAAAAAAAAAixwMcpbNy40crdW9GDlDNnTit/6KGHdNyuXTur9vPPP5/2dSIix44dS0B32dsvv/xi5d9//72Oy5Yta9UaN26s49dee82qHThwQMdbt261anXr1tWxORJBRGT16tVWbo7TGDZsmFW76667Trs9EXuEgjuyAamtXLlyEevp6ek6fvHFFxPbDOLGvP3PvY2qePHiOh4zZoxV69y5c2Ibc5i9iNgjOkaNGpXUXgBkX+7IhJYtW+p41apVSe4GR48e1XG8blk+99xzo37tokWL4rJNpJ727dtb+QMPPOD72v3791u5edw4ceJEXPtC/EycONHKzWPDM888Y9WUUjp211yS7ZJLLrFyszdXqtxuj/8qUqSIby3WMYlB40pcAAAAAAAAAAgxFnEBAAAAAAAAIMRYxAUAAAAAAACAEAt8Ju5nn31m5eZs2YIFC1o1c8bfjh074rL96tWrW3n37t11XKtWLatWp04d38+57bbbdMy8p+Qz587Onj3bqjVt2lTHH330kVUbPny4jt2ZuKbLLrvMyh999FHfujtHZ+3atTru27evVZs2bZrvNpHa+vfvH7E+c+ZMHS9dujTR7SBOli1bpuPevXtbtbfeekvHbdu2tWqvvPKKjhP19/3666/r+Oyzz7Zq7733no4PHTqUkO0jsRo2bBgxR9bmzo8051xPmDAh2e1EZD6b4IknnrBq+fLl07F7nERqatOmTdAtIKSuvvpqHbvPJYk0d/T//u//rHzFihVx7QvJMXr0aB3fcMMNVq1Ro0Y6HjdunFWbN2+ejp9++mmrtm7duph66dmzp5V36dJFxxUqVLBqkfZNZC2HDx8OuoWYcCUuAAAAAAAAAIQYi7gAAAAAAAAAEGKBj1OIpEqVKlaelpam40i3vmfE5ZdfbuXFihXzfa05wmHGjBlW7ZtvvolLP4jNli1bdOzermGO7LjiiiusmnmLscu8lcLzvKh7efPNN638kUce0fHOnTuj/hyknosuukjHrVu3jvhad7QHUs+XX35p5e+8846OO3ToYNXMWwrjNU7BvBVNRKRVq1Y63rZtm1UbPHhwXLaJ4AwcODDoFpBk5r/Tzz//vFUzb1NN1DiFEiVKnLYXl1szx5G5x6Lbb79dx2vWrMlsiwhAmTJlrPzWW2/1fe3nn39u5fv27UtITwiHwoULW/msWbN0fNZZZ0V874gRI3Ts/s5GajL/fW/ZsqVVW758uY5LlSpl1e644w4dd+rUyaqdOHEipl5y5Ypt2ctd4+F8GmHAlbgAAAAAAAAAEGIs4gIAAAAAAABAiLGICwAAAAAAAAAhFrqZuH379tVxv379rJo5YytRzDkru3btsmrDhw/X8dNPP53wXhAbd16yOfe4Xbt2Vq1ixYo67tq1q1X75z//qeM/m4n7xhtv6JgZb9mXeYwqUKCAVXP3oUOHDiWlJyTODz/8YOX9+/fX8VVXXWXVzHmm5pxJEZHHHnvMdxuVKlWy8rp16+r4hRdesGrmLLphw4ZZtVWrVvluA+HVsGHD08Z/xp2XPHfu3Pg0hMDkyGFfd9GtWzcduzPYp06dqmNzvr+IyIUXXqhj81kPIv87szDSswHM2urVq63a22+/reMnn3zSqrnbROqpUKGClRcqVMj3tdOnT7fyY8eOJaQnBMc8NpmzTEUiz8FdsmSJlffq1UvHR48ejVN3CIv09HQrN48j7n7Tvn17HVerVs2qlS5dOu69LViwwMrN55a8/vrrVo3n26SeK6+80srN8xfznEhEZP78+UnpKbO4EhcAAAAAAAAAQoxFXAAAAAAAAAAIsdCNU5g2bZqOFy1aZNXS0tJ07F5aHyv3Evlvv/1Wx6NGjYrLNhCsPXv26Pi1117zfV3v3r2T0A2ysuLFi+vYvfV05cqVVj558uSk9ITk2bhxo47dcQrm90n37t2tWpMmTU77OhGRwYMHW3mxYsV8tz9r1iwdjx49+s8bRkp7/PHHdTxo0KDgGkHCmOfEN9xwg1VzRx+YWrVqpWN3fIs5WsX9nnKPG+boA7MXlztG6sCBA76vReorWbJkxLr59//yyy8nuh0EzBxb5455iuSZZ56xckYoZF9jx471zc855xyrlj9/fis3Rwt99tlnVs0cQbZu3TqrtnjxYh3/9NNPVu3w4cPRtI0UEWnE4e7du5PdTlxwJS4AAAAAAAAAhBiLuAAAAAAAAAAQYiziAgAAAAAAAECIKXceVsQXKxX9i5FoSzzPqxN0E9FgvwkPz/NU0D1EI1X3GXOm9sUXX2zV+vTpY+XPP/98UnqKA441cVCoUCEdV65c2ar1799fx+Z8XBGRYcOG+X7mlClTrHzp0qU6PnbsWEx9xhH7DWLBfoNYsN8k0bvvvmvlrVu3tnLzmSZXXnllUnqKEftNDAoWLGjlP/74o46LFCli1ZT678+OL774wqo1btzYykNw3hIt9htkGL/Bg/Pggw9aef369XXcoUMHqxaymf6+xxquxAUAAAAAAACAEGMRFwAAAAAAAABCLFfQDQBAVrFq1Sodu+MUkL3t3btXx19//bVVa968ebLbAQAgJm3atLFydzSfOVoKWc8111xj5e4IBZM5QuHWW2+1aik0PgFACnNH00UaVZcquBIXAAAAAAAAAEKMRVwAAAAAAAAACDEWcQEAAAAAAAAgxJiJCwBxkpaWpuMKFSpYtW+++SbZ7QAAAMRVjhxcA5Sdmc9/EBH59ddfdfz9999btY4dO+r4559/TmxjAJBN8C0MAAAAAAAAACHGIi4AAAAAAAAAhBjjFAAgTsaPH3/aGAAAAEh1a9eutfLSpUsH1AkAZE9ciQsAAAAAAAAAIcYiLgAAAAAAAACEGIu4AAAAAAAAABBiGZ2Ju0NENiWiEWRY2aAbyAD2m3Bgn0Es2G8QC/YbxIL9BrFgv0Es2G8QC/YbZBT7DGLhu98oz/OS2QgAAAAAAAAAIAMYpwAAAAAAAAAAIcYiLgAAAAAAAACEGIu4AAAAAAAAABBiLOICAAAAAAAAQIixiAsAAAAAAAAAIcYiLgAAAAAAAACEGIu4AAAAAAAAABBiLOICAAAAAAAAQIixiAsAAAAAAAAAIfb/64D4+O62SxoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(mnist_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctjRsETiO1qO"
   },
   "source": [
    "## Partitioning the Data (IID and non-IID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3_v8lyrgO5dD"
   },
   "outputs": [],
   "source": [
    "def iid_partition(dataset, clients):\n",
    "  \"\"\"\n",
    "  I.I.D paritioning of data over clients\n",
    "  Shuffle the data\n",
    "  Split it between clients\n",
    "  \n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "\n",
    "  num_items_per_client = int(len(dataset)/clients)\n",
    "  client_dict = {}\n",
    "  image_idxs = [i for i in range(len(dataset))]\n",
    "\n",
    "  for i in range(clients):\n",
    "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
    "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
    "\n",
    "  return client_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "4zMdliGMQoSl"
   },
   "outputs": [],
   "source": [
    "def non_iid_partition(dataset, clients, total_shards, shards_size, num_shards_per_client):\n",
    "  \"\"\"\n",
    "  non I.I.D parititioning of data over clients\n",
    "  Sort the data by the digit label\n",
    "  Divide the data into N shards of size S\n",
    "  Each of the clients will get X shards\n",
    "\n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "    - total_shards (int): Number of shards to partition the data in\n",
    "    - shards_size (int): Size of each shard \n",
    "    - num_shards_per_client (int): Number of shards of size shards_size that each client receives\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "  \n",
    "  shard_idxs = [i for i in range(total_shards)]\n",
    "  client_dict = {i: np.array([], dtype='int64') for i in range(clients)}\n",
    "  idxs = np.arange(len(dataset))\n",
    "  data_labels = dataset.targets.numpy()\n",
    "\n",
    "  # sort the labels\n",
    "  label_idxs = np.vstack((idxs, data_labels))\n",
    "  label_idxs = label_idxs[:, label_idxs[1,:].argsort()]\n",
    "  idxs = label_idxs[0,:]\n",
    "\n",
    "  # divide the data into total_shards of size shards_size\n",
    "  # assign num_shards_per_client to each client\n",
    "  for i in range(clients):\n",
    "    rand_set = set(np.random.choice(shard_idxs, num_shards_per_client, replace=False))\n",
    "    shard_idxs = list(set(shard_idxs) - rand_set)\n",
    "\n",
    "    for rand in rand_set:\n",
    "      client_dict[i] = np.concatenate((client_dict[i], idxs[rand*shards_size:(rand+1)*shards_size]), axis=0)\n",
    "  \n",
    "  return client_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTfxv8kFoGAy"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "CvoDNFKbZST5"
   },
   "outputs": [],
   "source": [
    "class MNIST_2NN(nn.Module):\n",
    "  \"\"\"\n",
    "  A simple multilayer-perceptron with 2-hidden layers with 200 units each\n",
    "  using ReLu activations\n",
    "\n",
    "  Total Expected Params: 199,210\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super(MNIST_2NN, self).__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(28*28, 200)\n",
    "    self.fc2 = nn.Linear(200, 200)\n",
    "    self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    out = self.fc3(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ut1hZ8x3qYPZ"
   },
   "outputs": [],
   "source": [
    "class MNIST_CNN(nn.Module):\n",
    "  \"\"\"\n",
    "  CNN with two 5x5 convolution lauers(the first with 32 channels, second with 64,\n",
    "  each followed with 2x2 max pooling), a fully connected layer with 512 uunits and \n",
    "  ReLu activation, and the final Softmax output layer\n",
    "\n",
    "  Total Expected Params: 1,663,370\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super(MNIST_CNN, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "    \n",
    "    self.pool = nn.MaxPool2d(2,2)\n",
    "    self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    self.fc1 = nn.Linear(1024, 512)\n",
    "    self.out = nn.Linear(512, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = self.dropout(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.out(x)\n",
    "    out = F.log_softmax(x, dim=1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVv4HA9HuLtr"
   },
   "source": [
    "### Print Model Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5oTH710sJEt",
    "outputId": "3e8f2eff-a1be-45a7-a297-5963b3b4e48d"
   },
   "outputs": [],
   "source": [
    "mnist_mlp = MNIST_2NN()\n",
    "mnist_cnn = MNIST_CNN()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  mnist_mlp.cuda()\n",
    "  mnist_cnn.cuda()\n",
    "\n",
    "print(\"MNIST MLP SUMMARY\")\n",
    "print(summary(mnist_mlp, (28,28)))\n",
    "\n",
    "print(\"\\nMNIST CNN SUMMARY\")\n",
    "print(summary(mnist_cnn, (1, 28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gf_8XEXa-gZ7"
   },
   "source": [
    "## Federated Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-aNdQsQ-Kvp"
   },
   "source": [
    "### Local Training (Client Update)\n",
    "\n",
    "Local training for the model on client side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oX6OsQyO-Gz7"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, dataset, idxs):\n",
    "      self.dataset = dataset\n",
    "      self.idxs = list(idxs)\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.idxs)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "      image, label = self.dataset[self.idxs[item]]\n",
    "      return image, label\n",
    "\n",
    "\n",
    "class ClientUpdate(object):\n",
    "  def __init__(self, dataset, batchSize, learning_rate, epochs, idxs):\n",
    "    self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batchSize, shuffle=True)\n",
    "\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epochs = epochs\n",
    "\n",
    "  def train(self, model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.5)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    e_loss = []\n",
    "    for epoch in range(1, self.epochs+1):\n",
    "\n",
    "      train_loss = 0.0\n",
    "      model.train()\n",
    "      for data, labels in self.train_loader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "          data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # make a forward pass\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, labels)\n",
    "        # do a backwards pass\n",
    "        loss.backward()\n",
    "        # perform a single optimization step\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "      # average losses\n",
    "      train_loss = train_loss/len(self.train_loader.dataset)\n",
    "      e_loss.append(train_loss)\n",
    "\n",
    "    total_loss = sum(e_loss)/len(e_loss)\n",
    "\n",
    "    return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukgh1DVHE2Ds"
   },
   "source": [
    "### Server Side Training\n",
    "\n",
    "Following Algorithm 1 from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NF1e33BgpeL"
   },
   "outputs": [],
   "source": [
    "def training(model, rounds, batch_size, lr, ds, ds_test, data_dict, C, K, E, plt_title, plt_color):\n",
    "  \"\"\"\n",
    "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
    "  Specifically, this function is used for the server side training and weight update\n",
    "\n",
    "  Params:\n",
    "    - model:           PyTorch model to train\n",
    "    - rounds:          Number of communication rounds for the client update\n",
    "    - batch_size:      Batch size for client update training\n",
    "    - lr:              Learning rate used for client update training\n",
    "    - ds:              Dataset used for training\n",
    "    - ds_test:         Dataset used for testing\n",
    "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
    "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
    "    - K:               Total number of clients\n",
    "    - E:               Number of training passes each client makes over its local dataset per round\n",
    "    - tb_writer_name:  Directory name to save the tensorboard logs\n",
    "  Returns:\n",
    "    - model:           Trained model on the server\n",
    "  \"\"\"\n",
    "\n",
    "  # global model weights\n",
    "  global_weights = model.state_dict()\n",
    "\n",
    "  # training loss\n",
    "  # train_accuracy = []\n",
    "  train_loss = []\n",
    "  test_accuracy = []\n",
    "  test_loss = []\n",
    "\n",
    "\n",
    "  # measure time\n",
    "  start = time.time()\n",
    "\n",
    "  for curr_round in range(1, rounds+1):\n",
    "    w, local_loss = [], []\n",
    "\n",
    "    m = max(int(C*K), 1)\n",
    "    \n",
    "    S_t = np.random.choice(range(K), m, replace=False)\n",
    "    for k in S_t:\n",
    "      local_update = ClientUpdate(dataset=ds, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=data_dict[k])\n",
    "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
    "\n",
    "      w.append(copy.deepcopy(weights))\n",
    "      local_loss.append(copy.deepcopy(loss))\n",
    "\n",
    "    # updating the global weights\n",
    "    weights_avg = copy.deepcopy(w[0])\n",
    "    for k in weights_avg.keys():\n",
    "      for i in range(1, len(w)):\n",
    "        weights_avg[k] += w[i][k]\n",
    "\n",
    "      weights_avg[k] = torch.div(weights_avg[k], len(w))\n",
    "\n",
    "    global_weights = weights_avg\n",
    "\n",
    "    # move the updated weights to our model state dict\n",
    "    model.load_state_dict(global_weights)\n",
    "\n",
    "    # loss\n",
    "    loss_avg = sum(local_loss) / len(local_loss)\n",
    "    print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)))\n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    # test\n",
    "    test_criterion = nn.CrossEntropyLoss()\n",
    "    test_accuracy_current, test_loss_current =  testing(copy.deepcopy(model), ds_test, 128, test_criterion, num_classes, classes_test)\n",
    "    test_accuracy.append(test_accuracy_current)\n",
    "    test_loss.append(test_loss_current)\n",
    "\n",
    "  end = time.time()\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(train_loss)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Train Loss',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Train_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_loss)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Loss',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_accuracy)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Accuracy',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_Accuracy.jpg', format='jpg')\n",
    "  plt.show()\n",
    "  \n",
    "  print(\"Training Done!\")\n",
    "  print(\"Total time taken to Train: {}\\n\\n\".format(end-start))\n",
    "  \n",
    "  return model, train_loss, test_accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUYyb4T-uXmF"
   },
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCcIZmO5uan9"
   },
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion, num_classes, classes, print_info=False):\n",
    "  #test loss \n",
    "  test_loss = 0.0\n",
    "  correct_class = list(0. for i in range(num_classes))\n",
    "  total_class = list(0. for i in range(num_classes))\n",
    "\n",
    "  test_loader = DataLoader(dataset, batch_size=bs)\n",
    "  l = len(test_loader)\n",
    "  model.eval()\n",
    "  for data, labels in test_loader:\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "      data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    output = model(data)\n",
    "    loss = criterion(output, labels)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "    #test accuracy for each object class\n",
    "    for i in range(num_classes):\n",
    "      label = labels.data[i]\n",
    "      correct_class[label] += correct[i].item()\n",
    "      total_class[label] += 1\n",
    "    \n",
    "  # avg test loss\n",
    "  test_loss = test_loss/len(test_loader.dataset)\n",
    "  test_accuracy = 100. * np.sum(correct_class) / np.sum(total_class)\n",
    "\n",
    "  if print_info:\n",
    "    print(\"Test Loss: {:.6f}\\n\".format(test_loss))\n",
    "\n",
    "    for i in range(10):\n",
    "      if total_class[i]>0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % \n",
    "              (classes[i], 100 * correct_class[i] / total_class[i],\n",
    "              np.sum(correct_class[i]), np.sum(total_class[i])))\n",
    "      else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nFinal Test  Accuracy: {:.3f} ({}/{})'.format(\n",
    "          100. * np.sum(correct_class) / np.sum(total_class),\n",
    "          np.sum(correct_class), np.sum(total_class)))\n",
    "  \n",
    "  return test_accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ri0FqXFeHW-V"
   },
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thZm2kSiHT4v"
   },
   "outputs": [],
   "source": [
    "log_dict = {}\n",
    "NUM_REPEAT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hO5oV6aXqeh"
   },
   "source": [
    "## MNIST CNN on IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flSQv_P4zCfx"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0ZalcKZtEseA",
    "outputId": "b28f6fdb-c1ce-4c59-aa58-0e383d408230"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.1\n",
    "  # number of clients\n",
    "  K = 100\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 5\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr=0.05\n",
    "  # data partition dictionary\n",
    "  iid_dict = iid_partition(mnist_data_train, 100)\n",
    "  # load model\n",
    "  mnist_cnn = MNIST_CNN()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    mnist_cnn.cuda()\n",
    "\n",
    "  mnist_cnn_iid_trained, train_loss, test_accuracy, test_loss = training(mnist_cnn, rounds, batch_size, lr, mnist_data_train, mnist_data_test, iid_dict, C, K, E, \"MNIST CNN on IID Dataset\", \"orange\")\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNwC82przF6G"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qB97BFs9we9w",
    "outputId": "42f4c586-7c3c-46f8-d9c5-7025c1ab4e24"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "acc, loss = testing(mnist_cnn_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdQZEZmHHeqt"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               }\n",
    "\n",
    "log_dict['MNIST CNN on IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF8MdSIUYcnl"
   },
   "source": [
    "## MNIST CNN on Non IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6wXX7JW11bx"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fCD3kBCKYfBK",
    "outputId": "f47df54f-43d5-4d0a-b89b-e90161c5f516"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.1\n",
    "  # number of clients\n",
    "  K = 100\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 5\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr=0.05\n",
    "  # dict containing different type of data partition\n",
    "  data_dict = non_iid_partition(mnist_data_train, 100, 200, 300, 2)\n",
    "  # load model\n",
    "  mnist_cnn = MNIST_CNN()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    mnist_cnn.cuda()\n",
    "\n",
    "  mnist_cnn_non_iid_trained, train_loss, test_accuracy, test_loss = training(mnist_cnn, rounds, batch_size, lr, mnist_data_train, mnist_data_test, data_dict, C, K, E, \"MNIST CNN on Non-IID Dataset\", \"green\")\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C68J-Kk14dB"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yQ9GiAZ15jE",
    "outputId": "2793a0a1-6969-4670-dd04-53dc6b191d44"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "acc, loss = testing(mnist_cnn_non_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxMcxgLhLvX-"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               }\n",
    "\n",
    "log_dict['MNIST CNN on Non IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_jifdzniuhm"
   },
   "source": [
    "## MNIST MLP on IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh-te0Od2XGO"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UmpWmKOQixVV",
    "outputId": "a487fb22-a217-4dfc-f4d6-63c4df004b41"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.1\n",
    "  # number of clients\n",
    "  K = 100\n",
    "  # number of training passes on local dataset for each round\n",
    "  E = 5\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr=0.05\n",
    "  # dict containing different type of data partition\n",
    "  data_dict = iid_partition(mnist_data_train, 100)\n",
    "  # load model\n",
    "  mnist_mlp = MNIST_2NN()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    mnist_mlp.cuda()\n",
    "\n",
    "  mnist_mlp_iid_trained, train_loss, test_accuracy, test_loss = training(mnist_mlp, rounds, batch_size, lr, mnist_data_train, mnist_data_test, data_dict, C, K, E, \"MNIST MLP on IID Dataset\", \"orange\")\n",
    "  \n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTBsL3-72PPd"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9G4j5L62OrS",
    "outputId": "e74613f0-7e49-4865-b430-223d32519658"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "acc, loss = testing(mnist_mlp_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWCdJFRCL_f2"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               }\n",
    "\n",
    "log_dict['MNIST MLP on IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8jzEyO0iywz"
   },
   "source": [
    "## MNIST MLP on Non IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJFepr3y2bF-"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EBKO44Hgi1Uh",
    "outputId": "7d0db2bf-fa03-4916-cb89-c2055290bdbb"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "  \n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.1\n",
    "  # number of clients\n",
    "  K = 100\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 5\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr=0.05\n",
    "  # dict containing different type of data partition\n",
    "  data_dict = non_iid_partition(mnist_data_train, 100, 200, 300, 2)\n",
    "  # load model\n",
    "  mnist_mlp = MNIST_2NN()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    mnist_mlp.cuda()\n",
    "\n",
    "  mnist_mlp_non_iid_trained, train_loss, test_accuracy, test_loss = training(mnist_mlp, rounds, batch_size, lr, mnist_data_train, mnist_data_test, data_dict, C, K, E, \"MNIST MLP on Non-IID Dataset\", \"green\")\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmuQYPbF2mes"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tKMlJyF2nGN",
    "outputId": "93f7b3e3-8165-4dc8-d40c-579225a8aa33"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "acc, loss = testing(mnist_mlp_non_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1W5krYcSMQiu"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               }\n",
    "\n",
    "log_dict['MNIST MLP on Non IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emS_SaRAP6TZ"
   },
   "source": [
    "## Pickle Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soAN38JoP0c1"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open(path + 'Local_Round_FedAvg_5.pkl', 'wb') as file:\n",
    "  pickle.dump(log_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UBy-JswSoCJ",
    "outputId": "13b2bc77-3443-45b3-ee10-9e2265548afa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MNIST CNN on IID': {'hyperparams': {'C': 0.1,\n",
       "   'E': 5,\n",
       "   'K': 100,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.05,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[94.43037974683544,\n",
       "    96.83544303797468,\n",
       "    97.46835443037975,\n",
       "    97.84810126582279,\n",
       "    98.10126582278481,\n",
       "    98.73417721518987,\n",
       "    98.73417721518987,\n",
       "    98.86075949367088,\n",
       "    98.86075949367088,\n",
       "    98.86075949367088,\n",
       "    98.9873417721519,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696],\n",
       "   [94.43037974683544,\n",
       "    96.07594936708861,\n",
       "    96.83544303797468,\n",
       "    97.46835443037975,\n",
       "    97.72151898734177,\n",
       "    98.10126582278481,\n",
       "    98.48101265822785,\n",
       "    98.22784810126582,\n",
       "    98.48101265822785,\n",
       "    98.73417721518987,\n",
       "    98.86075949367088,\n",
       "    98.86075949367088,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    98.9873417721519,\n",
       "    99.11392405063292,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.11392405063292,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.62025316455696,\n",
       "    99.74683544303798,\n",
       "    99.62025316455696,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.74683544303798,\n",
       "    99.74683544303798,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494],\n",
       "   [94.30379746835443,\n",
       "    97.21518987341773,\n",
       "    97.72151898734177,\n",
       "    97.9746835443038,\n",
       "    98.10126582278481,\n",
       "    98.22784810126582,\n",
       "    98.10126582278481,\n",
       "    98.48101265822785,\n",
       "    98.9873417721519,\n",
       "    98.86075949367088,\n",
       "    98.9873417721519,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    98.9873417721519,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.11392405063292,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.49367088607595,\n",
       "    99.24050632911393,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.74683544303798,\n",
       "    99.74683544303798,\n",
       "    99.62025316455696,\n",
       "    99.74683544303798,\n",
       "    99.74683544303798,\n",
       "    99.74683544303798,\n",
       "    99.74683544303798,\n",
       "    99.74683544303798],\n",
       "   [95.0632911392405,\n",
       "    96.83544303797468,\n",
       "    96.9620253164557,\n",
       "    97.72151898734177,\n",
       "    98.35443037974683,\n",
       "    98.48101265822785,\n",
       "    98.48101265822785,\n",
       "    98.73417721518987,\n",
       "    98.9873417721519,\n",
       "    98.9873417721519,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.36708860759494,\n",
       "    99.11392405063292,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    98.9873417721519,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595],\n",
       "   [94.0506329113924,\n",
       "    97.0886075949367,\n",
       "    97.72151898734177,\n",
       "    97.84810126582279,\n",
       "    97.9746835443038,\n",
       "    98.22784810126582,\n",
       "    98.48101265822785,\n",
       "    98.60759493670886,\n",
       "    98.86075949367088,\n",
       "    98.9873417721519,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.11392405063292,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595]],\n",
       "  'test_loss': [[0.28707000436782837,\n",
       "    0.10102948295995592,\n",
       "    0.07433280615485273,\n",
       "    0.06806274849933107,\n",
       "    0.059012581154715735,\n",
       "    0.053434443478498725,\n",
       "    0.05004069135223399,\n",
       "    0.041982381846499627,\n",
       "    0.04075262037030188,\n",
       "    0.04094275901892106,\n",
       "    0.039291360499712755,\n",
       "    0.0360837310015806,\n",
       "    0.03537729832479381,\n",
       "    0.032801516075452675,\n",
       "    0.03464352218119602,\n",
       "    0.0356875872757184,\n",
       "    0.031935948380551415,\n",
       "    0.0313931642608688,\n",
       "    0.03004386509898177,\n",
       "    0.03147422516620282,\n",
       "    0.03116243175119016,\n",
       "    0.030397335330364875,\n",
       "    0.02809188125817309,\n",
       "    0.02888359694610117,\n",
       "    0.028211886157267146,\n",
       "    0.026191967681366078,\n",
       "    0.0255480881679905,\n",
       "    0.026771763737298535,\n",
       "    0.025832915643948944,\n",
       "    0.026729500107122293,\n",
       "    0.026038786947898917,\n",
       "    0.025401082759458585,\n",
       "    0.026040006287960205,\n",
       "    0.02606683307582207,\n",
       "    0.025477474651856756,\n",
       "    0.025761027652064512,\n",
       "    0.025356270519139072,\n",
       "    0.024751209950141493,\n",
       "    0.024301187553179626,\n",
       "    0.02242373033950207,\n",
       "    0.023168681442731758,\n",
       "    0.022899829958620103,\n",
       "    0.022563685536551928,\n",
       "    0.02252362782321652,\n",
       "    0.022496340877670447,\n",
       "    0.02231427665589872,\n",
       "    0.021626382561205536,\n",
       "    0.021301827716055412,\n",
       "    0.02156404883353316,\n",
       "    0.020949622330615966],\n",
       "   [0.30752798709869383,\n",
       "    0.09967672347538173,\n",
       "    0.08645709916302002,\n",
       "    0.06698787448531948,\n",
       "    0.06108889193830546,\n",
       "    0.052733727407554394,\n",
       "    0.050547319852607325,\n",
       "    0.04676783196439501,\n",
       "    0.044623031701921716,\n",
       "    0.040237224328459706,\n",
       "    0.04172777729198569,\n",
       "    0.04486498230183788,\n",
       "    0.03955733189907623,\n",
       "    0.03893716280334629,\n",
       "    0.038239651310787305,\n",
       "    0.03699823670741171,\n",
       "    0.03573538309937867,\n",
       "    0.03602562065277889,\n",
       "    0.03490195910933544,\n",
       "    0.03440200915717869,\n",
       "    0.03341184304261551,\n",
       "    0.03329430827700853,\n",
       "    0.03181912090014375,\n",
       "    0.031796825454675125,\n",
       "    0.03143580598527478,\n",
       "    0.0320045748314471,\n",
       "    0.029827210314502008,\n",
       "    0.03216216434459129,\n",
       "    0.03151568200904585,\n",
       "    0.029353229858027772,\n",
       "    0.029546445424083505,\n",
       "    0.028500206942512887,\n",
       "    0.027910996296549275,\n",
       "    0.028076846937923984,\n",
       "    0.02723962686475861,\n",
       "    0.026846278282935964,\n",
       "    0.025951585840754705,\n",
       "    0.02687016794635638,\n",
       "    0.02842707362554429,\n",
       "    0.027788527115598843,\n",
       "    0.026672387896094007,\n",
       "    0.028043586106453584,\n",
       "    0.027017182170918384,\n",
       "    0.0269298500823832,\n",
       "    0.02577931193548211,\n",
       "    0.02501725802889923,\n",
       "    0.025375850941057432,\n",
       "    0.025644126877218877,\n",
       "    0.026098104414687986,\n",
       "    0.026795381744942462],\n",
       "   [0.31527115836143493,\n",
       "    0.10421526004374028,\n",
       "    0.08415165983566548,\n",
       "    0.06900277654544916,\n",
       "    0.05826182350289309,\n",
       "    0.04999789083953947,\n",
       "    0.04899227587592613,\n",
       "    0.048932974103669404,\n",
       "    0.04465015136337897,\n",
       "    0.04189173573321023,\n",
       "    0.03877897691082326,\n",
       "    0.03777966799839633,\n",
       "    0.03529407976225484,\n",
       "    0.0349908800050529,\n",
       "    0.03315233841142035,\n",
       "    0.03328694664681971,\n",
       "    0.031370681550927114,\n",
       "    0.02915359330889769,\n",
       "    0.029330298120857332,\n",
       "    0.029954877717772613,\n",
       "    0.0272251676885513,\n",
       "    0.02771887269911822,\n",
       "    0.02663836478120793,\n",
       "    0.026299288588065246,\n",
       "    0.025475500407013168,\n",
       "    0.02454489602273825,\n",
       "    0.025506483431591186,\n",
       "    0.02512821823075792,\n",
       "    0.024650217349817104,\n",
       "    0.0257329407081721,\n",
       "    0.02577591839568122,\n",
       "    0.02589538514620872,\n",
       "    0.025554727028026535,\n",
       "    0.02509880199756444,\n",
       "    0.022826916793335112,\n",
       "    0.023839898733637527,\n",
       "    0.024346671159620747,\n",
       "    0.024339785514806863,\n",
       "    0.02479425105849805,\n",
       "    0.023272372787509085,\n",
       "    0.023593160698103747,\n",
       "    0.024335849525544472,\n",
       "    0.024030084725044434,\n",
       "    0.023157057054257166,\n",
       "    0.023088402072064126,\n",
       "    0.02269199844365612,\n",
       "    0.022998676686425825,\n",
       "    0.021957531253408887,\n",
       "    0.022318423496216565,\n",
       "    0.021977715221063773],\n",
       "   [0.24527670850753786,\n",
       "    0.10757666289657354,\n",
       "    0.08524313668375835,\n",
       "    0.06894091073870659,\n",
       "    0.05938034075939213,\n",
       "    0.05317708238862397,\n",
       "    0.050415905541868415,\n",
       "    0.04554880748556461,\n",
       "    0.044181098475135516,\n",
       "    0.040720151254294616,\n",
       "    0.03913176558594278,\n",
       "    0.037079602213460024,\n",
       "    0.033137716857151826,\n",
       "    0.03308811042849556,\n",
       "    0.030876600635997602,\n",
       "    0.03075367842412088,\n",
       "    0.030543855954681204,\n",
       "    0.028801972824323455,\n",
       "    0.029718416937318397,\n",
       "    0.027710013877938037,\n",
       "    0.03054821851195302,\n",
       "    0.02943840787381996,\n",
       "    0.028986665816192546,\n",
       "    0.027611906857133727,\n",
       "    0.027357863477363572,\n",
       "    0.026142108505941723,\n",
       "    0.02568529047916636,\n",
       "    0.026397362674908435,\n",
       "    0.02625805098802921,\n",
       "    0.02582670612759248,\n",
       "    0.024195308412928718,\n",
       "    0.025666372062875597,\n",
       "    0.025128042978716986,\n",
       "    0.023456001944912715,\n",
       "    0.024568185997594628,\n",
       "    0.024070779173876507,\n",
       "    0.024088838249979743,\n",
       "    0.023779308938993562,\n",
       "    0.022443405110236198,\n",
       "    0.023244451009449402,\n",
       "    0.023823467827505374,\n",
       "    0.023735777343451628,\n",
       "    0.02367303391389796,\n",
       "    0.0223544360257094,\n",
       "    0.0222824876552113,\n",
       "    0.022094472161632437,\n",
       "    0.02264165619596861,\n",
       "    0.022218025568549637,\n",
       "    0.022586624295445654,\n",
       "    0.02168605721210606],\n",
       "   [0.40233294353485105,\n",
       "    0.09841629305928945,\n",
       "    0.08130432992670684,\n",
       "    0.06893907611141913,\n",
       "    0.06388926848617849,\n",
       "    0.05711995794541435,\n",
       "    0.050626625612546924,\n",
       "    0.04743613313852111,\n",
       "    0.044614249514753464,\n",
       "    0.04260643079295987,\n",
       "    0.03705467284572078,\n",
       "    0.03720386533671117,\n",
       "    0.03558365749356162,\n",
       "    0.03336635222722252,\n",
       "    0.03503055974607851,\n",
       "    0.032028164961896984,\n",
       "    0.031311437787082105,\n",
       "    0.03148412381263333,\n",
       "    0.029359905129078833,\n",
       "    0.029205405069640984,\n",
       "    0.029804290222748386,\n",
       "    0.029264165933146433,\n",
       "    0.02820003878555435,\n",
       "    0.02910162186532325,\n",
       "    0.026615676671174877,\n",
       "    0.027667829494361102,\n",
       "    0.026904609444170637,\n",
       "    0.02642098932748777,\n",
       "    0.02610143059229813,\n",
       "    0.02609951317021205,\n",
       "    0.025148859113307845,\n",
       "    0.025128082950144744,\n",
       "    0.026361240232859563,\n",
       "    0.02485125848059906,\n",
       "    0.024022765581455316,\n",
       "    0.02528932601693814,\n",
       "    0.0242308942557971,\n",
       "    0.024739610316209838,\n",
       "    0.02500593526456032,\n",
       "    0.024843940858785028,\n",
       "    0.024285388694447102,\n",
       "    0.024195668456726344,\n",
       "    0.024774592986027893,\n",
       "    0.025381102668095627,\n",
       "    0.025271539562509316,\n",
       "    0.025779066215101374,\n",
       "    0.024576424054777453,\n",
       "    0.023606315656984952,\n",
       "    0.023542483882208035,\n",
       "    0.023370375937359494]],\n",
       "  'train_loss': [[0.5047347418840412,\n",
       "    0.1312671918678725,\n",
       "    0.08431469233378024,\n",
       "    0.05916172847991178,\n",
       "    0.05456637232381013,\n",
       "    0.04152115872607258,\n",
       "    0.03799512543924628,\n",
       "    0.042364287598312046,\n",
       "    0.03370392142531151,\n",
       "    0.026343744195975915,\n",
       "    0.02761299162643152,\n",
       "    0.029837970099760358,\n",
       "    0.01976238005745479,\n",
       "    0.03189922250340922,\n",
       "    0.02472857997768303,\n",
       "    0.02258767338895897,\n",
       "    0.020950866950595427,\n",
       "    0.022309609079107326,\n",
       "    0.018933972436221073,\n",
       "    0.018375105219317837,\n",
       "    0.01850790522189408,\n",
       "    0.01866640618945036,\n",
       "    0.012006986234702886,\n",
       "    0.019512724604849603,\n",
       "    0.01548899823529568,\n",
       "    0.01533957937564569,\n",
       "    0.013602226411249191,\n",
       "    0.012273872811191185,\n",
       "    0.014955543393640983,\n",
       "    0.013514071355888242,\n",
       "    0.014733669774577709,\n",
       "    0.012344219294024001,\n",
       "    0.013923169270625587,\n",
       "    0.016030377167007826,\n",
       "    0.011573889127542106,\n",
       "    0.009237622045379146,\n",
       "    0.010331860888225292,\n",
       "    0.012730465995721049,\n",
       "    0.010402967717447356,\n",
       "    0.013047350719464524,\n",
       "    0.009468419230532347,\n",
       "    0.009622086017618823,\n",
       "    0.012605214173353831,\n",
       "    0.008892052226429428,\n",
       "    0.01103794009883562,\n",
       "    0.00928165272589855,\n",
       "    0.008841372084264047,\n",
       "    0.010031647872996935,\n",
       "    0.008610855297474896,\n",
       "    0.011129143593834014],\n",
       "   [0.503362713351283,\n",
       "    0.1477883848285375,\n",
       "    0.0736343698580691,\n",
       "    0.07492689835595587,\n",
       "    0.04763988978464957,\n",
       "    0.043835051409450716,\n",
       "    0.04585082029734687,\n",
       "    0.03901130160758605,\n",
       "    0.0292779618650143,\n",
       "    0.030291058480790937,\n",
       "    0.03553065370046039,\n",
       "    0.037630406689483406,\n",
       "    0.022907760181123137,\n",
       "    0.029275676411252026,\n",
       "    0.023031762835989754,\n",
       "    0.02627129996868647,\n",
       "    0.022292408635110967,\n",
       "    0.020307782949823862,\n",
       "    0.02222099161971996,\n",
       "    0.018703085951570483,\n",
       "    0.020059456262760098,\n",
       "    0.016339440523393735,\n",
       "    0.013429624417213626,\n",
       "    0.018200417353910973,\n",
       "    0.01735107624536072,\n",
       "    0.01681534201977579,\n",
       "    0.014392881415620415,\n",
       "    0.012502863955856711,\n",
       "    0.01945431598394427,\n",
       "    0.018404824111492593,\n",
       "    0.015176353188345603,\n",
       "    0.01590176739479075,\n",
       "    0.01500006247614423,\n",
       "    0.010939140692099975,\n",
       "    0.014355719867767246,\n",
       "    0.012663403283325974,\n",
       "    0.013344033582979234,\n",
       "    0.009141608751560209,\n",
       "    0.015782361578996432,\n",
       "    0.009296696063288905,\n",
       "    0.011407296830369605,\n",
       "    0.014427615091605677,\n",
       "    0.013001565715732582,\n",
       "    0.007305604357581712,\n",
       "    0.010051901803952476,\n",
       "    0.00899476392855883,\n",
       "    0.009343969084743595,\n",
       "    0.007348381133301447,\n",
       "    0.01305128588685241,\n",
       "    0.011694260581744508],\n",
       "   [0.506853538196614,\n",
       "    0.1406126092811337,\n",
       "    0.08152704237763207,\n",
       "    0.06521454854335267,\n",
       "    0.05103591641944542,\n",
       "    0.051472099825239336,\n",
       "    0.03942514802044626,\n",
       "    0.036270889038344814,\n",
       "    0.03932652742168967,\n",
       "    0.030985108139167432,\n",
       "    0.033750293150092744,\n",
       "    0.027420960890373387,\n",
       "    0.024863670251337414,\n",
       "    0.02943101282573305,\n",
       "    0.0257143367499132,\n",
       "    0.023815473342067583,\n",
       "    0.022089846806881173,\n",
       "    0.024566300379403824,\n",
       "    0.02119702691771611,\n",
       "    0.021368562233601843,\n",
       "    0.015526167038659324,\n",
       "    0.01946692547788386,\n",
       "    0.020766157262866004,\n",
       "    0.012847625275458862,\n",
       "    0.02027381480863382,\n",
       "    0.014508567145160228,\n",
       "    0.015386514111016537,\n",
       "    0.014328502866321346,\n",
       "    0.018030785502971353,\n",
       "    0.014150971184378473,\n",
       "    0.012491592790209009,\n",
       "    0.009787930077311947,\n",
       "    0.016928813197561773,\n",
       "    0.011940172262855542,\n",
       "    0.017931046819645663,\n",
       "    0.009072567334778816,\n",
       "    0.013349967225463383,\n",
       "    0.015299106552208373,\n",
       "    0.008417520268734708,\n",
       "    0.012550637829123312,\n",
       "    0.011203149193637633,\n",
       "    0.013179093867609223,\n",
       "    0.009879248075506013,\n",
       "    0.01022084951849886,\n",
       "    0.005130060301358501,\n",
       "    0.01093503850764684,\n",
       "    0.00913291093605149,\n",
       "    0.009189262261553264,\n",
       "    0.008217403835891677,\n",
       "    0.008937107221695283],\n",
       "   [0.4722327896845819,\n",
       "    0.13279591673005234,\n",
       "    0.0677538140645679,\n",
       "    0.0735662947868386,\n",
       "    0.06030494111908887,\n",
       "    0.03828689741325371,\n",
       "    0.04076100532027281,\n",
       "    0.03885312801825292,\n",
       "    0.02968939494739401,\n",
       "    0.03839353083741448,\n",
       "    0.02853284926947755,\n",
       "    0.02568589276564092,\n",
       "    0.024312777275158494,\n",
       "    0.021971723895405457,\n",
       "    0.02200155875872715,\n",
       "    0.02286616603270224,\n",
       "    0.020890177225146564,\n",
       "    0.030360778894471883,\n",
       "    0.022661941126556888,\n",
       "    0.0186947904000685,\n",
       "    0.02315308174174065,\n",
       "    0.01566294465281734,\n",
       "    0.017847353291711825,\n",
       "    0.01639924065503294,\n",
       "    0.016068551217734643,\n",
       "    0.01751715223478657,\n",
       "    0.016583603389504535,\n",
       "    0.013688090040946736,\n",
       "    0.015839918508872484,\n",
       "    0.014378530009883228,\n",
       "    0.0135823954289753,\n",
       "    0.015012106575513435,\n",
       "    0.01625982975463334,\n",
       "    0.015201492814091161,\n",
       "    0.011502093603890196,\n",
       "    0.012453299154436317,\n",
       "    0.012225335807219918,\n",
       "    0.009801270369087869,\n",
       "    0.016841185234022064,\n",
       "    0.01095896443509053,\n",
       "    0.012481684988156558,\n",
       "    0.013936663547974093,\n",
       "    0.0075309565216240245,\n",
       "    0.01134592388600698,\n",
       "    0.012138062800574338,\n",
       "    0.011660895005762974,\n",
       "    0.008516973321401918,\n",
       "    0.010468862982905659,\n",
       "    0.011686244381315653,\n",
       "    0.007997407157050232],\n",
       "   [0.501339711105257,\n",
       "    0.14768912446415197,\n",
       "    0.08469315520386833,\n",
       "    0.07065934071163503,\n",
       "    0.04981554737509828,\n",
       "    0.046853659439768686,\n",
       "    0.045417473600211554,\n",
       "    0.037589855360306255,\n",
       "    0.0364209375301619,\n",
       "    0.032829644675457834,\n",
       "    0.03778293007188099,\n",
       "    0.02626677282099681,\n",
       "    0.027110740831451458,\n",
       "    0.028964563275609517,\n",
       "    0.020862219255026508,\n",
       "    0.02024160756352844,\n",
       "    0.026938926394363606,\n",
       "    0.01796813079677196,\n",
       "    0.027224214277447572,\n",
       "    0.01724710204753664,\n",
       "    0.020265341071149447,\n",
       "    0.015870644180115294,\n",
       "    0.01389786451249302,\n",
       "    0.01542456726284204,\n",
       "    0.019599508200972456,\n",
       "    0.012739995846557148,\n",
       "    0.016452456335097107,\n",
       "    0.013274086926540325,\n",
       "    0.013491783499608676,\n",
       "    0.010063687337665949,\n",
       "    0.018272952674508326,\n",
       "    0.010863415886495519,\n",
       "    0.014437121642346003,\n",
       "    0.013221738655098092,\n",
       "    0.013554463750806257,\n",
       "    0.013054127814560793,\n",
       "    0.012799130533142949,\n",
       "    0.012374380307472298,\n",
       "    0.013701197652741332,\n",
       "    0.010099451032384717,\n",
       "    0.010176989724063458,\n",
       "    0.01079624702492125,\n",
       "    0.007066838514234651,\n",
       "    0.009864614096019516,\n",
       "    0.010131905811103018,\n",
       "    0.012883624480331049,\n",
       "    0.011783966176300282,\n",
       "    0.013728398678128506,\n",
       "    0.00834842218564142,\n",
       "    0.007238725852267247]]},\n",
       " 'MNIST CNN on Non IID': {'hyperparams': {'C': 0.1,\n",
       "   'E': 5,\n",
       "   'K': 100,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.05,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[11.772151898734178,\n",
       "    55.063291139240505,\n",
       "    69.11392405063292,\n",
       "    63.67088607594937,\n",
       "    82.9113924050633,\n",
       "    84.68354430379746,\n",
       "    80.88607594936708,\n",
       "    83.92405063291139,\n",
       "    79.87341772151899,\n",
       "    91.64556962025317,\n",
       "    82.53164556962025,\n",
       "    95.0632911392405,\n",
       "    96.20253164556962,\n",
       "    95.44303797468355,\n",
       "    93.16455696202532,\n",
       "    91.89873417721519,\n",
       "    95.44303797468355,\n",
       "    96.70886075949367,\n",
       "    93.0379746835443,\n",
       "    96.83544303797468,\n",
       "    97.0886075949367,\n",
       "    96.9620253164557,\n",
       "    96.9620253164557,\n",
       "    97.34177215189874,\n",
       "    97.0886075949367,\n",
       "    95.0632911392405,\n",
       "    97.84810126582279,\n",
       "    96.58227848101266,\n",
       "    97.46835443037975,\n",
       "    96.70886075949367,\n",
       "    97.59493670886076,\n",
       "    97.0886075949367,\n",
       "    96.20253164556962,\n",
       "    97.21518987341773,\n",
       "    96.45569620253164,\n",
       "    98.10126582278481,\n",
       "    96.70886075949367,\n",
       "    98.60759493670886,\n",
       "    98.35443037974683,\n",
       "    98.48101265822785,\n",
       "    98.48101265822785,\n",
       "    98.60759493670886,\n",
       "    97.84810126582279,\n",
       "    98.22784810126582,\n",
       "    98.60759493670886,\n",
       "    98.86075949367088,\n",
       "    99.11392405063292,\n",
       "    98.73417721518987,\n",
       "    98.48101265822785,\n",
       "    98.48101265822785],\n",
       "   [9.746835443037975,\n",
       "    34.30379746835443,\n",
       "    54.050632911392405,\n",
       "    52.78481012658228,\n",
       "    78.86075949367088,\n",
       "    83.67088607594937,\n",
       "    84.81012658227849,\n",
       "    91.77215189873418,\n",
       "    89.74683544303798,\n",
       "    95.44303797468355,\n",
       "    92.9113924050633,\n",
       "    90.50632911392405,\n",
       "    90.75949367088607,\n",
       "    96.32911392405063,\n",
       "    93.16455696202532,\n",
       "    94.55696202531645,\n",
       "    95.44303797468355,\n",
       "    96.58227848101266,\n",
       "    94.68354430379746,\n",
       "    95.69620253164557,\n",
       "    96.32911392405063,\n",
       "    94.43037974683544,\n",
       "    92.27848101265823,\n",
       "    95.31645569620254,\n",
       "    97.59493670886076,\n",
       "    97.9746835443038,\n",
       "    98.73417721518987,\n",
       "    98.48101265822785,\n",
       "    97.84810126582279,\n",
       "    97.34177215189874,\n",
       "    98.48101265822785,\n",
       "    97.59493670886076,\n",
       "    98.35443037974683,\n",
       "    98.86075949367088,\n",
       "    98.35443037974683,\n",
       "    97.84810126582279,\n",
       "    98.10126582278481,\n",
       "    98.48101265822785,\n",
       "    98.86075949367088,\n",
       "    98.86075949367088,\n",
       "    98.86075949367088,\n",
       "    98.35443037974683,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    98.48101265822785,\n",
       "    98.60759493670886,\n",
       "    98.35443037974683,\n",
       "    98.86075949367088,\n",
       "    98.73417721518987,\n",
       "    98.73417721518987],\n",
       "   [25.569620253164558,\n",
       "    29.11392405063291,\n",
       "    58.9873417721519,\n",
       "    70.25316455696202,\n",
       "    74.43037974683544,\n",
       "    87.34177215189874,\n",
       "    83.92405063291139,\n",
       "    87.21518987341773,\n",
       "    90.37974683544304,\n",
       "    82.65822784810126,\n",
       "    93.29113924050633,\n",
       "    93.92405063291139,\n",
       "    95.31645569620254,\n",
       "    94.9367088607595,\n",
       "    94.17721518987342,\n",
       "    96.58227848101266,\n",
       "    95.9493670886076,\n",
       "    95.31645569620254,\n",
       "    97.46835443037975,\n",
       "    95.9493670886076,\n",
       "    96.07594936708861,\n",
       "    96.20253164556962,\n",
       "    97.46835443037975,\n",
       "    97.0886075949367,\n",
       "    97.0886075949367,\n",
       "    97.72151898734177,\n",
       "    97.46835443037975,\n",
       "    97.46835443037975,\n",
       "    98.73417721518987,\n",
       "    98.10126582278481,\n",
       "    97.9746835443038,\n",
       "    97.34177215189874,\n",
       "    97.84810126582279,\n",
       "    97.84810126582279,\n",
       "    97.9746835443038,\n",
       "    97.9746835443038,\n",
       "    98.60759493670886,\n",
       "    98.48101265822785,\n",
       "    98.60759493670886,\n",
       "    97.9746835443038,\n",
       "    97.34177215189874,\n",
       "    98.10126582278481,\n",
       "    98.60759493670886,\n",
       "    98.48101265822785,\n",
       "    97.9746835443038,\n",
       "    98.10126582278481,\n",
       "    98.48101265822785,\n",
       "    98.10126582278481,\n",
       "    99.11392405063292,\n",
       "    98.86075949367088],\n",
       "   [29.49367088607595,\n",
       "    46.075949367088604,\n",
       "    46.962025316455694,\n",
       "    65.56962025316456,\n",
       "    79.87341772151899,\n",
       "    79.36708860759494,\n",
       "    87.84810126582279,\n",
       "    84.9367088607595,\n",
       "    92.40506329113924,\n",
       "    95.18987341772151,\n",
       "    96.58227848101266,\n",
       "    94.81012658227849,\n",
       "    89.62025316455696,\n",
       "    94.81012658227849,\n",
       "    94.9367088607595,\n",
       "    96.9620253164557,\n",
       "    97.21518987341773,\n",
       "    96.58227848101266,\n",
       "    97.21518987341773,\n",
       "    97.72151898734177,\n",
       "    96.9620253164557,\n",
       "    97.9746835443038,\n",
       "    97.46835443037975,\n",
       "    96.58227848101266,\n",
       "    98.10126582278481,\n",
       "    96.07594936708861,\n",
       "    97.9746835443038,\n",
       "    97.9746835443038,\n",
       "    98.22784810126582,\n",
       "    97.9746835443038,\n",
       "    96.45569620253164,\n",
       "    97.9746835443038,\n",
       "    98.35443037974683,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.9746835443038,\n",
       "    98.73417721518987,\n",
       "    98.22784810126582,\n",
       "    98.22784810126582,\n",
       "    99.11392405063292,\n",
       "    98.73417721518987,\n",
       "    97.72151898734177,\n",
       "    98.35443037974683,\n",
       "    98.9873417721519,\n",
       "    98.86075949367088,\n",
       "    98.9873417721519,\n",
       "    97.9746835443038,\n",
       "    97.9746835443038,\n",
       "    99.11392405063292,\n",
       "    98.73417721518987],\n",
       "   [24.17721518987342,\n",
       "    46.32911392405063,\n",
       "    52.78481012658228,\n",
       "    66.58227848101266,\n",
       "    71.51898734177215,\n",
       "    87.72151898734177,\n",
       "    77.46835443037975,\n",
       "    73.92405063291139,\n",
       "    80.88607594936708,\n",
       "    82.15189873417721,\n",
       "    81.26582278481013,\n",
       "    91.89873417721519,\n",
       "    95.0632911392405,\n",
       "    89.62025316455696,\n",
       "    91.77215189873418,\n",
       "    83.79746835443038,\n",
       "    95.18987341772151,\n",
       "    96.20253164556962,\n",
       "    87.84810126582279,\n",
       "    87.34177215189874,\n",
       "    88.86075949367088,\n",
       "    93.16455696202532,\n",
       "    98.22784810126582,\n",
       "    95.69620253164557,\n",
       "    97.9746835443038,\n",
       "    96.58227848101266,\n",
       "    95.31645569620254,\n",
       "    95.56962025316456,\n",
       "    95.31645569620254,\n",
       "    94.17721518987342,\n",
       "    98.60759493670886,\n",
       "    97.9746835443038,\n",
       "    97.9746835443038,\n",
       "    98.22784810126582,\n",
       "    98.35443037974683,\n",
       "    97.84810126582279,\n",
       "    96.45569620253164,\n",
       "    96.58227848101266,\n",
       "    97.46835443037975,\n",
       "    98.86075949367088,\n",
       "    98.48101265822785,\n",
       "    98.9873417721519,\n",
       "    98.9873417721519,\n",
       "    98.9873417721519,\n",
       "    97.84810126582279,\n",
       "    98.9873417721519,\n",
       "    98.73417721518987,\n",
       "    98.22784810126582,\n",
       "    98.22784810126582,\n",
       "    98.86075949367088]],\n",
       "  'test_loss': [[2.2340702213287353,\n",
       "    1.7367066890716554,\n",
       "    1.11532563457489,\n",
       "    1.044894538497925,\n",
       "    0.7277659789085388,\n",
       "    0.4966083714962006,\n",
       "    0.5457724585056305,\n",
       "    0.4521297664642334,\n",
       "    0.5658024255752564,\n",
       "    0.2715885384082794,\n",
       "    0.501042947101593,\n",
       "    0.1699995239198208,\n",
       "    0.15487634412050247,\n",
       "    0.14508936927318572,\n",
       "    0.1912731815993786,\n",
       "    0.2552728075385094,\n",
       "    0.16825402042865753,\n",
       "    0.11949486941695213,\n",
       "    0.16232608218789102,\n",
       "    0.09920315528810024,\n",
       "    0.09371126561909913,\n",
       "    0.09642192378044129,\n",
       "    0.09834149956479668,\n",
       "    0.0857654910877347,\n",
       "    0.09120454097390175,\n",
       "    0.14100061346888543,\n",
       "    0.07197936241403222,\n",
       "    0.08915206527113914,\n",
       "    0.09845343382954598,\n",
       "    0.11034574479609728,\n",
       "    0.08574262746870517,\n",
       "    0.08930677818506956,\n",
       "    0.11427944613918663,\n",
       "    0.08153542165979744,\n",
       "    0.11058335797190666,\n",
       "    0.06835290876030922,\n",
       "    0.08869734365046024,\n",
       "    0.07131027069538831,\n",
       "    0.06729165008813143,\n",
       "    0.06955218034088612,\n",
       "    0.05926512256488204,\n",
       "    0.058786885546520354,\n",
       "    0.08058545545786619,\n",
       "    0.07297539098411798,\n",
       "    0.06381746741123498,\n",
       "    0.05136152849849313,\n",
       "    0.05092166496925056,\n",
       "    0.049903216534294186,\n",
       "    0.06030881521999836,\n",
       "    0.04937469390910119],\n",
       "   [2.2731726104736327,\n",
       "    1.8318418422698974,\n",
       "    1.276389895439148,\n",
       "    1.3185135971069335,\n",
       "    0.771288727426529,\n",
       "    0.461045515704155,\n",
       "    0.42664359478950503,\n",
       "    0.283793390917778,\n",
       "    0.30919005942344663,\n",
       "    0.18314735510349273,\n",
       "    0.23465729651451112,\n",
       "    0.25892880215644837,\n",
       "    0.2787233204841614,\n",
       "    0.14166741077303888,\n",
       "    0.1966961553812027,\n",
       "    0.17620523756742476,\n",
       "    0.1437402503401041,\n",
       "    0.11234764827042817,\n",
       "    0.13552674044966698,\n",
       "    0.11610938414633275,\n",
       "    0.11589861637353897,\n",
       "    0.14872361468970777,\n",
       "    0.16540397680997848,\n",
       "    0.1261835020184517,\n",
       "    0.0869804836936295,\n",
       "    0.0857278492718935,\n",
       "    0.07150064678788186,\n",
       "    0.08001971830874681,\n",
       "    0.08164136286973954,\n",
       "    0.07811182011589408,\n",
       "    0.0641404395520687,\n",
       "    0.07769041888788343,\n",
       "    0.07286396567486227,\n",
       "    0.07712142891064286,\n",
       "    0.06032676606327295,\n",
       "    0.07189478007256984,\n",
       "    0.06324700156897306,\n",
       "    0.06844467836096883,\n",
       "    0.053925328488834204,\n",
       "    0.05203959621302783,\n",
       "    0.05629526070654392,\n",
       "    0.059551388539373876,\n",
       "    0.04721599243544042,\n",
       "    0.044030292744748296,\n",
       "    0.04458778268713504,\n",
       "    0.04903480136319995,\n",
       "    0.05425967108719051,\n",
       "    0.048138096283748745,\n",
       "    0.045498258911818266,\n",
       "    0.045457836908381434],\n",
       "   [2.2624216026306154,\n",
       "    2.0038908252716063,\n",
       "    1.3196831958770752,\n",
       "    0.8428445467948914,\n",
       "    0.7618626785278321,\n",
       "    0.3785880871295929,\n",
       "    0.4835725005626679,\n",
       "    0.33610703246593476,\n",
       "    0.2631518137574196,\n",
       "    0.4377717207431793,\n",
       "    0.21102124524116517,\n",
       "    0.16779685264825822,\n",
       "    0.1446903771162033,\n",
       "    0.18159177913665772,\n",
       "    0.15663703385591507,\n",
       "    0.13821118564009666,\n",
       "    0.11504313762784005,\n",
       "    0.11210770948529243,\n",
       "    0.1042479006677866,\n",
       "    0.1053179058611393,\n",
       "    0.11142553302645683,\n",
       "    0.09904461991339922,\n",
       "    0.10003261269927025,\n",
       "    0.08476025514155626,\n",
       "    0.08334950763955712,\n",
       "    0.07373651610650123,\n",
       "    0.08958560833930969,\n",
       "    0.07906456745639444,\n",
       "    0.06063619472384453,\n",
       "    0.0688000394180417,\n",
       "    0.07404110913574695,\n",
       "    0.08810959697663784,\n",
       "    0.0696924325555563,\n",
       "    0.056544780018180606,\n",
       "    0.05667968640476465,\n",
       "    0.056965847369655966,\n",
       "    0.0515373392239213,\n",
       "    0.05313366195559502,\n",
       "    0.05106506154388189,\n",
       "    0.0656421522974968,\n",
       "    0.07659923026561737,\n",
       "    0.08265541683286429,\n",
       "    0.04559840634353459,\n",
       "    0.04088510379372164,\n",
       "    0.07273518154546618,\n",
       "    0.056639637976884843,\n",
       "    0.04723656457178295,\n",
       "    0.06686548710465431,\n",
       "    0.04759836843088269,\n",
       "    0.039458872885629534],\n",
       "   [2.134629923248291,\n",
       "    1.7343824745178222,\n",
       "    1.5298963508605956,\n",
       "    1.1033219675064088,\n",
       "    0.6902147807121277,\n",
       "    0.610033226108551,\n",
       "    0.3850190405845642,\n",
       "    0.38693508987426756,\n",
       "    0.2496718598127365,\n",
       "    0.17135072546005248,\n",
       "    0.13901839590072632,\n",
       "    0.15709755612909793,\n",
       "    0.2833711747646332,\n",
       "    0.1498983350723982,\n",
       "    0.1468268879175186,\n",
       "    0.1156126627728343,\n",
       "    0.0912712073341012,\n",
       "    0.09830005087405443,\n",
       "    0.11250464570820332,\n",
       "    0.07879196466207504,\n",
       "    0.08710279399007559,\n",
       "    0.07600352419316769,\n",
       "    0.07369329246282577,\n",
       "    0.10790207974612713,\n",
       "    0.06284847208485007,\n",
       "    0.12119701514989138,\n",
       "    0.07060756884664297,\n",
       "    0.06475575205609202,\n",
       "    0.06882982546258717,\n",
       "    0.06196554470956325,\n",
       "    0.0959176486492157,\n",
       "    0.06069815569594503,\n",
       "    0.0575778966024518,\n",
       "    0.06890318118333817,\n",
       "    0.06160913344621658,\n",
       "    0.05149554789364338,\n",
       "    0.047498017827421427,\n",
       "    0.05383581715486944,\n",
       "    0.05461484064534307,\n",
       "    0.05004292180016637,\n",
       "    0.04524628012264147,\n",
       "    0.055941971728019416,\n",
       "    0.04903665831908584,\n",
       "    0.04452167200706899,\n",
       "    0.06252601205855608,\n",
       "    0.04661759646423161,\n",
       "    0.04626818079352379,\n",
       "    0.06972466026777402,\n",
       "    0.04500759295336902,\n",
       "    0.0479322840705514],\n",
       "   [2.2496021736145018,\n",
       "    1.5532638912200927,\n",
       "    1.4534250541687013,\n",
       "    0.8961083135604858,\n",
       "    0.7371360676765442,\n",
       "    0.40702897868156435,\n",
       "    0.6198112847328187,\n",
       "    0.632893632888794,\n",
       "    0.49927695078849793,\n",
       "    0.47703626189231874,\n",
       "    0.44677147784233096,\n",
       "    0.22372206158638,\n",
       "    0.15822309657931327,\n",
       "    0.2556209055185318,\n",
       "    0.22480326703190803,\n",
       "    0.43119189052581786,\n",
       "    0.14122383655905724,\n",
       "    0.1445195141673088,\n",
       "    0.24868127973079682,\n",
       "    0.36138201627731326,\n",
       "    0.29516731550693515,\n",
       "    0.16189756873846053,\n",
       "    0.08908734303563834,\n",
       "    0.12785548303872346,\n",
       "    0.08847958043813706,\n",
       "    0.1166177880167961,\n",
       "    0.13895618336200713,\n",
       "    0.12886680788993835,\n",
       "    0.13244936083555223,\n",
       "    0.15583817108869552,\n",
       "    0.06492492613568902,\n",
       "    0.09357447138428689,\n",
       "    0.0741070111244917,\n",
       "    0.07372299824655056,\n",
       "    0.06817232943549752,\n",
       "    0.06570098872184753,\n",
       "    0.09382275545597077,\n",
       "    0.10970478736460208,\n",
       "    0.09819054078757763,\n",
       "    0.049580473666638133,\n",
       "    0.06455976531542838,\n",
       "    0.05657872402798384,\n",
       "    0.0511008365765214,\n",
       "    0.06749126080572605,\n",
       "    0.07662396285831928,\n",
       "    0.06448225064873696,\n",
       "    0.06073031478375197,\n",
       "    0.07368938846737147,\n",
       "    0.07274128798022866,\n",
       "    0.056178908788785335]],\n",
       "  'train_loss': [[0.13664727986924124,\n",
       "    0.08080894718235171,\n",
       "    0.038386260113723106,\n",
       "    0.030147018605264107,\n",
       "    0.029643770128522057,\n",
       "    0.022809770017346645,\n",
       "    0.024988093602243043,\n",
       "    0.012726519510201798,\n",
       "    0.028998860204315975,\n",
       "    0.023860506398622847,\n",
       "    0.011985415733786819,\n",
       "    0.014610377644761327,\n",
       "    0.013065651031105236,\n",
       "    0.01859206522945782,\n",
       "    0.008937873127519471,\n",
       "    0.016225825241961523,\n",
       "    0.016603292150594997,\n",
       "    0.011117765510104387,\n",
       "    0.010375913691730746,\n",
       "    0.0104323952361192,\n",
       "    0.007622343040629931,\n",
       "    0.007396282929114599,\n",
       "    0.013280106329414853,\n",
       "    0.009863464817713977,\n",
       "    0.013837633749734476,\n",
       "    0.009424905099233633,\n",
       "    0.0036557087982786963,\n",
       "    0.012577875028471413,\n",
       "    0.007471674467974749,\n",
       "    0.006068308999634736,\n",
       "    0.007224092265504284,\n",
       "    0.008661264592736322,\n",
       "    0.0038404418966510173,\n",
       "    0.009783824721339537,\n",
       "    0.01111443441096315,\n",
       "    0.009392665351079927,\n",
       "    0.01697074820487872,\n",
       "    0.006981689381426107,\n",
       "    0.010522422306097116,\n",
       "    0.012465453940120722,\n",
       "    0.007880895586046644,\n",
       "    0.007698066143196011,\n",
       "    0.0039884917028585425,\n",
       "    0.01290308901463516,\n",
       "    0.008146496383544042,\n",
       "    0.006860866250111368,\n",
       "    0.006148217416440574,\n",
       "    0.0037839062001577286,\n",
       "    0.00671598718445434,\n",
       "    0.005189226094402794],\n",
       "   [0.11891510069440783,\n",
       "    0.09597674703185671,\n",
       "    0.03421450175251802,\n",
       "    0.030570702374265884,\n",
       "    0.039488557859059026,\n",
       "    0.014998021978774275,\n",
       "    0.02404604486760383,\n",
       "    0.022206177405549594,\n",
       "    0.02732883002444126,\n",
       "    0.020264221934196486,\n",
       "    0.022949819847175926,\n",
       "    0.009034664868822533,\n",
       "    0.016652770197412178,\n",
       "    0.019262167208107944,\n",
       "    0.023010529382231464,\n",
       "    0.012334221455080124,\n",
       "    0.011558662289780978,\n",
       "    0.01576052122200559,\n",
       "    0.008434639569911185,\n",
       "    0.008969535164326338,\n",
       "    0.00832826208775873,\n",
       "    0.013704083040784026,\n",
       "    0.013009864837545043,\n",
       "    0.011506604879030546,\n",
       "    0.012695344002475439,\n",
       "    0.009119826626634596,\n",
       "    0.012565648397591814,\n",
       "    0.008216911017503348,\n",
       "    0.007769370586096761,\n",
       "    0.007657901621702173,\n",
       "    0.013925078842844194,\n",
       "    0.00856620633485088,\n",
       "    0.00930019446805413,\n",
       "    0.00924556292566757,\n",
       "    0.00846505820156514,\n",
       "    0.004381133910155037,\n",
       "    0.010580634473211479,\n",
       "    0.009440863201512115,\n",
       "    0.008760627833735827,\n",
       "    0.00682003287915781,\n",
       "    0.007814140035229589,\n",
       "    0.006296475281632387,\n",
       "    0.006648893590567755,\n",
       "    0.005803036961001517,\n",
       "    0.005704657714481236,\n",
       "    0.010619508845141002,\n",
       "    0.007916018459402176,\n",
       "    0.00803803141335952,\n",
       "    0.008869230500380585,\n",
       "    0.003602706991160417],\n",
       "   [0.11494583847930664,\n",
       "    0.06893311622730255,\n",
       "    0.048471961754705785,\n",
       "    0.033815112451012,\n",
       "    0.025956172019644876,\n",
       "    0.0168505600727586,\n",
       "    0.02527603569455067,\n",
       "    0.010582446818968621,\n",
       "    0.01688397063890661,\n",
       "    0.012702290189100452,\n",
       "    0.023293250402179718,\n",
       "    0.012200381964006513,\n",
       "    0.011834076164804,\n",
       "    0.025918297139138215,\n",
       "    0.009916440927150744,\n",
       "    0.01469628701241009,\n",
       "    0.013283760609532434,\n",
       "    0.01662382489342603,\n",
       "    0.011954838174006513,\n",
       "    0.014001374769322042,\n",
       "    0.00977384419670139,\n",
       "    0.009996031442031029,\n",
       "    0.011136380995596948,\n",
       "    0.008047095292522963,\n",
       "    0.01170213399464488,\n",
       "    0.00928611141169194,\n",
       "    0.00445325494819887,\n",
       "    0.012766433068245509,\n",
       "    0.009222667010579451,\n",
       "    0.006649807987263515,\n",
       "    0.011929901098649748,\n",
       "    0.008004639352493336,\n",
       "    0.007169751192247838,\n",
       "    0.007079652185842794,\n",
       "    0.010309124191424648,\n",
       "    0.007622073014111592,\n",
       "    0.006442024248894604,\n",
       "    0.005596589528209784,\n",
       "    0.007811249432369593,\n",
       "    0.004786364800688705,\n",
       "    0.0043193000545667755,\n",
       "    0.006275579216004706,\n",
       "    0.005914318069202231,\n",
       "    0.004382752964678134,\n",
       "    0.0055896990625189475,\n",
       "    0.008204233154653566,\n",
       "    0.008054829890128807,\n",
       "    0.0039322197910446445,\n",
       "    0.008927220274912702,\n",
       "    0.007311824568718711],\n",
       "   [0.09301926932998418,\n",
       "    0.08509126305021222,\n",
       "    0.04034186752552846,\n",
       "    0.036626018650394956,\n",
       "    0.022189979289100478,\n",
       "    0.0176001053700916,\n",
       "    0.023136442263589064,\n",
       "    0.020430632072856603,\n",
       "    0.020884299161638163,\n",
       "    0.011752154649275297,\n",
       "    0.012582862456020541,\n",
       "    0.011139082976612208,\n",
       "    0.02337762386294371,\n",
       "    0.010106422136425916,\n",
       "    0.0059392377539434745,\n",
       "    0.01392795710886142,\n",
       "    0.014869511366664279,\n",
       "    0.01299510658769969,\n",
       "    0.008708174640661478,\n",
       "    0.006595651935748329,\n",
       "    0.00933049098610568,\n",
       "    0.009924516716905685,\n",
       "    0.011595553183624244,\n",
       "    0.009467387002217342,\n",
       "    0.006844309269933045,\n",
       "    0.004185504552904288,\n",
       "    0.011898854861499802,\n",
       "    0.0107814063460225,\n",
       "    0.00587017837696866,\n",
       "    0.005721350012678787,\n",
       "    0.012620267691987486,\n",
       "    0.0070264531460694805,\n",
       "    0.008201590246598285,\n",
       "    0.010224151188261543,\n",
       "    0.006566740262111298,\n",
       "    0.005230245977284669,\n",
       "    0.004245222274029845,\n",
       "    0.004177047856210794,\n",
       "    0.007802758689442861,\n",
       "    0.003260820725650941,\n",
       "    0.005528460559391965,\n",
       "    0.003729150734984197,\n",
       "    0.004046411130419662,\n",
       "    0.006075082073492751,\n",
       "    0.006849086424781213,\n",
       "    0.004564964290347895,\n",
       "    0.007845943861479644,\n",
       "    0.007068138988920833,\n",
       "    0.008155053571349663,\n",
       "    0.013880454482871892],\n",
       "   [0.12336778992573785,\n",
       "    0.06182322709469305,\n",
       "    0.05211449942614167,\n",
       "    0.02744176929980104,\n",
       "    0.018646676961895623,\n",
       "    0.021554202008189007,\n",
       "    0.017183406211944745,\n",
       "    0.020966231813050434,\n",
       "    0.01755132087687089,\n",
       "    0.02013777934105556,\n",
       "    0.014846374655558974,\n",
       "    0.0147251259987176,\n",
       "    0.010303405488659165,\n",
       "    0.011866980042201063,\n",
       "    0.008860057475797867,\n",
       "    0.015299988474419629,\n",
       "    0.021448277832813036,\n",
       "    0.0070365573410210245,\n",
       "    0.014890391155383176,\n",
       "    0.01316643565309338,\n",
       "    0.011207245530239688,\n",
       "    0.009123810768729475,\n",
       "    0.010085321247200985,\n",
       "    0.010380175635411614,\n",
       "    0.007933526914991888,\n",
       "    0.007425740090500663,\n",
       "    0.012666886375288533,\n",
       "    0.005751001395359945,\n",
       "    0.009507391855800474,\n",
       "    0.008719855419711788,\n",
       "    0.006422047286967626,\n",
       "    0.009170953703574281,\n",
       "    0.007714884196192723,\n",
       "    0.009435301627327529,\n",
       "    0.004581126552526274,\n",
       "    0.01180468850985958,\n",
       "    0.01263739728394212,\n",
       "    0.007923338787732317,\n",
       "    0.00602928300793428,\n",
       "    0.005333993305243812,\n",
       "    0.005718152250717613,\n",
       "    0.004447661063236012,\n",
       "    0.006943516351065898,\n",
       "    0.006551154105641587,\n",
       "    0.00913180324792682,\n",
       "    0.008340481406527872,\n",
       "    0.007961534062906282,\n",
       "    0.004984609770690337,\n",
       "    0.005963042606158838,\n",
       "    0.005549631931441771]]},\n",
       " 'MNIST MLP on IID': {'hyperparams': {'C': 0.1,\n",
       "   'E': 5,\n",
       "   'K': 100,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.05,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[91.13924050632912,\n",
       "    94.0506329113924,\n",
       "    94.17721518987342,\n",
       "    94.9367088607595,\n",
       "    95.44303797468355,\n",
       "    95.9493670886076,\n",
       "    96.07594936708861,\n",
       "    96.45569620253164,\n",
       "    96.32911392405063,\n",
       "    96.70886075949367,\n",
       "    96.58227848101266,\n",
       "    96.45569620253164,\n",
       "    96.58227848101266,\n",
       "    96.83544303797468,\n",
       "    97.0886075949367,\n",
       "    96.83544303797468,\n",
       "    96.9620253164557,\n",
       "    96.83544303797468,\n",
       "    96.83544303797468,\n",
       "    96.9620253164557,\n",
       "    97.34177215189874,\n",
       "    97.34177215189874,\n",
       "    96.9620253164557,\n",
       "    97.46835443037975,\n",
       "    96.9620253164557,\n",
       "    97.34177215189874,\n",
       "    97.59493670886076,\n",
       "    97.0886075949367,\n",
       "    97.46835443037975,\n",
       "    97.46835443037975,\n",
       "    97.72151898734177,\n",
       "    97.59493670886076,\n",
       "    97.84810126582279,\n",
       "    97.9746835443038,\n",
       "    97.46835443037975,\n",
       "    97.84810126582279,\n",
       "    97.84810126582279,\n",
       "    98.10126582278481,\n",
       "    97.9746835443038,\n",
       "    98.10126582278481,\n",
       "    97.84810126582279,\n",
       "    98.22784810126582,\n",
       "    98.10126582278481,\n",
       "    97.9746835443038,\n",
       "    97.72151898734177,\n",
       "    97.9746835443038,\n",
       "    97.84810126582279,\n",
       "    97.46835443037975,\n",
       "    97.46835443037975,\n",
       "    97.9746835443038],\n",
       "   [90.37974683544304,\n",
       "    94.30379746835443,\n",
       "    94.55696202531645,\n",
       "    94.9367088607595,\n",
       "    95.44303797468355,\n",
       "    95.44303797468355,\n",
       "    96.07594936708861,\n",
       "    96.20253164556962,\n",
       "    96.70886075949367,\n",
       "    96.07594936708861,\n",
       "    96.58227848101266,\n",
       "    97.0886075949367,\n",
       "    96.9620253164557,\n",
       "    97.21518987341773,\n",
       "    97.34177215189874,\n",
       "    97.21518987341773,\n",
       "    96.9620253164557,\n",
       "    96.9620253164557,\n",
       "    97.0886075949367,\n",
       "    96.9620253164557,\n",
       "    96.9620253164557,\n",
       "    96.9620253164557,\n",
       "    96.70886075949367,\n",
       "    96.9620253164557,\n",
       "    97.34177215189874,\n",
       "    97.21518987341773,\n",
       "    97.21518987341773,\n",
       "    97.0886075949367,\n",
       "    97.46835443037975,\n",
       "    96.9620253164557,\n",
       "    97.72151898734177,\n",
       "    97.34177215189874,\n",
       "    97.21518987341773,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.84810126582279,\n",
       "    97.59493670886076,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.59493670886076,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    98.22784810126582],\n",
       "   [91.89873417721519,\n",
       "    93.92405063291139,\n",
       "    94.0506329113924,\n",
       "    94.0506329113924,\n",
       "    94.81012658227849,\n",
       "    95.0632911392405,\n",
       "    95.44303797468355,\n",
       "    96.07594936708861,\n",
       "    96.32911392405063,\n",
       "    96.70886075949367,\n",
       "    96.58227848101266,\n",
       "    96.83544303797468,\n",
       "    96.20253164556962,\n",
       "    96.45569620253164,\n",
       "    96.20253164556962,\n",
       "    96.58227848101266,\n",
       "    96.58227848101266,\n",
       "    97.0886075949367,\n",
       "    96.9620253164557,\n",
       "    97.21518987341773,\n",
       "    96.83544303797468,\n",
       "    96.83544303797468,\n",
       "    96.70886075949367,\n",
       "    96.70886075949367,\n",
       "    96.70886075949367,\n",
       "    96.9620253164557,\n",
       "    97.0886075949367,\n",
       "    97.34177215189874,\n",
       "    96.83544303797468,\n",
       "    97.21518987341773,\n",
       "    97.21518987341773,\n",
       "    97.34177215189874,\n",
       "    97.34177215189874,\n",
       "    97.46835443037975,\n",
       "    97.59493670886076,\n",
       "    97.34177215189874,\n",
       "    97.34177215189874,\n",
       "    97.46835443037975,\n",
       "    97.46835443037975,\n",
       "    97.59493670886076,\n",
       "    97.84810126582279,\n",
       "    97.84810126582279,\n",
       "    97.59493670886076,\n",
       "    98.35443037974683,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    98.10126582278481,\n",
       "    98.22784810126582],\n",
       "   [91.39240506329114,\n",
       "    93.41772151898734,\n",
       "    94.43037974683544,\n",
       "    94.55696202531645,\n",
       "    95.18987341772151,\n",
       "    95.56962025316456,\n",
       "    96.07594936708861,\n",
       "    95.56962025316456,\n",
       "    96.45569620253164,\n",
       "    96.58227848101266,\n",
       "    96.45569620253164,\n",
       "    96.45569620253164,\n",
       "    96.32911392405063,\n",
       "    96.07594936708861,\n",
       "    96.70886075949367,\n",
       "    96.70886075949367,\n",
       "    96.83544303797468,\n",
       "    96.9620253164557,\n",
       "    96.70886075949367,\n",
       "    97.0886075949367,\n",
       "    97.0886075949367,\n",
       "    97.21518987341773,\n",
       "    97.21518987341773,\n",
       "    96.58227848101266,\n",
       "    96.83544303797468,\n",
       "    97.59493670886076,\n",
       "    97.21518987341773,\n",
       "    97.59493670886076,\n",
       "    97.21518987341773,\n",
       "    97.46835443037975,\n",
       "    97.46835443037975,\n",
       "    97.0886075949367,\n",
       "    97.46835443037975,\n",
       "    97.34177215189874,\n",
       "    97.59493670886076,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177,\n",
       "    97.9746835443038,\n",
       "    98.10126582278481,\n",
       "    97.9746835443038,\n",
       "    97.84810126582279,\n",
       "    97.84810126582279,\n",
       "    97.59493670886076,\n",
       "    98.10126582278481,\n",
       "    98.10126582278481,\n",
       "    97.84810126582279,\n",
       "    97.9746835443038,\n",
       "    98.10126582278481,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177],\n",
       "   [91.13924050632912,\n",
       "    93.79746835443038,\n",
       "    94.9367088607595,\n",
       "    94.55696202531645,\n",
       "    95.31645569620254,\n",
       "    95.9493670886076,\n",
       "    96.45569620253164,\n",
       "    95.56962025316456,\n",
       "    95.56962025316456,\n",
       "    95.9493670886076,\n",
       "    96.32911392405063,\n",
       "    96.32911392405063,\n",
       "    96.20253164556962,\n",
       "    96.07594936708861,\n",
       "    96.20253164556962,\n",
       "    96.45569620253164,\n",
       "    96.20253164556962,\n",
       "    96.70886075949367,\n",
       "    96.83544303797468,\n",
       "    96.58227848101266,\n",
       "    96.70886075949367,\n",
       "    97.0886075949367,\n",
       "    97.34177215189874,\n",
       "    96.9620253164557,\n",
       "    96.70886075949367,\n",
       "    97.0886075949367,\n",
       "    97.21518987341773,\n",
       "    97.0886075949367,\n",
       "    96.83544303797468,\n",
       "    96.58227848101266,\n",
       "    96.9620253164557,\n",
       "    96.45569620253164,\n",
       "    96.83544303797468,\n",
       "    96.9620253164557,\n",
       "    97.0886075949367,\n",
       "    97.34177215189874,\n",
       "    97.46835443037975,\n",
       "    97.9746835443038,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.9746835443038,\n",
       "    97.46835443037975,\n",
       "    97.59493670886076,\n",
       "    97.59493670886076,\n",
       "    97.72151898734177,\n",
       "    98.10126582278481,\n",
       "    98.10126582278481,\n",
       "    98.22784810126582,\n",
       "    97.72151898734177,\n",
       "    97.9746835443038]],\n",
       "  'test_loss': [[0.32695179480314257,\n",
       "    0.2627036438420415,\n",
       "    0.23278263702243568,\n",
       "    0.20870386507734656,\n",
       "    0.18256138154715298,\n",
       "    0.16817079727947712,\n",
       "    0.15944039705470203,\n",
       "    0.15049266472794115,\n",
       "    0.1413922214370221,\n",
       "    0.13283793104216457,\n",
       "    0.12554054680243135,\n",
       "    0.12105959919542074,\n",
       "    0.11877555260639638,\n",
       "    0.11656918613323942,\n",
       "    0.10844689946062863,\n",
       "    0.10578176012244075,\n",
       "    0.10129761406499893,\n",
       "    0.10178731720568612,\n",
       "    0.1040601049120538,\n",
       "    0.10115180535819382,\n",
       "    0.1019461857803166,\n",
       "    0.09694707368463278,\n",
       "    0.09263977284147404,\n",
       "    0.09418585818689316,\n",
       "    0.09476665601581336,\n",
       "    0.09555001732474193,\n",
       "    0.09156859938427805,\n",
       "    0.0895300798498094,\n",
       "    0.0899554453542456,\n",
       "    0.08757753989063204,\n",
       "    0.08764875519541092,\n",
       "    0.08748391731313895,\n",
       "    0.08484803285032977,\n",
       "    0.08581344573061214,\n",
       "    0.0873068411600194,\n",
       "    0.08464419137518853,\n",
       "    0.08508283917579101,\n",
       "    0.08338086126220878,\n",
       "    0.08405483856289647,\n",
       "    0.0824818543252768,\n",
       "    0.08197380741683301,\n",
       "    0.08054053548311349,\n",
       "    0.08214089886874426,\n",
       "    0.08082892833938822,\n",
       "    0.08180667085042223,\n",
       "    0.0815987515203422,\n",
       "    0.08185479684502352,\n",
       "    0.08152290118811652,\n",
       "    0.0811355340690352,\n",
       "    0.08037458234517834],\n",
       "   [0.3399472411990166,\n",
       "    0.2580495035916567,\n",
       "    0.22558653295338155,\n",
       "    0.19519039390571416,\n",
       "    0.18269702130369841,\n",
       "    0.17212210837602615,\n",
       "    0.15552488613277674,\n",
       "    0.1446004368353635,\n",
       "    0.13891625725030898,\n",
       "    0.1324643986158073,\n",
       "    0.12746725707389414,\n",
       "    0.12217093525454402,\n",
       "    0.11569033893533051,\n",
       "    0.11489698203597218,\n",
       "    0.11195196844302117,\n",
       "    0.1097883888467215,\n",
       "    0.11002612150777132,\n",
       "    0.1093199175324291,\n",
       "    0.10265087872780859,\n",
       "    0.10160911175543443,\n",
       "    0.09883699012203143,\n",
       "    0.0976749746888876,\n",
       "    0.09555940724294633,\n",
       "    0.09892216326035559,\n",
       "    0.09373329845792613,\n",
       "    0.09372408153777942,\n",
       "    0.09074923090552911,\n",
       "    0.0923091871412471,\n",
       "    0.08832344984640367,\n",
       "    0.0890881979512982,\n",
       "    0.08677551260283217,\n",
       "    0.08666627538464963,\n",
       "    0.08423186377463862,\n",
       "    0.08513711871085688,\n",
       "    0.08659489417127333,\n",
       "    0.0858188842558302,\n",
       "    0.08879022041438148,\n",
       "    0.08956377195038367,\n",
       "    0.08697396720889956,\n",
       "    0.08407225609584712,\n",
       "    0.0840620133254677,\n",
       "    0.08424677460605744,\n",
       "    0.08480936789177358,\n",
       "    0.08463212226140313,\n",
       "    0.08352143052159809,\n",
       "    0.083581700961967,\n",
       "    0.0830526816778467,\n",
       "    0.08362558957426809,\n",
       "    0.08386846461528912,\n",
       "    0.08345312873837538],\n",
       "   [0.32818145956397055,\n",
       "    0.26694679360687734,\n",
       "    0.23289123625606298,\n",
       "    0.21218837622851133,\n",
       "    0.18670739186555146,\n",
       "    0.17019125839173793,\n",
       "    0.15956013278849424,\n",
       "    0.15426601202748716,\n",
       "    0.14245585862044244,\n",
       "    0.13406336150038986,\n",
       "    0.12778562813177705,\n",
       "    0.12707770732287318,\n",
       "    0.12289274396430701,\n",
       "    0.11886949912980199,\n",
       "    0.11395763576924801,\n",
       "    0.11105036564730107,\n",
       "    0.1104099426060915,\n",
       "    0.10558587476350367,\n",
       "    0.10319584467690437,\n",
       "    0.10496230826228857,\n",
       "    0.09993896086718887,\n",
       "    0.10270304430024699,\n",
       "    0.09980271467752755,\n",
       "    0.09984684536233544,\n",
       "    0.10159239960918202,\n",
       "    0.09724841461954638,\n",
       "    0.09716068299543112,\n",
       "    0.09932683575600386,\n",
       "    0.0942337376552634,\n",
       "    0.09196275041494519,\n",
       "    0.09083899509292095,\n",
       "    0.09102179233785719,\n",
       "    0.08726688888650387,\n",
       "    0.08924311621552333,\n",
       "    0.0864497033356689,\n",
       "    0.0850767615751829,\n",
       "    0.08726437862259336,\n",
       "    0.08763842713651247,\n",
       "    0.08602194134443998,\n",
       "    0.08852313566789963,\n",
       "    0.08495941917365417,\n",
       "    0.08460512143862434,\n",
       "    0.08584558219853788,\n",
       "    0.0837489549134858,\n",
       "    0.08331274789758027,\n",
       "    0.08374776350734756,\n",
       "    0.08313727648747153,\n",
       "    0.08217924690863583,\n",
       "    0.08222522465470247,\n",
       "    0.07941968833175488],\n",
       "   [0.3269356367826462,\n",
       "    0.2726376818060875,\n",
       "    0.23294710158705711,\n",
       "    0.20299666959792376,\n",
       "    0.18446063401699067,\n",
       "    0.16540050012543797,\n",
       "    0.15378907231017946,\n",
       "    0.1464770152181387,\n",
       "    0.1431370378062129,\n",
       "    0.13410811374932527,\n",
       "    0.12920393440052866,\n",
       "    0.12237183896154165,\n",
       "    0.12126891714930535,\n",
       "    0.11590885205417871,\n",
       "    0.11084593054652214,\n",
       "    0.11038372616581618,\n",
       "    0.1103985718101263,\n",
       "    0.10947245691791177,\n",
       "    0.10181016323920339,\n",
       "    0.09703265317007899,\n",
       "    0.09635872254297137,\n",
       "    0.09870431356802582,\n",
       "    0.09597330644596368,\n",
       "    0.09239617664255202,\n",
       "    0.09098679752275347,\n",
       "    0.0909940440043807,\n",
       "    0.09000045643672347,\n",
       "    0.08776747083626688,\n",
       "    0.08655751819554716,\n",
       "    0.08734223769176751,\n",
       "    0.08405080491639674,\n",
       "    0.08348032789980062,\n",
       "    0.08356981900297106,\n",
       "    0.08242682223394514,\n",
       "    0.08203012591041625,\n",
       "    0.08223665841761976,\n",
       "    0.08213552728174255,\n",
       "    0.08173799300938844,\n",
       "    0.08015610091499985,\n",
       "    0.0782394313789904,\n",
       "    0.07872700283955783,\n",
       "    0.07900577075826004,\n",
       "    0.076464962222334,\n",
       "    0.0760327255552169,\n",
       "    0.07569710960122757,\n",
       "    0.07500281858900562,\n",
       "    0.07551298508970067,\n",
       "    0.07354403475439177,\n",
       "    0.07349136548303067,\n",
       "    0.07535420569595881],\n",
       "   [0.31400266654491427,\n",
       "    0.2531124589383602,\n",
       "    0.2202119962453842,\n",
       "    0.2012913445800543,\n",
       "    0.1783110019017011,\n",
       "    0.1633708765298128,\n",
       "    0.15097207431718707,\n",
       "    0.15067482268810273,\n",
       "    0.14081047755777837,\n",
       "    0.13677981583159418,\n",
       "    0.13122348809037357,\n",
       "    0.12394388317232952,\n",
       "    0.12076255412567406,\n",
       "    0.11654148453772067,\n",
       "    0.11168692648299039,\n",
       "    0.10999328988632187,\n",
       "    0.11065595110896975,\n",
       "    0.10735933367814869,\n",
       "    0.10213825915344059,\n",
       "    0.10082909695589914,\n",
       "    0.10229949931502343,\n",
       "    0.10088135752622038,\n",
       "    0.09892094335537403,\n",
       "    0.10199306722441688,\n",
       "    0.097982237128634,\n",
       "    0.09605854378454387,\n",
       "    0.09493875926658511,\n",
       "    0.09630838439520449,\n",
       "    0.09520691945243161,\n",
       "    0.09524611084391363,\n",
       "    0.09354502556091175,\n",
       "    0.09478462526439689,\n",
       "    0.09150387097280473,\n",
       "    0.08994855650039389,\n",
       "    0.08753259653262795,\n",
       "    0.08794080454842187,\n",
       "    0.08706068495970685,\n",
       "    0.08556817903716583,\n",
       "    0.08502958418447525,\n",
       "    0.08490082709663548,\n",
       "    0.0832291793368291,\n",
       "    0.08357088322036434,\n",
       "    0.08504044339542743,\n",
       "    0.08471284644310363,\n",
       "    0.08300199667313136,\n",
       "    0.08426466191103682,\n",
       "    0.08248457438395126,\n",
       "    0.08182250385521911,\n",
       "    0.08347391076355706,\n",
       "    0.08345838831065922]],\n",
       "  'train_loss': [[0.5972959178858825,\n",
       "    0.17383920097028993,\n",
       "    0.12512593637781783,\n",
       "    0.09545114415109857,\n",
       "    0.0869817014461587,\n",
       "    0.08432215792174491,\n",
       "    0.06965374291155482,\n",
       "    0.06548404818840209,\n",
       "    0.06013423302780696,\n",
       "    0.05499340132545331,\n",
       "    0.06173530639979434,\n",
       "    0.04706223117679898,\n",
       "    0.044128261299894805,\n",
       "    0.0433009782266851,\n",
       "    0.0619754678720583,\n",
       "    0.050847701543144164,\n",
       "    0.040925350707743745,\n",
       "    0.03407344454219674,\n",
       "    0.035815953704010396,\n",
       "    0.04115158187416531,\n",
       "    0.03212357923461726,\n",
       "    0.032729516286651536,\n",
       "    0.036436510191225804,\n",
       "    0.028362269562755577,\n",
       "    0.031266067946971204,\n",
       "    0.029945848926076147,\n",
       "    0.031236697755889435,\n",
       "    0.02849023349271465,\n",
       "    0.0270455365965419,\n",
       "    0.023839469104281686,\n",
       "    0.023712498908502917,\n",
       "    0.02811718311663806,\n",
       "    0.025879463497135175,\n",
       "    0.02123130883628877,\n",
       "    0.027091206337884838,\n",
       "    0.02357728135648381,\n",
       "    0.021612798098940022,\n",
       "    0.02180270885102057,\n",
       "    0.019023865782216792,\n",
       "    0.02208998970255614,\n",
       "    0.02621190633947117,\n",
       "    0.026820127370994668,\n",
       "    0.019972071531809053,\n",
       "    0.018266549754737637,\n",
       "    0.019606894497433133,\n",
       "    0.016984617196325037,\n",
       "    0.02109783291587602,\n",
       "    0.019590000545652325,\n",
       "    0.019991719950267266,\n",
       "    0.015948113920735748],\n",
       "   [0.5567540619955398,\n",
       "    0.1631274384731563,\n",
       "    0.13458514140310823,\n",
       "    0.09358249242007878,\n",
       "    0.08999026054301554,\n",
       "    0.07932880231784659,\n",
       "    0.07355598840550373,\n",
       "    0.06971180738069234,\n",
       "    0.06178309261030397,\n",
       "    0.05947136023238757,\n",
       "    0.05456847124856844,\n",
       "    0.050513185495662284,\n",
       "    0.05063062683312455,\n",
       "    0.04301891061418822,\n",
       "    0.04452122378098405,\n",
       "    0.04242912117436451,\n",
       "    0.03541221721775083,\n",
       "    0.04290749281274111,\n",
       "    0.03643945025536141,\n",
       "    0.04059848409218966,\n",
       "    0.039103572140186164,\n",
       "    0.03917885000161672,\n",
       "    0.03595631379295386,\n",
       "    0.03293423856260354,\n",
       "    0.030774729576744448,\n",
       "    0.03437023876069421,\n",
       "    0.035905383913118386,\n",
       "    0.026335570488494643,\n",
       "    0.028970642315259816,\n",
       "    0.025816879147597928,\n",
       "    0.030472551954177106,\n",
       "    0.022761675525808794,\n",
       "    0.02984504293690134,\n",
       "    0.02418511261089058,\n",
       "    0.028537046508123543,\n",
       "    0.02461923178925402,\n",
       "    0.01665468019496071,\n",
       "    0.022722020208629904,\n",
       "    0.02356997326726946,\n",
       "    0.020804646740591355,\n",
       "    0.01776551458056201,\n",
       "    0.019385487615884964,\n",
       "    0.017557290006933346,\n",
       "    0.021244665590506133,\n",
       "    0.019097154024476367,\n",
       "    0.014278737249804788,\n",
       "    0.012055057967529896,\n",
       "    0.018295114345543727,\n",
       "    0.017760239599699128,\n",
       "    0.02035344371044493],\n",
       "   [0.46867349289070503,\n",
       "    0.16064302204817069,\n",
       "    0.12068129364675165,\n",
       "    0.09507736326925563,\n",
       "    0.09228018764227454,\n",
       "    0.0678458938723925,\n",
       "    0.07819085032801862,\n",
       "    0.06454015722934611,\n",
       "    0.06677166070321984,\n",
       "    0.061905079771830664,\n",
       "    0.05886656239293432,\n",
       "    0.046154275833455057,\n",
       "    0.0450067549052122,\n",
       "    0.04095713178956794,\n",
       "    0.05570960083712574,\n",
       "    0.0412453225037704,\n",
       "    0.03400701623401922,\n",
       "    0.03831838503155753,\n",
       "    0.04208040753655526,\n",
       "    0.03392236437097532,\n",
       "    0.04364527524159712,\n",
       "    0.02401058756734104,\n",
       "    0.038131386509510784,\n",
       "    0.03362421006505883,\n",
       "    0.030670907617728053,\n",
       "    0.03192096520507251,\n",
       "    0.025578585962871336,\n",
       "    0.027151599373725428,\n",
       "    0.03095208326259156,\n",
       "    0.03130480227746106,\n",
       "    0.028118571149876516,\n",
       "    0.01968795005852796,\n",
       "    0.025793721678701025,\n",
       "    0.02282938082374479,\n",
       "    0.023427627552564143,\n",
       "    0.02358179044998133,\n",
       "    0.02045392500025969,\n",
       "    0.025952143890281602,\n",
       "    0.027582966889182974,\n",
       "    0.023962671017440852,\n",
       "    0.024981589813919847,\n",
       "    0.01518987540047457,\n",
       "    0.019871770115054158,\n",
       "    0.01920719749703274,\n",
       "    0.019016766776797037,\n",
       "    0.017578346061019146,\n",
       "    0.017515099450796736,\n",
       "    0.023836367163749324,\n",
       "    0.017551318917300746,\n",
       "    0.01733563520690988],\n",
       "   [0.5382320315544494,\n",
       "    0.1620457342826024,\n",
       "    0.1289327589911991,\n",
       "    0.10009711650159685,\n",
       "    0.09196698291687304,\n",
       "    0.07596784255294671,\n",
       "    0.07476418294757604,\n",
       "    0.06623408207940033,\n",
       "    0.05037477436543243,\n",
       "    0.06084968788044959,\n",
       "    0.050588785879030186,\n",
       "    0.05110161811352615,\n",
       "    0.04630940404650573,\n",
       "    0.0493836420624563,\n",
       "    0.04666991282856665,\n",
       "    0.04145872303748896,\n",
       "    0.03214542487942405,\n",
       "    0.03830836648463113,\n",
       "    0.041553184325978834,\n",
       "    0.04253862623908238,\n",
       "    0.03486561515681978,\n",
       "    0.031525330207387015,\n",
       "    0.029047724758693223,\n",
       "    0.029306940405827236,\n",
       "    0.03356717483915115,\n",
       "    0.025109514829958702,\n",
       "    0.028672181308289357,\n",
       "    0.02898202215968467,\n",
       "    0.028032228213901673,\n",
       "    0.022196111566320873,\n",
       "    0.030240464718131084,\n",
       "    0.03017548306724833,\n",
       "    0.026048766476199185,\n",
       "    0.028507689101338957,\n",
       "    0.024584609811036745,\n",
       "    0.028206293108248248,\n",
       "    0.020099905100290395,\n",
       "    0.02104934795719828,\n",
       "    0.02514833214790163,\n",
       "    0.021998704185819933,\n",
       "    0.022791383096642144,\n",
       "    0.027742225575677293,\n",
       "    0.023635409416599636,\n",
       "    0.02332447263491046,\n",
       "    0.023240161305785174,\n",
       "    0.022456131058198707,\n",
       "    0.01725533340439491,\n",
       "    0.018755446150875744,\n",
       "    0.01901084450610673,\n",
       "    0.017852629471376454],\n",
       "   [0.5534542021461724,\n",
       "    0.17178328572949006,\n",
       "    0.11748428703947382,\n",
       "    0.09700116476329763,\n",
       "    0.09113557311235612,\n",
       "    0.08266038955054925,\n",
       "    0.07095452843877985,\n",
       "    0.062104726716913625,\n",
       "    0.06522773155993188,\n",
       "    0.05298289588054407,\n",
       "    0.05577786141891374,\n",
       "    0.048878094192171685,\n",
       "    0.04852971610329769,\n",
       "    0.04979994738461695,\n",
       "    0.048287409502433855,\n",
       "    0.042130185142852196,\n",
       "    0.033872251277853135,\n",
       "    0.04453516906865419,\n",
       "    0.03895915216332045,\n",
       "    0.03934866739016525,\n",
       "    0.03884109805853828,\n",
       "    0.031392386540076436,\n",
       "    0.025844915307910922,\n",
       "    0.029150222064509755,\n",
       "    0.03247131310058164,\n",
       "    0.029604376421714727,\n",
       "    0.03480631110068134,\n",
       "    0.022930628755900673,\n",
       "    0.029983828690534665,\n",
       "    0.026508127826751503,\n",
       "    0.025545463133106138,\n",
       "    0.022794092200064068,\n",
       "    0.02644918940572961,\n",
       "    0.027105135236655347,\n",
       "    0.02416171329772563,\n",
       "    0.029799885703449498,\n",
       "    0.021226320948213775,\n",
       "    0.025496394825299983,\n",
       "    0.021598792967414283,\n",
       "    0.020680395260926732,\n",
       "    0.022958372421470283,\n",
       "    0.020780260475992428,\n",
       "    0.02092681589526122,\n",
       "    0.023350758221857403,\n",
       "    0.023941244089282273,\n",
       "    0.01589421638047823,\n",
       "    0.01943137695860446,\n",
       "    0.014699053333831008,\n",
       "    0.021518599128448612,\n",
       "    0.019088052936209958]]},\n",
       " 'MNIST MLP on Non IID': {'hyperparams': {'C': 0.1,\n",
       "   'E': 5,\n",
       "   'K': 100,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.05,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[21.772151898734176,\n",
       "    32.40506329113924,\n",
       "    47.34177215189873,\n",
       "    53.79746835443038,\n",
       "    76.83544303797468,\n",
       "    78.35443037974683,\n",
       "    62.91139240506329,\n",
       "    82.0253164556962,\n",
       "    86.58227848101266,\n",
       "    82.0253164556962,\n",
       "    79.11392405063292,\n",
       "    86.07594936708861,\n",
       "    82.65822784810126,\n",
       "    90.75949367088607,\n",
       "    88.35443037974683,\n",
       "    85.69620253164557,\n",
       "    90.25316455696202,\n",
       "    91.89873417721519,\n",
       "    88.9873417721519,\n",
       "    91.13924050632912,\n",
       "    92.78481012658227,\n",
       "    89.11392405063292,\n",
       "    89.74683544303798,\n",
       "    93.92405063291139,\n",
       "    91.64556962025317,\n",
       "    91.13924050632912,\n",
       "    85.44303797468355,\n",
       "    86.32911392405063,\n",
       "    90.0,\n",
       "    91.0126582278481,\n",
       "    85.69620253164557,\n",
       "    91.13924050632912,\n",
       "    93.0379746835443,\n",
       "    94.81012658227849,\n",
       "    94.17721518987342,\n",
       "    93.54430379746836,\n",
       "    94.30379746835443,\n",
       "    94.17721518987342,\n",
       "    93.54430379746836,\n",
       "    93.54430379746836,\n",
       "    92.15189873417721,\n",
       "    93.29113924050633,\n",
       "    89.62025316455696,\n",
       "    92.27848101265823,\n",
       "    91.26582278481013,\n",
       "    94.0506329113924,\n",
       "    92.65822784810126,\n",
       "    94.9367088607595,\n",
       "    94.55696202531645,\n",
       "    94.68354430379746],\n",
       "   [37.21518987341772,\n",
       "    46.075949367088604,\n",
       "    45.949367088607595,\n",
       "    62.278481012658226,\n",
       "    58.607594936708864,\n",
       "    84.68354430379746,\n",
       "    69.62025316455696,\n",
       "    67.72151898734177,\n",
       "    80.50632911392405,\n",
       "    86.45569620253164,\n",
       "    84.43037974683544,\n",
       "    90.0,\n",
       "    89.24050632911393,\n",
       "    89.11392405063292,\n",
       "    91.0126582278481,\n",
       "    86.9620253164557,\n",
       "    89.24050632911393,\n",
       "    88.10126582278481,\n",
       "    87.59493670886076,\n",
       "    91.89873417721519,\n",
       "    88.22784810126582,\n",
       "    81.77215189873418,\n",
       "    90.25316455696202,\n",
       "    87.9746835443038,\n",
       "    91.89873417721519,\n",
       "    90.75949367088607,\n",
       "    91.51898734177215,\n",
       "    90.37974683544304,\n",
       "    91.26582278481013,\n",
       "    91.89873417721519,\n",
       "    93.54430379746836,\n",
       "    92.15189873417721,\n",
       "    94.81012658227849,\n",
       "    93.41772151898734,\n",
       "    95.31645569620254,\n",
       "    92.78481012658227,\n",
       "    90.37974683544304,\n",
       "    93.41772151898734,\n",
       "    93.41772151898734,\n",
       "    94.68354430379746,\n",
       "    95.0632911392405,\n",
       "    90.25316455696202,\n",
       "    89.74683544303798,\n",
       "    93.92405063291139,\n",
       "    91.77215189873418,\n",
       "    94.81012658227849,\n",
       "    95.44303797468355,\n",
       "    94.68354430379746,\n",
       "    92.0253164556962,\n",
       "    91.26582278481013],\n",
       "   [34.81012658227848,\n",
       "    47.9746835443038,\n",
       "    60.50632911392405,\n",
       "    62.91139240506329,\n",
       "    59.24050632911393,\n",
       "    69.24050632911393,\n",
       "    79.62025316455696,\n",
       "    82.78481012658227,\n",
       "    77.34177215189874,\n",
       "    86.20253164556962,\n",
       "    88.10126582278481,\n",
       "    88.86075949367088,\n",
       "    90.50632911392405,\n",
       "    84.81012658227849,\n",
       "    86.9620253164557,\n",
       "    84.68354430379746,\n",
       "    84.81012658227849,\n",
       "    89.49367088607595,\n",
       "    91.64556962025317,\n",
       "    86.9620253164557,\n",
       "    89.49367088607595,\n",
       "    89.36708860759494,\n",
       "    87.84810126582279,\n",
       "    86.9620253164557,\n",
       "    90.50632911392405,\n",
       "    87.59493670886076,\n",
       "    92.0253164556962,\n",
       "    92.9113924050633,\n",
       "    90.63291139240506,\n",
       "    91.13924050632912,\n",
       "    93.54430379746836,\n",
       "    91.64556962025317,\n",
       "    88.73417721518987,\n",
       "    90.37974683544304,\n",
       "    93.92405063291139,\n",
       "    93.92405063291139,\n",
       "    92.9113924050633,\n",
       "    93.16455696202532,\n",
       "    92.15189873417721,\n",
       "    90.63291139240506,\n",
       "    94.0506329113924,\n",
       "    89.49367088607595,\n",
       "    94.0506329113924,\n",
       "    94.0506329113924,\n",
       "    96.20253164556962,\n",
       "    93.0379746835443,\n",
       "    94.43037974683544,\n",
       "    95.44303797468355,\n",
       "    93.16455696202532,\n",
       "    89.11392405063292],\n",
       "   [30.759493670886076,\n",
       "    40.379746835443036,\n",
       "    52.40506329113924,\n",
       "    69.62025316455696,\n",
       "    60.63291139240506,\n",
       "    69.87341772151899,\n",
       "    74.0506329113924,\n",
       "    76.20253164556962,\n",
       "    81.77215189873418,\n",
       "    84.68354430379746,\n",
       "    77.9746835443038,\n",
       "    84.68354430379746,\n",
       "    89.24050632911393,\n",
       "    87.72151898734177,\n",
       "    84.9367088607595,\n",
       "    90.50632911392405,\n",
       "    90.50632911392405,\n",
       "    90.12658227848101,\n",
       "    91.13924050632912,\n",
       "    87.59493670886076,\n",
       "    82.65822784810126,\n",
       "    83.67088607594937,\n",
       "    90.37974683544304,\n",
       "    91.0126582278481,\n",
       "    84.30379746835443,\n",
       "    85.56962025316456,\n",
       "    87.0886075949367,\n",
       "    90.0,\n",
       "    92.65822784810126,\n",
       "    86.83544303797468,\n",
       "    90.50632911392405,\n",
       "    94.30379746835443,\n",
       "    94.30379746835443,\n",
       "    94.43037974683544,\n",
       "    92.15189873417721,\n",
       "    89.49367088607595,\n",
       "    93.16455696202532,\n",
       "    91.64556962025317,\n",
       "    91.64556962025317,\n",
       "    92.15189873417721,\n",
       "    92.78481012658227,\n",
       "    90.75949367088607,\n",
       "    92.78481012658227,\n",
       "    94.0506329113924,\n",
       "    94.0506329113924,\n",
       "    92.9113924050633,\n",
       "    91.39240506329114,\n",
       "    91.89873417721519,\n",
       "    95.44303797468355,\n",
       "    91.64556962025317],\n",
       "   [30.0,\n",
       "    26.20253164556962,\n",
       "    47.34177215189873,\n",
       "    66.32911392405063,\n",
       "    83.92405063291139,\n",
       "    80.12658227848101,\n",
       "    85.69620253164557,\n",
       "    85.31645569620254,\n",
       "    81.77215189873418,\n",
       "    88.48101265822785,\n",
       "    87.9746835443038,\n",
       "    87.46835443037975,\n",
       "    82.9113924050633,\n",
       "    86.83544303797468,\n",
       "    89.24050632911393,\n",
       "    89.11392405063292,\n",
       "    88.60759493670886,\n",
       "    91.39240506329114,\n",
       "    91.26582278481013,\n",
       "    88.22784810126582,\n",
       "    87.59493670886076,\n",
       "    87.46835443037975,\n",
       "    90.88607594936708,\n",
       "    91.39240506329114,\n",
       "    94.30379746835443,\n",
       "    91.77215189873418,\n",
       "    93.0379746835443,\n",
       "    91.89873417721519,\n",
       "    91.77215189873418,\n",
       "    91.0126582278481,\n",
       "    88.73417721518987,\n",
       "    92.40506329113924,\n",
       "    92.53164556962025,\n",
       "    91.0126582278481,\n",
       "    93.79746835443038,\n",
       "    94.55696202531645,\n",
       "    92.15189873417721,\n",
       "    94.0506329113924,\n",
       "    93.0379746835443,\n",
       "    92.65822784810126,\n",
       "    93.79746835443038,\n",
       "    95.31645569620254,\n",
       "    92.15189873417721,\n",
       "    94.9367088607595,\n",
       "    94.0506329113924,\n",
       "    95.69620253164557,\n",
       "    91.39240506329114,\n",
       "    91.89873417721519,\n",
       "    94.43037974683544,\n",
       "    94.9367088607595]],\n",
       "  'test_loss': [[3.310948645782471,\n",
       "    2.482221892166138,\n",
       "    1.5951323158264161,\n",
       "    1.649097227859497,\n",
       "    0.9729208696365357,\n",
       "    0.8315823125839233,\n",
       "    1.1223890781402588,\n",
       "    0.6035943525314331,\n",
       "    0.45003086738586423,\n",
       "    0.5293703256130219,\n",
       "    0.5558767217636108,\n",
       "    0.4227699634552002,\n",
       "    0.4522565227508545,\n",
       "    0.3173113063335419,\n",
       "    0.3260763212203979,\n",
       "    0.3831980672597885,\n",
       "    0.30471082458496096,\n",
       "    0.27184364724159243,\n",
       "    0.32596727004051207,\n",
       "    0.27897030606269835,\n",
       "    0.224518328332901,\n",
       "    0.3273250803947449,\n",
       "    0.32550947945117953,\n",
       "    0.21333721442222595,\n",
       "    0.26866272382736206,\n",
       "    0.24415942063331603,\n",
       "    0.40378948941230774,\n",
       "    0.36616625204086306,\n",
       "    0.30913800115585327,\n",
       "    0.27423518691062926,\n",
       "    0.37755776610374453,\n",
       "    0.26071928555965423,\n",
       "    0.1884821358203888,\n",
       "    0.17298413818478584,\n",
       "    0.17066606369018555,\n",
       "    0.1917620603621006,\n",
       "    0.1847219284057617,\n",
       "    0.1954749720811844,\n",
       "    0.21548595329523088,\n",
       "    0.17244392561912536,\n",
       "    0.20003897943496704,\n",
       "    0.20011341869831084,\n",
       "    0.2770774199962616,\n",
       "    0.18274177124500274,\n",
       "    0.2242222418308258,\n",
       "    0.18330054174661636,\n",
       "    0.22300622951984406,\n",
       "    0.1525747330546379,\n",
       "    0.1637047407925129,\n",
       "    0.17169087596535682],\n",
       "   [3.184309535598755,\n",
       "    2.3500373975753783,\n",
       "    2.220420295333862,\n",
       "    1.2932008609771728,\n",
       "    1.3528760110855103,\n",
       "    0.5827733329772949,\n",
       "    0.8297941529273987,\n",
       "    0.9233662663459777,\n",
       "    0.6457238889694213,\n",
       "    0.4962364009141922,\n",
       "    0.49996255259513855,\n",
       "    0.35388888585567474,\n",
       "    0.3306668564200401,\n",
       "    0.3667823977947235,\n",
       "    0.331229133439064,\n",
       "    0.3304270891189575,\n",
       "    0.28895838844180105,\n",
       "    0.367619722700119,\n",
       "    0.3396132077693939,\n",
       "    0.26625293605327605,\n",
       "    0.3182495462179184,\n",
       "    0.46232060812711717,\n",
       "    0.27254235575199126,\n",
       "    0.31586171379089356,\n",
       "    0.23657493867278098,\n",
       "    0.2880581185042858,\n",
       "    0.2559930014967918,\n",
       "    0.30084986451864243,\n",
       "    0.23897132798433304,\n",
       "    0.22493901205062866,\n",
       "    0.18311770274043082,\n",
       "    0.2259208410024643,\n",
       "    0.18533166146874427,\n",
       "    0.24124193682670594,\n",
       "    0.16526744679808617,\n",
       "    0.20704161868691445,\n",
       "    0.2745543827056885,\n",
       "    0.19739880871772766,\n",
       "    0.20821120750904082,\n",
       "    0.1675822084516287,\n",
       "    0.17279595134258272,\n",
       "    0.2676615235209465,\n",
       "    0.29295799434185027,\n",
       "    0.1836970349431038,\n",
       "    0.24058183282613754,\n",
       "    0.16377831701636314,\n",
       "    0.15957815850973128,\n",
       "    0.16870504583120347,\n",
       "    0.23525481442809104,\n",
       "    0.22201801392436027],\n",
       "   [3.379201620864868,\n",
       "    2.111823363494873,\n",
       "    1.6448978828430176,\n",
       "    1.1716388333320618,\n",
       "    1.1836520446777343,\n",
       "    1.0314239463806152,\n",
       "    0.6208605815887451,\n",
       "    0.5288700688838959,\n",
       "    0.5966032608032227,\n",
       "    0.4376838257789612,\n",
       "    0.4109624791622162,\n",
       "    0.3577697246789932,\n",
       "    0.324268497133255,\n",
       "    0.45285345797538756,\n",
       "    0.36893028078079226,\n",
       "    0.42842771017551423,\n",
       "    0.4150576645851135,\n",
       "    0.29789483761787416,\n",
       "    0.25796024062633516,\n",
       "    0.4253359325408936,\n",
       "    0.30800209283828733,\n",
       "    0.2756091737151146,\n",
       "    0.342271687912941,\n",
       "    0.3459605762004852,\n",
       "    0.29062900784015655,\n",
       "    0.3389340962409973,\n",
       "    0.24885084758400916,\n",
       "    0.21992641063928603,\n",
       "    0.27141615751981735,\n",
       "    0.2540957581520081,\n",
       "    0.2246789831638336,\n",
       "    0.26974474809765814,\n",
       "    0.3277962741017342,\n",
       "    0.3021668454647064,\n",
       "    0.22520865116119385,\n",
       "    0.2235410313129425,\n",
       "    0.22628717473745347,\n",
       "    0.2139853391289711,\n",
       "    0.2423527007818222,\n",
       "    0.2840994580745697,\n",
       "    0.19294197251200676,\n",
       "    0.31126206406354906,\n",
       "    0.20147612297534942,\n",
       "    0.1798392480492592,\n",
       "    0.15056618195176125,\n",
       "    0.21958527077436446,\n",
       "    0.18605710084438323,\n",
       "    0.1661522872030735,\n",
       "    0.20575616079568862,\n",
       "    0.32739436586499215],\n",
       "   [3.4264556213378907,\n",
       "    2.200166296005249,\n",
       "    1.7139511814117432,\n",
       "    1.0834571411132812,\n",
       "    1.282966831588745,\n",
       "    0.8935506688117981,\n",
       "    0.8366112143516541,\n",
       "    0.9097701000213623,\n",
       "    0.5581248058319092,\n",
       "    0.47081090655326846,\n",
       "    0.6941418884754181,\n",
       "    0.4539503155708313,\n",
       "    0.3977550169467926,\n",
       "    0.4059315849304199,\n",
       "    0.43564492931365967,\n",
       "    0.31188956723213196,\n",
       "    0.2969010550498962,\n",
       "    0.2927931461811066,\n",
       "    0.29920556492805483,\n",
       "    0.33183726468086244,\n",
       "    0.46523794751167297,\n",
       "    0.42921171779632566,\n",
       "    0.30250347628593444,\n",
       "    0.2911783332824707,\n",
       "    0.4414870092868805,\n",
       "    0.38887179470062255,\n",
       "    0.3879091627597809,\n",
       "    0.2850085716724396,\n",
       "    0.22816657778024674,\n",
       "    0.34752845799922943,\n",
       "    0.2606421451807022,\n",
       "    0.19537440404891968,\n",
       "    0.20434999102354048,\n",
       "    0.21128470937013627,\n",
       "    0.27954624795913696,\n",
       "    0.3096724316596985,\n",
       "    0.25296698582172394,\n",
       "    0.24676252846717833,\n",
       "    0.2305147725582123,\n",
       "    0.2464916485786438,\n",
       "    0.2131439331293106,\n",
       "    0.2577097443342209,\n",
       "    0.21249050343036652,\n",
       "    0.1871169784784317,\n",
       "    0.187601362657547,\n",
       "    0.2067613445997238,\n",
       "    0.21189446312785148,\n",
       "    0.20173373811244966,\n",
       "    0.1605403436243534,\n",
       "    0.24374388425350188],\n",
       "   [3.3126536754608154,\n",
       "    2.4889989364624023,\n",
       "    2.0563342555999755,\n",
       "    1.091263045024872,\n",
       "    0.659023861169815,\n",
       "    0.6164910007953643,\n",
       "    0.49103747749328613,\n",
       "    0.543480938577652,\n",
       "    0.5222939405441284,\n",
       "    0.4093340031147003,\n",
       "    0.38368674190044405,\n",
       "    0.37060319535732267,\n",
       "    0.4845865689277649,\n",
       "    0.3800723243236542,\n",
       "    0.3446248991250992,\n",
       "    0.33278940243721006,\n",
       "    0.3479566946029663,\n",
       "    0.2907002866744995,\n",
       "    0.27101368975639345,\n",
       "    0.3493276961565018,\n",
       "    0.39493196852207185,\n",
       "    0.34035911061763763,\n",
       "    0.2698027497768402,\n",
       "    0.26676759935617445,\n",
       "    0.22503928303718568,\n",
       "    0.2506145984649658,\n",
       "    0.2300806121826172,\n",
       "    0.23538061923980713,\n",
       "    0.2418489462018013,\n",
       "    0.24701215336322785,\n",
       "    0.3432367289304733,\n",
       "    0.2096669551372528,\n",
       "    0.24447842396497727,\n",
       "    0.2491912124097347,\n",
       "    0.19876656109690666,\n",
       "    0.18772224360108375,\n",
       "    0.24240820106863975,\n",
       "    0.18820308244228362,\n",
       "    0.20950037553310394,\n",
       "    0.20267354559898376,\n",
       "    0.19838856397867202,\n",
       "    0.16815702660381793,\n",
       "    0.2333987209647894,\n",
       "    0.1598320267021656,\n",
       "    0.19249761882424354,\n",
       "    0.14851531378030777,\n",
       "    0.24088227869272233,\n",
       "    0.23827683086395263,\n",
       "    0.17939851182699204,\n",
       "    0.152687117639184]],\n",
       "  'train_loss': [[0.11451629387532827,\n",
       "    0.06391115190160065,\n",
       "    0.04008103314892945,\n",
       "    0.0392506404897503,\n",
       "    0.043987947452892175,\n",
       "    0.02357705000594954,\n",
       "    0.02217310059458809,\n",
       "    0.016069254883623957,\n",
       "    0.02961667075986311,\n",
       "    0.03067777453823064,\n",
       "    0.034476186843417814,\n",
       "    0.023423576200860073,\n",
       "    0.019607614105147105,\n",
       "    0.015677468754420335,\n",
       "    0.02074319524044147,\n",
       "    0.01395113862832017,\n",
       "    0.01459286936931263,\n",
       "    0.017909101093552725,\n",
       "    0.02550428510254748,\n",
       "    0.014598360073397487,\n",
       "    0.014027624155249024,\n",
       "    0.01580846948615707,\n",
       "    0.011416512066910493,\n",
       "    0.00874369204644402,\n",
       "    0.013453259324512587,\n",
       "    0.01481506696220535,\n",
       "    0.014077506148536456,\n",
       "    0.013052777926276907,\n",
       "    0.016455200967822395,\n",
       "    0.01114427011144196,\n",
       "    0.01678873938751272,\n",
       "    0.013023887788287055,\n",
       "    0.015891276842190365,\n",
       "    0.01484919792473062,\n",
       "    0.009424172441067327,\n",
       "    0.019059415956308258,\n",
       "    0.01591667075275458,\n",
       "    0.015127926399730773,\n",
       "    0.014123547114860894,\n",
       "    0.012892786470619205,\n",
       "    0.011978706484561884,\n",
       "    0.01093684696093421,\n",
       "    0.007235378522735593,\n",
       "    0.008366958976211522,\n",
       "    0.009766560445951027,\n",
       "    0.007347997966805316,\n",
       "    0.010225810226089945,\n",
       "    0.007355093068911521,\n",
       "    0.015321111621300476,\n",
       "    0.006261580068372222],\n",
       "   [0.09948828535729737,\n",
       "    0.049716589460187206,\n",
       "    0.04290247353394453,\n",
       "    0.03595468016593364,\n",
       "    0.023459062073372443,\n",
       "    0.04159783896393017,\n",
       "    0.057986158087762286,\n",
       "    0.026298686567015866,\n",
       "    0.031454389169482865,\n",
       "    0.03195223571812059,\n",
       "    0.02743899873570238,\n",
       "    0.021578642472106696,\n",
       "    0.028601473849170982,\n",
       "    0.027092328559529828,\n",
       "    0.014458235914526293,\n",
       "    0.014771735609880576,\n",
       "    0.0267397169463446,\n",
       "    0.022424366537716532,\n",
       "    0.014285660227263824,\n",
       "    0.010714597876204369,\n",
       "    0.01376201401887876,\n",
       "    0.014264635089610908,\n",
       "    0.013182827319380294,\n",
       "    0.015183984952872964,\n",
       "    0.022602148086027243,\n",
       "    0.00810439279898378,\n",
       "    0.010903053489419843,\n",
       "    0.021736521014609083,\n",
       "    0.011525490861478594,\n",
       "    0.014373436597076988,\n",
       "    0.019865521126446326,\n",
       "    0.010294458194303635,\n",
       "    0.008792458805201034,\n",
       "    0.009103616829706436,\n",
       "    0.018111269128246604,\n",
       "    0.01630894853935965,\n",
       "    0.012672050656435091,\n",
       "    0.010579709926621144,\n",
       "    0.00901935712912592,\n",
       "    0.005870475986056124,\n",
       "    0.01602659873936815,\n",
       "    0.007770064928478909,\n",
       "    0.014961529978536562,\n",
       "    0.009379109499422283,\n",
       "    0.005920942623909733,\n",
       "    0.015158216092043406,\n",
       "    0.014901627632410267,\n",
       "    0.005681983843501571,\n",
       "    0.010423225382898622,\n",
       "    0.008046534838123764],\n",
       "   [0.14400782458988032,\n",
       "    0.06692455956047248,\n",
       "    0.0420558292598527,\n",
       "    0.03607961404771576,\n",
       "    0.02811589780952479,\n",
       "    0.039608511763371865,\n",
       "    0.03194810624223006,\n",
       "    0.01906244060583373,\n",
       "    0.03242962640566995,\n",
       "    0.036988356637113876,\n",
       "    0.016408856432439754,\n",
       "    0.024742072023863734,\n",
       "    0.025417648073310917,\n",
       "    0.019893042153346224,\n",
       "    0.015116687490088054,\n",
       "    0.020383316233694077,\n",
       "    0.014142921946461296,\n",
       "    0.01840533711061832,\n",
       "    0.008799978069720122,\n",
       "    0.023500742422736275,\n",
       "    0.018016285605340437,\n",
       "    0.008598306007567372,\n",
       "    0.01114552705923166,\n",
       "    0.021582296695911975,\n",
       "    0.013715861781878025,\n",
       "    0.010484343086404627,\n",
       "    0.01116299366049507,\n",
       "    0.017655658607795905,\n",
       "    0.011084461371368046,\n",
       "    0.010778256418618506,\n",
       "    0.011856914840297219,\n",
       "    0.012925735025118512,\n",
       "    0.018067446919771878,\n",
       "    0.008166316355047522,\n",
       "    0.0195297592388908,\n",
       "    0.01075381619930656,\n",
       "    0.00839554253394382,\n",
       "    0.014651931010261816,\n",
       "    0.017817442330072552,\n",
       "    0.009861745129797952,\n",
       "    0.011384396141839314,\n",
       "    0.007873254003098368,\n",
       "    0.009316381951757751,\n",
       "    0.015263974146874668,\n",
       "    0.011199391015877113,\n",
       "    0.008332545287032953,\n",
       "    0.005651783451324076,\n",
       "    0.010266148118093895,\n",
       "    0.00941421981571753,\n",
       "    0.012564781234605929],\n",
       "   [0.08473450410185049,\n",
       "    0.030883639988138756,\n",
       "    0.0489473940198293,\n",
       "    0.03379806152296075,\n",
       "    0.02914223847075626,\n",
       "    0.03933004475920357,\n",
       "    0.024195238974013236,\n",
       "    0.03311216604611082,\n",
       "    0.025195882646457318,\n",
       "    0.02414886842343583,\n",
       "    0.02310959693967707,\n",
       "    0.02918174526027111,\n",
       "    0.022653953108241316,\n",
       "    0.01981393627278442,\n",
       "    0.02555472608799495,\n",
       "    0.017468495985596046,\n",
       "    0.01666960053641402,\n",
       "    0.01824350016947316,\n",
       "    0.016621348286267608,\n",
       "    0.014933149862223768,\n",
       "    0.019877271387385785,\n",
       "    0.01886858883012963,\n",
       "    0.014507615646494628,\n",
       "    0.013743648582972168,\n",
       "    0.015249590178045638,\n",
       "    0.011149451872440323,\n",
       "    0.010913261889307455,\n",
       "    0.00937416257854157,\n",
       "    0.010094633237962414,\n",
       "    0.013527305820744174,\n",
       "    0.011912666792006098,\n",
       "    0.015122016713085268,\n",
       "    0.0060600045113185196,\n",
       "    0.007999719470295446,\n",
       "    0.010591991757463618,\n",
       "    0.010444284007745,\n",
       "    0.01131734351127948,\n",
       "    0.01437877824473138,\n",
       "    0.009494096323882368,\n",
       "    0.006091013575864675,\n",
       "    0.009293331360643184,\n",
       "    0.010920241431586455,\n",
       "    0.00612525150019364,\n",
       "    0.016671955653391923,\n",
       "    0.0056095763496397544,\n",
       "    0.01502090184901991,\n",
       "    0.008392090490075214,\n",
       "    0.006328637716709129,\n",
       "    0.007146625420497518,\n",
       "    0.013527505637644585],\n",
       "   [0.11180381293653818,\n",
       "    0.062452933186468405,\n",
       "    0.04360694464267546,\n",
       "    0.0528002251983706,\n",
       "    0.027108963200151846,\n",
       "    0.030506273996949322,\n",
       "    0.02948337621899172,\n",
       "    0.01688053343915667,\n",
       "    0.02928567766758048,\n",
       "    0.018423021873388696,\n",
       "    0.0344620674047406,\n",
       "    0.022780219132906426,\n",
       "    0.01634031015005851,\n",
       "    0.019463280554740205,\n",
       "    0.026765585242254704,\n",
       "    0.01972210310550766,\n",
       "    0.011398459822315403,\n",
       "    0.013431280703486651,\n",
       "    0.02051086632369417,\n",
       "    0.018286236507699262,\n",
       "    0.01901530677592341,\n",
       "    0.009970300529630613,\n",
       "    0.01201953672940466,\n",
       "    0.017197143658949716,\n",
       "    0.01440234303192695,\n",
       "    0.019534064543389823,\n",
       "    0.010566928042971086,\n",
       "    0.008067690613983755,\n",
       "    0.012307203128561237,\n",
       "    0.015392454279560527,\n",
       "    0.019256179149254354,\n",
       "    0.012951212932533753,\n",
       "    0.01075002648698859,\n",
       "    0.011828890837304306,\n",
       "    0.008793113996610341,\n",
       "    0.015160207658269568,\n",
       "    0.009569620809522462,\n",
       "    0.010933330538950514,\n",
       "    0.010369644905027828,\n",
       "    0.013505967936628043,\n",
       "    0.011394047916750263,\n",
       "    0.004716594825670863,\n",
       "    0.0051139380654993795,\n",
       "    0.011693607747054338,\n",
       "    0.009062311941786663,\n",
       "    0.007650467321289302,\n",
       "    0.00534885682157858,\n",
       "    0.009878463017984436,\n",
       "    0.01709043748608144,\n",
       "    0.014196140572649901]]}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open(path + 'Local_Round_FedAvg_5.pkl', 'rb') as file:\n",
    "  log_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "se_04JMaVJPg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.62025316455696, 99.36708860759494, 99.74683544303798, 99.49367088607595, 99.49367088607595]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['MNIST CNN on IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "5sv0rv-G4Sqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98.48101265822785, 98.73417721518987, 98.86075949367088, 98.73417721518987, 98.86075949367088]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['MNIST CNN on Non IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "b2a2_Az-4nal"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97.9746835443038, 98.22784810126582, 98.22784810126582, 97.72151898734177, 97.9746835443038]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['MNIST MLP on IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "YoRqZyvD4p2K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94.68354430379746, 91.26582278481013, 89.11392405063292, 91.64556962025317, 94.9367088607595]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['MNIST MLP on Non IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "B87eGKJnAHIh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "FederatedAveraging",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "QSGD",
   "language": "python",
   "name": "qsgd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
