{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tushar-semwal/fedperf/blob/main/Vineeth/Local_Rounds/FedAvg/FederatedAveraging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKcpjZLrQQJV",
    "outputId": "5fca5a43-8803-4d05-99e7-310c60b2eb17"
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    import os\n",
    "    path = '/content/drive/MyDrive/Colab Notebooks/OpenMined/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "except:\n",
    "    path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0_nKpfq2h1R"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLLNM9X2JbQ8",
    "outputId": "c88c97b3-b806-4e29-f4cd-02a6743f4f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 12 23:22:01 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 17%   33C    P0    54W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 17%   32C    P0    56W / 250W |      0MiB / 11178MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Check assigned GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "# set manual seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# general reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# gpu training specific\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY4eWzGiL6Mj"
   },
   "source": [
    "## Load the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "G649tjTXLL8F"
   },
   "outputs": [],
   "source": [
    "# create transforms\n",
    "# We will just convert to tensor and normalize since no special transforms are mentioned in the paper\n",
    "transforms_mnist = transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                       ])\n",
    "\n",
    "mnist_data_train = datasets.MNIST('./data/mnist/', train=True, download=True, transform=transforms_mnist)\n",
    "mnist_data_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=transforms_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dm9usjn2vFkL",
    "outputId": "a76539d2-3f37-4485-e5ac-7633e785c18c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0 1 2 3 4 5 6 7 8 9] \tType: <class 'numpy.ndarray'>\n",
      "Classes Test: [0 1 2 3 4 5 6 7 8 9] \tType: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "classes = np.array(list(mnist_data_train.class_to_idx.values()))\n",
    "classes_test = np.array(list(mnist_data_test.class_to_idx.values()))\n",
    "num_classes = len(classes_test)\n",
    "print(\"Classes: {} \\tType: {}\".format(classes, type(classes)))\n",
    "print(\"Classes Test: {} \\tType: {}\".format(classes_test, type(classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lvJt3Ofv2SO",
    "outputId": "d3626726-b3da-426f-9712-7a7be680d33b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"Image Shape: {}\".format(mnist_data_train.data[0].size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCOONkg-zV7Y"
   },
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "R9MK03TZw6Qs"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "\timg = img/2 + 0.5 #unnormalize the image\n",
    "\tplt.imshow(img, cmap='gray') # convert from tensor to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "gMJ0Kx4Kw-_H"
   },
   "outputs": [],
   "source": [
    "def visualize(dataset):\n",
    "  figure = plt.figure(figsize=(25,4))\n",
    "  for i in range(20):\n",
    "    axis = figure.add_subplot(2, 20/2, i+1, xticks=[], yticks=[])\n",
    "    data = dataset.data[i]\n",
    "    data = data.numpy()\n",
    "\n",
    "    target = dataset.targets[i]\n",
    "    target = target.numpy()\n",
    "    imshow(data)\n",
    "    axis.set_title(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "8bPOwKg10Ro7",
    "outputId": "52916fa2-c981-44e5-92a7-43886e91b271"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(mnist_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "RKoh5Cf70UYu",
    "outputId": "91e5ef2a-5e61-454b-a4f3-c64ff266071a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineeth/anaconda3/envs/QSGD-PT/lib/python3.7/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(mnist_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctjRsETiO1qO"
   },
   "source": [
    "## Partitioning the Data (IID and non-IID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "3_v8lyrgO5dD"
   },
   "outputs": [],
   "source": [
    "def iid_partition(dataset, clients):\n",
    "  \"\"\"\n",
    "  I.I.D paritioning of data over clients\n",
    "  Shuffle the data\n",
    "  Split it between clients\n",
    "  \n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "\n",
    "  num_items_per_client = int(len(dataset)/clients)\n",
    "  client_dict = {}\n",
    "  image_idxs = [i for i in range(len(dataset))]\n",
    "\n",
    "  for i in range(clients):\n",
    "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
    "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
    "\n",
    "  return client_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4zMdliGMQoSl"
   },
   "outputs": [],
   "source": [
    "def non_iid_partition(dataset, clients, total_shards, shards_size, num_shards_per_client):\n",
    "  \"\"\"\n",
    "  non I.I.D parititioning of data over clients\n",
    "  Sort the data by the digit label\n",
    "  Divide the data into N shards of size S\n",
    "  Each of the clients will get X shards\n",
    "\n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "    - total_shards (int): Number of shards to partition the data in\n",
    "    - shards_size (int): Size of each shard \n",
    "    - num_shards_per_client (int): Number of shards of size shards_size that each client receives\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "  \n",
    "  shard_idxs = [i for i in range(total_shards)]\n",
    "  client_dict = {i: np.array([], dtype='int64') for i in range(clients)}\n",
    "  idxs = np.arange(len(dataset))\n",
    "  data_labels = dataset.targets.numpy()\n",
    "\n",
    "  # sort the labels\n",
    "  label_idxs = np.vstack((idxs, data_labels))\n",
    "  label_idxs = label_idxs[:, label_idxs[1,:].argsort()]\n",
    "  idxs = label_idxs[0,:]\n",
    "\n",
    "  # divide the data into total_shards of size shards_size\n",
    "  # assign num_shards_per_client to each client\n",
    "  for i in range(clients):\n",
    "    rand_set = set(np.random.choice(shard_idxs, num_shards_per_client, replace=False))\n",
    "    shard_idxs = list(set(shard_idxs) - rand_set)\n",
    "\n",
    "    for rand in rand_set:\n",
    "      client_dict[i] = np.concatenate((client_dict[i], idxs[rand*shards_size:(rand+1)*shards_size]), axis=0)\n",
    "  \n",
    "  return client_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTfxv8kFoGAy"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "CvoDNFKbZST5"
   },
   "outputs": [],
   "source": [
    "class MNIST_2NN(nn.Module):\n",
    "  \"\"\"\n",
    "  A simple multilayer-perceptron with 2-hidden layers with 200 units each\n",
    "  using ReLu activations\n",
    "\n",
    "  Total Expected Params: 199,210\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super(MNIST_2NN, self).__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(28*28, 200)\n",
    "    self.fc2 = nn.Linear(200, 200)\n",
    "    self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    out = self.fc3(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ut1hZ8x3qYPZ"
   },
   "outputs": [],
   "source": [
    "class MNIST_CNN(nn.Module):\n",
    "  \"\"\"\n",
    "  CNN with two 5x5 convolution lauers(the first with 32 channels, second with 64,\n",
    "  each followed with 2x2 max pooling), a fully connected layer with 512 uunits and \n",
    "  ReLu activation, and the final Softmax output layer\n",
    "\n",
    "  Total Expected Params: 1,663,370\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super(MNIST_CNN, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "    \n",
    "    self.pool = nn.MaxPool2d(2,2)\n",
    "    self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    self.fc1 = nn.Linear(1024, 512)\n",
    "    self.out = nn.Linear(512, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = self.dropout(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.out(x)\n",
    "    out = F.log_softmax(x, dim=1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVv4HA9HuLtr"
   },
   "source": [
    "### Print Model Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5oTH710sJEt",
    "outputId": "3e8f2eff-a1be-45a7-a297-5963b3b4e48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST MLP SUMMARY\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 200]         157,000\n",
      "            Linear-2                  [-1, 200]          40,200\n",
      "            Linear-3                   [-1, 10]           2,010\n",
      "================================================================\n",
      "Total params: 199,210\n",
      "Trainable params: 199,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.76\n",
      "Estimated Total Size (MB): 0.77\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "\n",
      "MNIST CNN SUMMARY\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 24, 24]             832\n",
      "         MaxPool2d-2           [-1, 32, 12, 12]               0\n",
      "            Conv2d-3             [-1, 64, 8, 8]          51,264\n",
      "         MaxPool2d-4             [-1, 64, 4, 4]               0\n",
      "           Dropout-5             [-1, 64, 4, 4]               0\n",
      "            Linear-6                  [-1, 512]         524,800\n",
      "            Linear-7                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 582,026\n",
      "Trainable params: 582,026\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.23\n",
      "Params size (MB): 2.22\n",
      "Estimated Total Size (MB): 2.45\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "mnist_mlp = MNIST_2NN()\n",
    "mnist_cnn = MNIST_CNN()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  mnist_mlp.cuda()\n",
    "  mnist_cnn.cuda()\n",
    "\n",
    "print(\"MNIST MLP SUMMARY\")\n",
    "print(summary(mnist_mlp, (28,28)))\n",
    "\n",
    "print(\"\\nMNIST CNN SUMMARY\")\n",
    "print(summary(mnist_cnn, (1, 28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gf_8XEXa-gZ7"
   },
   "source": [
    "## Federated Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-aNdQsQ-Kvp"
   },
   "source": [
    "### Local Training (Client Update)\n",
    "\n",
    "Local training for the model on client side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "oX6OsQyO-Gz7"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, dataset, idxs):\n",
    "      self.dataset = dataset\n",
    "      self.idxs = list(idxs)\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.idxs)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "      image, label = self.dataset[self.idxs[item]]\n",
    "      return image, label\n",
    "\n",
    "\n",
    "class ClientUpdate(object):\n",
    "  def __init__(self, dataset, batchSize, learning_rate, epochs, idxs):\n",
    "    self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batchSize, shuffle=True)\n",
    "\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epochs = epochs\n",
    "\n",
    "  def train(self, model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.5)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    e_loss = []\n",
    "    for epoch in range(1, self.epochs+1):\n",
    "\n",
    "      train_loss = 0.0\n",
    "      model.train()\n",
    "      for data, labels in self.train_loader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "          data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # make a forward pass\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, labels)\n",
    "        # do a backwards pass\n",
    "        loss.backward()\n",
    "        # perform a single optimization step\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "      # average losses\n",
    "      train_loss = train_loss/len(self.train_loader.dataset)\n",
    "      e_loss.append(train_loss)\n",
    "\n",
    "    total_loss = sum(e_loss)/len(e_loss)\n",
    "\n",
    "    return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukgh1DVHE2Ds"
   },
   "source": [
    "### Server Side Training\n",
    "\n",
    "Following Algorithm 1 from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1NF1e33BgpeL"
   },
   "outputs": [],
   "source": [
    "def training(model, rounds, batch_size, lr, ds, ds_test, data_dict, C, K, E, plt_title, plt_color):\n",
    "  \"\"\"\n",
    "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
    "  Specifically, this function is used for the server side training and weight update\n",
    "\n",
    "  Params:\n",
    "    - model:           PyTorch model to train\n",
    "    - rounds:          Number of communication rounds for the client update\n",
    "    - batch_size:      Batch size for client update training\n",
    "    - lr:              Learning rate used for client update training\n",
    "    - ds:              Dataset used for training\n",
    "    - ds_test:         Dataset used for testing\n",
    "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
    "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
    "    - K:               Total number of clients\n",
    "    - E:               Number of training passes each client makes over its local dataset per round\n",
    "    - tb_writer_name:  Directory name to save the tensorboard logs\n",
    "  Returns:\n",
    "    - model:           Trained model on the server\n",
    "  \"\"\"\n",
    "\n",
    "  # global model weights\n",
    "  global_weights = model.state_dict()\n",
    "\n",
    "  # training loss\n",
    "  # train_accuracy = []\n",
    "  train_loss = []\n",
    "  test_accuracy = []\n",
    "  test_loss = []\n",
    "\n",
    "\n",
    "  # measure time\n",
    "  start = time.time()\n",
    "\n",
    "  for curr_round in range(1, rounds+1):\n",
    "    w, local_loss = [], []\n",
    "\n",
    "    m = max(int(C*K), 1)\n",
    "    \n",
    "    S_t = np.random.choice(range(K), m, replace=False)\n",
    "    for k in S_t:\n",
    "      local_update = ClientUpdate(dataset=ds, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=data_dict[k])\n",
    "      weights, loss = local_update.train(model=copy.deepcopy(model))\n",
    "\n",
    "      w.append(copy.deepcopy(weights))\n",
    "      local_loss.append(copy.deepcopy(loss))\n",
    "\n",
    "    # updating the global weights\n",
    "    weights_avg = copy.deepcopy(w[0])\n",
    "    for k in weights_avg.keys():\n",
    "      for i in range(1, len(w)):\n",
    "        weights_avg[k] += w[i][k]\n",
    "\n",
    "      weights_avg[k] = torch.div(weights_avg[k], len(w))\n",
    "\n",
    "    global_weights = weights_avg\n",
    "\n",
    "    # move the updated weights to our model state dict\n",
    "    model.load_state_dict(global_weights)\n",
    "\n",
    "    # loss\n",
    "    loss_avg = sum(local_loss) / len(local_loss)\n",
    "    print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)))\n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    # test\n",
    "    test_criterion = nn.CrossEntropyLoss()\n",
    "    test_accuracy_current, test_loss_current =  testing(copy.deepcopy(model), ds_test, 128, test_criterion, num_classes, classes_test)\n",
    "    test_accuracy.append(test_accuracy_current)\n",
    "    test_loss.append(test_loss_current)\n",
    "\n",
    "  end = time.time()\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(train_loss)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Train Loss',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Train_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_loss)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Loss',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_loss.jpg', format='jpg')\n",
    "  plt.show()\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  y_axis = np.array(test_accuracy)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Test Accuracy',\n",
    "       title=plt_title)\n",
    "  ax.grid()\n",
    "  fig.savefig(plt_title+'_Test_Accuracy.jpg', format='jpg')\n",
    "  plt.show()\n",
    "  \n",
    "  print(\"Training Done!\")\n",
    "  print(\"Total time taken to Train: {}\\n\\n\".format(end-start))\n",
    "  \n",
    "  return model, train_loss, test_accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUYyb4T-uXmF"
   },
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "uCcIZmO5uan9"
   },
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion, num_classes, classes, print_info=False):\n",
    "  #test loss \n",
    "  test_loss = 0.0\n",
    "  correct_class = list(0. for i in range(num_classes))\n",
    "  total_class = list(0. for i in range(num_classes))\n",
    "\n",
    "  test_loader = DataLoader(dataset, batch_size=bs)\n",
    "  l = len(test_loader)\n",
    "  model.eval()\n",
    "  for data, labels in test_loader:\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "      data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    output = model(data)\n",
    "    loss = criterion(output, labels)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "    #test accuracy for each object class\n",
    "    for i in range(num_classes):\n",
    "      label = labels.data[i]\n",
    "      correct_class[label] += correct[i].item()\n",
    "      total_class[label] += 1\n",
    "    \n",
    "  # avg test loss\n",
    "  test_loss = test_loss/len(test_loader.dataset)\n",
    "  test_accuracy = 100. * np.sum(correct_class) / np.sum(total_class)\n",
    "\n",
    "  if print_info:\n",
    "    print(\"Test Loss: {:.6f}\\n\".format(test_loss))\n",
    "\n",
    "    for i in range(10):\n",
    "      if total_class[i]>0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % \n",
    "              (classes[i], 100 * correct_class[i] / total_class[i],\n",
    "              np.sum(correct_class[i]), np.sum(total_class[i])))\n",
    "      else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nFinal Test  Accuracy: {:.3f} ({}/{})'.format(\n",
    "          100. * np.sum(correct_class) / np.sum(total_class),\n",
    "          np.sum(correct_class), np.sum(total_class)))\n",
    "  \n",
    "  return test_accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ri0FqXFeHW-V"
   },
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "thZm2kSiHT4v"
   },
   "outputs": [],
   "source": [
    "log_dict = {}\n",
    "NUM_REPEAT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hO5oV6aXqeh"
   },
   "source": [
    "## MNIST CNN on IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flSQv_P4zCfx"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0ZalcKZtEseA",
    "outputId": "b28f6fdb-c1ce-4c59-aa58-0e383d408230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Run Number:  0\n",
      "Round: 1... \tAverage Loss: 1.441\n",
      "Round: 2... \tAverage Loss: 0.569\n",
      "Round: 3... \tAverage Loss: 0.391\n",
      "Round: 4... \tAverage Loss: 0.278\n",
      "Round: 5... \tAverage Loss: 0.217\n",
      "Round: 6... \tAverage Loss: 0.203\n",
      "Round: 7... \tAverage Loss: 0.166\n",
      "Round: 8... \tAverage Loss: 0.172\n",
      "Round: 9... \tAverage Loss: 0.156\n",
      "Round: 10... \tAverage Loss: 0.126\n",
      "Round: 11... \tAverage Loss: 0.12\n",
      "Round: 12... \tAverage Loss: 0.124\n"
     ]
    }
   ],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.1\n",
    "  # number of clients\n",
    "  K = 100\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 1\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr=0.05\n",
    "  # data partition dictionary\n",
    "  iid_dict = iid_partition(mnist_data_train, 100)\n",
    "  # load model\n",
    "  mnist_cnn = MNIST_CNN()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    mnist_cnn.cuda()\n",
    "\n",
    "  mnist_cnn_iid_trained, train_loss, test_accuracy, test_loss = training(mnist_cnn, rounds, batch_size, lr, mnist_data_train, mnist_data_test, iid_dict, C, K, E, \"MNIST CNN on IID Dataset\", \"orange\")\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNwC82przF6G"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qB97BFs9we9w",
    "outputId": "42f4c586-7c3c-46f8-d9c5-7025c1ab4e24"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "acc, loss = testing(mnist_cnn_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdQZEZmHHeqt"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               }\n",
    "\n",
    "log_dict['MNIST CNN on IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF8MdSIUYcnl"
   },
   "source": [
    "## MNIST CNN on Non IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6wXX7JW11bx"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fCD3kBCKYfBK",
    "outputId": "f47df54f-43d5-4d0a-b89b-e90161c5f516"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.1\n",
    "  # number of clients\n",
    "  K = 100\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 1\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr=0.05\n",
    "  # dict containing different type of data partition\n",
    "  data_dict = non_iid_partition(mnist_data_train, 100, 200, 300, 2)\n",
    "  # load model\n",
    "  mnist_cnn = MNIST_CNN()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    mnist_cnn.cuda()\n",
    "\n",
    "  mnist_cnn_non_iid_trained, train_loss, test_accuracy, test_loss = training(mnist_cnn, rounds, batch_size, lr, mnist_data_train, mnist_data_test, data_dict, C, K, E, \"MNIST CNN on Non-IID Dataset\", \"green\")\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C68J-Kk14dB"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yQ9GiAZ15jE",
    "outputId": "2793a0a1-6969-4670-dd04-53dc6b191d44"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "acc, loss = testing(mnist_cnn_non_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxMcxgLhLvX-"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               }\n",
    "\n",
    "log_dict['MNIST CNN on Non IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_jifdzniuhm"
   },
   "source": [
    "## MNIST MLP on IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh-te0Od2XGO"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UmpWmKOQixVV",
    "outputId": "a487fb22-a217-4dfc-f4d6-63c4df004b41"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "\n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.1\n",
    "  # number of clients\n",
    "  K = 100\n",
    "  # number of training passes on local dataset for each round\n",
    "  E = 1\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr=0.05\n",
    "  # dict containing different type of data partition\n",
    "  data_dict = iid_partition(mnist_data_train, 100)\n",
    "  # load model\n",
    "  mnist_mlp = MNIST_2NN()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    mnist_mlp.cuda()\n",
    "\n",
    "  mnist_mlp_iid_trained, train_loss, test_accuracy, test_loss = training(mnist_mlp, rounds, batch_size, lr, mnist_data_train, mnist_data_test, data_dict, C, K, E, \"MNIST MLP on IID Dataset\", \"orange\")\n",
    "  \n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTBsL3-72PPd"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9G4j5L62OrS",
    "outputId": "e74613f0-7e49-4865-b430-223d32519658"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "acc, loss = testing(mnist_mlp_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWCdJFRCL_f2"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               }\n",
    "\n",
    "log_dict['MNIST MLP on IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8jzEyO0iywz"
   },
   "source": [
    "## MNIST MLP on Non IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJFepr3y2bF-"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EBKO44Hgi1Uh",
    "outputId": "7d0db2bf-fa03-4916-cb89-c2055290bdbb"
   },
   "outputs": [],
   "source": [
    "train_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "test_accuracy_multiple_runs = [None] * NUM_REPEAT\n",
    "test_loss_multiple_runs = [None] * NUM_REPEAT\n",
    "\n",
    "for exp_num in range(NUM_REPEAT):\n",
    "  print(\"Experiment Run Number: \", exp_num)\n",
    "  \n",
    "  # number of training rounds\n",
    "  rounds = 50\n",
    "  # client fraction\n",
    "  C = 0.1\n",
    "  # number of clients\n",
    "  K = 100\n",
    "  # number of training passes on local dataset for each roung\n",
    "  E = 1\n",
    "  # batch size\n",
    "  batch_size = 10\n",
    "  # learning Rate\n",
    "  lr=0.05\n",
    "  # dict containing different type of data partition\n",
    "  data_dict = non_iid_partition(mnist_data_train, 100, 200, 300, 2)\n",
    "  # load model\n",
    "  mnist_mlp = MNIST_2NN()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    mnist_mlp.cuda()\n",
    "\n",
    "  mnist_mlp_non_iid_trained, train_loss, test_accuracy, test_loss = training(mnist_mlp, rounds, batch_size, lr, mnist_data_train, mnist_data_test, data_dict, C, K, E, \"MNIST MLP on Non-IID Dataset\", \"green\")\n",
    "\n",
    "  train_loss_multiple_runs[exp_num] = train_loss\n",
    "  test_accuracy_multiple_runs[exp_num] = test_accuracy\n",
    "  test_loss_multiple_runs[exp_num] = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmuQYPbF2mes"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tKMlJyF2nGN",
    "outputId": "93f7b3e3-8165-4dc8-d40c-579225a8aa33"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "acc, loss = testing(mnist_mlp_non_iid_trained, mnist_data_test, 128, criterion, num_classes, classes_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1W5krYcSMQiu"
   },
   "outputs": [],
   "source": [
    "hyperparams = {'rounds': rounds,\n",
    "               'C': C,\n",
    "               'K': K,\n",
    "               'E': E,\n",
    "               'batch_size': batch_size,\n",
    "               'lr': lr,\n",
    "               }\n",
    "\n",
    "log_dict['MNIST MLP on Non IID'] = {'train_loss': train_loss_multiple_runs, \n",
    "                                'test_loss': test_loss_multiple_runs, \n",
    "                                'test_accuracy': test_accuracy_multiple_runs,\n",
    "                                'hyperparams': hyperparams,\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emS_SaRAP6TZ"
   },
   "source": [
    "## Pickle Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soAN38JoP0c1"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open(path + 'Local_Round_FedAvg_1.pkl', 'wb') as file:\n",
    "  pickle.dump(log_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UBy-JswSoCJ",
    "outputId": "13b2bc77-3443-45b3-ee10-9e2265548afa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MNIST CNN on IID': {'hyperparams': {'C': 0.1,\n",
       "   'E': 1,\n",
       "   'K': 100,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.05,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[86.32911392405063,\n",
       "    93.41772151898734,\n",
       "    95.9493670886076,\n",
       "    96.20253164556962,\n",
       "    96.20253164556962,\n",
       "    96.70886075949367,\n",
       "    96.9620253164557,\n",
       "    97.72151898734177,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177,\n",
       "    98.10126582278481,\n",
       "    98.10126582278481,\n",
       "    98.48101265822785,\n",
       "    98.48101265822785,\n",
       "    98.73417721518987,\n",
       "    98.35443037974683,\n",
       "    98.60759493670886,\n",
       "    98.73417721518987,\n",
       "    98.86075949367088,\n",
       "    98.86075949367088,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    98.9873417721519,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.49367088607595,\n",
       "    99.24050632911393,\n",
       "    98.9873417721519,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393],\n",
       "   [88.48101265822785,\n",
       "    94.30379746835443,\n",
       "    95.18987341772151,\n",
       "    96.58227848101266,\n",
       "    96.83544303797468,\n",
       "    96.9620253164557,\n",
       "    97.0886075949367,\n",
       "    97.46835443037975,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177,\n",
       "    98.35443037974683,\n",
       "    98.22784810126582,\n",
       "    98.86075949367088,\n",
       "    98.60759493670886,\n",
       "    98.60759493670886,\n",
       "    98.35443037974683,\n",
       "    98.35443037974683,\n",
       "    98.86075949367088,\n",
       "    98.60759493670886,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    98.60759493670886,\n",
       "    98.35443037974683,\n",
       "    99.24050632911393,\n",
       "    98.86075949367088,\n",
       "    98.73417721518987,\n",
       "    98.73417721518987,\n",
       "    99.11392405063292,\n",
       "    98.73417721518987,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    98.9873417721519,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    98.9873417721519,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393],\n",
       "   [88.86075949367088,\n",
       "    94.68354430379746,\n",
       "    95.9493670886076,\n",
       "    96.07594936708861,\n",
       "    96.9620253164557,\n",
       "    97.34177215189874,\n",
       "    97.34177215189874,\n",
       "    97.9746835443038,\n",
       "    98.22784810126582,\n",
       "    98.48101265822785,\n",
       "    98.48101265822785,\n",
       "    98.48101265822785,\n",
       "    98.48101265822785,\n",
       "    98.60759493670886,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    98.86075949367088,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.62025316455696],\n",
       "   [83.79746835443038,\n",
       "    94.68354430379746,\n",
       "    95.44303797468355,\n",
       "    96.45569620253164,\n",
       "    97.0886075949367,\n",
       "    97.72151898734177,\n",
       "    96.9620253164557,\n",
       "    97.59493670886076,\n",
       "    97.59493670886076,\n",
       "    98.10126582278481,\n",
       "    97.9746835443038,\n",
       "    97.84810126582279,\n",
       "    98.22784810126582,\n",
       "    98.73417721518987,\n",
       "    98.86075949367088,\n",
       "    98.60759493670886,\n",
       "    98.73417721518987,\n",
       "    98.48101265822785,\n",
       "    98.73417721518987,\n",
       "    99.11392405063292,\n",
       "    98.86075949367088,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    98.9873417721519,\n",
       "    99.36708860759494,\n",
       "    98.86075949367088,\n",
       "    98.9873417721519,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.36708860759494,\n",
       "    99.49367088607595,\n",
       "    99.62025316455696,\n",
       "    99.49367088607595,\n",
       "    99.49367088607595,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494],\n",
       "   [88.48101265822785,\n",
       "    94.68354430379746,\n",
       "    97.0886075949367,\n",
       "    96.58227848101266,\n",
       "    96.45569620253164,\n",
       "    97.21518987341773,\n",
       "    97.0886075949367,\n",
       "    97.59493670886076,\n",
       "    97.84810126582279,\n",
       "    97.9746835443038,\n",
       "    98.60759493670886,\n",
       "    98.10126582278481,\n",
       "    98.60759493670886,\n",
       "    98.22784810126582,\n",
       "    98.86075949367088,\n",
       "    98.86075949367088,\n",
       "    98.48101265822785,\n",
       "    98.86075949367088,\n",
       "    98.9873417721519,\n",
       "    98.60759493670886,\n",
       "    98.73417721518987,\n",
       "    98.73417721518987,\n",
       "    98.86075949367088,\n",
       "    99.11392405063292,\n",
       "    98.9873417721519,\n",
       "    99.11392405063292,\n",
       "    98.86075949367088,\n",
       "    99.11392405063292,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    98.86075949367088,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.36708860759494,\n",
       "    99.24050632911393,\n",
       "    99.11392405063292,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393,\n",
       "    99.24050632911393]],\n",
       "  'test_loss': [[0.732213876247406,\n",
       "    0.2528602949857712,\n",
       "    0.17569891424179077,\n",
       "    0.12739581908583641,\n",
       "    0.102930496519804,\n",
       "    0.09136834254711866,\n",
       "    0.08282769587375223,\n",
       "    0.07827060376852751,\n",
       "    0.06760769111141562,\n",
       "    0.06287362762391567,\n",
       "    0.05856353202797473,\n",
       "    0.05354615826830268,\n",
       "    0.050833836602419614,\n",
       "    0.04829212408605963,\n",
       "    0.04539406486004591,\n",
       "    0.043892595319449904,\n",
       "    0.04262082140780985,\n",
       "    0.03967697779741138,\n",
       "    0.0363758789954707,\n",
       "    0.037938657095842064,\n",
       "    0.03950637445524335,\n",
       "    0.035426581649947914,\n",
       "    0.03636340023539961,\n",
       "    0.03415479813739657,\n",
       "    0.033910951763484624,\n",
       "    0.03305423417417332,\n",
       "    0.03323498502494767,\n",
       "    0.03120813807696104,\n",
       "    0.03031658410625532,\n",
       "    0.029332168352324516,\n",
       "    0.03043660163190216,\n",
       "    0.029762310311710463,\n",
       "    0.03164850054429844,\n",
       "    0.029639970740536228,\n",
       "    0.02904187107607722,\n",
       "    0.027613206487591378,\n",
       "    0.032035279489099046,\n",
       "    0.02707889918363653,\n",
       "    0.026528016996802763,\n",
       "    0.027219751877197995,\n",
       "    0.02684283512928523,\n",
       "    0.025396615640912206,\n",
       "    0.024745172380423175,\n",
       "    0.02457270965462085,\n",
       "    0.026157609982322902,\n",
       "    0.026369434356875717,\n",
       "    0.025128657560888678,\n",
       "    0.02537442869360093,\n",
       "    0.024749995774403215,\n",
       "    0.02398238316148054],\n",
       "   [0.6710576662063599,\n",
       "    0.24615077719688416,\n",
       "    0.16129530194997788,\n",
       "    0.1284183256626129,\n",
       "    0.1051930244922638,\n",
       "    0.0935306711256504,\n",
       "    0.0886055321726948,\n",
       "    0.07438486964888871,\n",
       "    0.07118663981910794,\n",
       "    0.06553639547917992,\n",
       "    0.06651991347577423,\n",
       "    0.06084139669174329,\n",
       "    0.05980719902776182,\n",
       "    0.05766538369078189,\n",
       "    0.05233909647613764,\n",
       "    0.047658843384310604,\n",
       "    0.048721274685673416,\n",
       "    0.04704823133544996,\n",
       "    0.04574517085589468,\n",
       "    0.04353976181317121,\n",
       "    0.04245050864862278,\n",
       "    0.041506224388908594,\n",
       "    0.03931387369832955,\n",
       "    0.038725740429013965,\n",
       "    0.03908598566539585,\n",
       "    0.04131076235282235,\n",
       "    0.036865643232595176,\n",
       "    0.03701808553789742,\n",
       "    0.034740206536464396,\n",
       "    0.0347122552451212,\n",
       "    0.03346300504244864,\n",
       "    0.03386653711302206,\n",
       "    0.03384250589422882,\n",
       "    0.03393272753749043,\n",
       "    0.03184957767096348,\n",
       "    0.03376398700505961,\n",
       "    0.0329958818102954,\n",
       "    0.03273363410271704,\n",
       "    0.03168543038070202,\n",
       "    0.03054861401831731,\n",
       "    0.031776298920577394,\n",
       "    0.029719852067623287,\n",
       "    0.029243455775408073,\n",
       "    0.029257109377579762,\n",
       "    0.028696931935206522,\n",
       "    0.02732786961346865,\n",
       "    0.02935528236851096,\n",
       "    0.02798555538316723,\n",
       "    0.02779484577262774,\n",
       "    0.02724153535978403],\n",
       "   [0.7947073181152344,\n",
       "    0.23964568586349488,\n",
       "    0.15175047401189803,\n",
       "    0.1163559900969267,\n",
       "    0.09621315111964941,\n",
       "    0.08453606680855155,\n",
       "    0.07402350914441048,\n",
       "    0.06915339862778783,\n",
       "    0.0662589471898973,\n",
       "    0.05709021564349532,\n",
       "    0.05346394639164209,\n",
       "    0.05270887115560472,\n",
       "    0.05271275653578341,\n",
       "    0.04704617139361799,\n",
       "    0.047493253990914676,\n",
       "    0.041905228679813444,\n",
       "    0.041477568566426634,\n",
       "    0.04002849610447884,\n",
       "    0.039580303462222216,\n",
       "    0.03875726553415879,\n",
       "    0.036096799604594706,\n",
       "    0.03729311455581337,\n",
       "    0.03700441329497844,\n",
       "    0.0340236026821658,\n",
       "    0.034705713635124265,\n",
       "    0.031780831025261434,\n",
       "    0.032343995835492384,\n",
       "    0.03199751813774929,\n",
       "    0.03270726821091957,\n",
       "    0.03234575225855224,\n",
       "    0.030890082681924103,\n",
       "    0.03160973076545633,\n",
       "    0.0312770058942493,\n",
       "    0.03117228567842394,\n",
       "    0.02933050905689597,\n",
       "    0.027790491392975673,\n",
       "    0.02771175377466716,\n",
       "    0.026448013722524047,\n",
       "    0.027946037619770506,\n",
       "    0.026668201013747603,\n",
       "    0.025722341655846685,\n",
       "    0.027093241720064543,\n",
       "    0.02680916624041274,\n",
       "    0.025264631877071224,\n",
       "    0.02594348196417559,\n",
       "    0.027217056902032345,\n",
       "    0.025626148949819617,\n",
       "    0.024415937677957116,\n",
       "    0.0254112784340512,\n",
       "    0.023657652212399988],\n",
       "   [0.6786388189315796,\n",
       "    0.24672067351341248,\n",
       "    0.15782542639374733,\n",
       "    0.12473701702952385,\n",
       "    0.10879613683968782,\n",
       "    0.093886640766263,\n",
       "    0.0798725652128458,\n",
       "    0.07491215179041028,\n",
       "    0.06995962939076125,\n",
       "    0.0648882329236716,\n",
       "    0.05986150997523219,\n",
       "    0.06111882462445647,\n",
       "    0.05339369499795139,\n",
       "    0.0494390328405425,\n",
       "    0.04752113407710567,\n",
       "    0.047088265518844125,\n",
       "    0.04696486185956746,\n",
       "    0.048976266853511335,\n",
       "    0.043683868928439916,\n",
       "    0.04039329295307398,\n",
       "    0.04285345456041396,\n",
       "    0.04105965649941936,\n",
       "    0.03835913807051256,\n",
       "    0.037517333444580435,\n",
       "    0.03697943599987775,\n",
       "    0.035687520436011255,\n",
       "    0.036798458999674766,\n",
       "    0.03441997224171646,\n",
       "    0.03243552706576884,\n",
       "    0.03370219580456615,\n",
       "    0.03310956236254424,\n",
       "    0.03268487143767997,\n",
       "    0.03387023815615103,\n",
       "    0.031080229474045335,\n",
       "    0.03231782980510034,\n",
       "    0.031192255474533886,\n",
       "    0.028929113930044697,\n",
       "    0.028689713438297623,\n",
       "    0.02850004904731177,\n",
       "    0.028320532559091224,\n",
       "    0.028133916489826515,\n",
       "    0.026965213833702727,\n",
       "    0.027531401479896158,\n",
       "    0.02759201382645406,\n",
       "    0.02728561329115182,\n",
       "    0.027145473329909145,\n",
       "    0.02745418297792785,\n",
       "    0.025901202557981014,\n",
       "    0.02618364549856633,\n",
       "    0.025618540487764404],\n",
       "   [0.5806490686416625,\n",
       "    0.22332627470493316,\n",
       "    0.15046968309879302,\n",
       "    0.1158504021346569,\n",
       "    0.10566404905319214,\n",
       "    0.09019190056920051,\n",
       "    0.08060528420582413,\n",
       "    0.06864267572723329,\n",
       "    0.0668052779391408,\n",
       "    0.06427662073299288,\n",
       "    0.0637411715745926,\n",
       "    0.0529457297835499,\n",
       "    0.05457878766059875,\n",
       "    0.048464174070954325,\n",
       "    0.048421068164333704,\n",
       "    0.04536029581259936,\n",
       "    0.04490549864852801,\n",
       "    0.041104947446100416,\n",
       "    0.041617556889727715,\n",
       "    0.039492632147856054,\n",
       "    0.03943681693701073,\n",
       "    0.040033094470016656,\n",
       "    0.043601818503718824,\n",
       "    0.03635678875837475,\n",
       "    0.03693937376178801,\n",
       "    0.035780828521214426,\n",
       "    0.036187758892960845,\n",
       "    0.03223601871337742,\n",
       "    0.032375959485769275,\n",
       "    0.032448543171212076,\n",
       "    0.030361547273769975,\n",
       "    0.03091125958110206,\n",
       "    0.029786538601573556,\n",
       "    0.031216182973980905,\n",
       "    0.03048425064748153,\n",
       "    0.029685017500072717,\n",
       "    0.029885432352684437,\n",
       "    0.027627859910018742,\n",
       "    0.028091303079295905,\n",
       "    0.02744834739668295,\n",
       "    0.0284476108931005,\n",
       "    0.029361342107644305,\n",
       "    0.02708521521096118,\n",
       "    0.027315198582969605,\n",
       "    0.02806484944568947,\n",
       "    0.026528861726634205,\n",
       "    0.026743753408640623,\n",
       "    0.025288678751839325,\n",
       "    0.025062356256507337,\n",
       "    0.02495790458493866]],\n",
       "  'train_loss': [[1.4411240097135305,\n",
       "    0.5690949102801582,\n",
       "    0.3905034786951728,\n",
       "    0.2775783813661352,\n",
       "    0.2167166739225892,\n",
       "    0.20334475503729968,\n",
       "    0.1662146739056334,\n",
       "    0.1716772645172508,\n",
       "    0.15644556409999497,\n",
       "    0.12575930608569857,\n",
       "    0.11970618856107951,\n",
       "    0.12401812376224068,\n",
       "    0.09420629916855736,\n",
       "    0.12189035025114814,\n",
       "    0.10288200843966477,\n",
       "    0.0994495486379795,\n",
       "    0.09824579313496845,\n",
       "    0.08966270370913357,\n",
       "    0.0677093338221433,\n",
       "    0.08638203597352913,\n",
       "    0.08519878287941235,\n",
       "    0.08232273603464516,\n",
       "    0.06511075626249901,\n",
       "    0.07492402569938048,\n",
       "    0.07443528519716588,\n",
       "    0.06407417834800677,\n",
       "    0.08101788907957296,\n",
       "    0.06520044846535106,\n",
       "    0.06454913638393615,\n",
       "    0.060929038107287836,\n",
       "    0.06318861340909127,\n",
       "    0.05981399046100706,\n",
       "    0.060166737667711155,\n",
       "    0.07908577229815743,\n",
       "    0.047407053424575074,\n",
       "    0.04007835294974863,\n",
       "    0.050686963736128146,\n",
       "    0.04882848395790461,\n",
       "    0.05464524815498636,\n",
       "    0.056252089267560826,\n",
       "    0.05058860790861748,\n",
       "    0.04820815020550981,\n",
       "    0.04460208114979537,\n",
       "    0.039870222962952846,\n",
       "    0.062072319332223735,\n",
       "    0.05065155535495099,\n",
       "    0.04990975034860942,\n",
       "    0.03508504377621193,\n",
       "    0.04243779424469115,\n",
       "    0.041129065064181604],\n",
       "   [1.4352035397539535,\n",
       "    0.5841812201620391,\n",
       "    0.3354450503467039,\n",
       "    0.2899972521758173,\n",
       "    0.22039999610822028,\n",
       "    0.1964422844312018,\n",
       "    0.18899801912363426,\n",
       "    0.1521984668026562,\n",
       "    0.15271716860641993,\n",
       "    0.13866967222694557,\n",
       "    0.14032218959003026,\n",
       "    0.13240643911696678,\n",
       "    0.10851735192006648,\n",
       "    0.1275652432416488,\n",
       "    0.10374335760700584,\n",
       "    0.10205534966871103,\n",
       "    0.10696884998335007,\n",
       "    0.08794398566644909,\n",
       "    0.0959970343521915,\n",
       "    0.08821765682833453,\n",
       "    0.09444518748168168,\n",
       "    0.07603183629429623,\n",
       "    0.07231916655427995,\n",
       "    0.07135946071476915,\n",
       "    0.07848441426511273,\n",
       "    0.07776007203494979,\n",
       "    0.06839387440276672,\n",
       "    0.06282189484415238,\n",
       "    0.07456078299438255,\n",
       "    0.07528714353047991,\n",
       "    0.05452834156693218,\n",
       "    0.06648194450349063,\n",
       "    0.06907333645992669,\n",
       "    0.06029837324303723,\n",
       "    0.06023706859590069,\n",
       "    0.051252436745453454,\n",
       "    0.06086046420268606,\n",
       "    0.048604548268191744,\n",
       "    0.06150765870182719,\n",
       "    0.04854045210072854,\n",
       "    0.055783804927089786,\n",
       "    0.06059416285381304,\n",
       "    0.04295893919397031,\n",
       "    0.06520102367755498,\n",
       "    0.048887659876872935,\n",
       "    0.03565356613573385,\n",
       "    0.05605607568094456,\n",
       "    0.03765853910438031,\n",
       "    0.04000981906967353,\n",
       "    0.048069884316907216],\n",
       "   [1.4326269726703562,\n",
       "    0.5621489561613029,\n",
       "    0.33806426970365766,\n",
       "    0.2796316170296632,\n",
       "    0.225636906871805,\n",
       "    0.19539406927729336,\n",
       "    0.15611950482916048,\n",
       "    0.13973582026730585,\n",
       "    0.1436504900052508,\n",
       "    0.12981573661071405,\n",
       "    0.1310842119112931,\n",
       "    0.11652475387076264,\n",
       "    0.11627336480408605,\n",
       "    0.10725144779712234,\n",
       "    0.10184888037849305,\n",
       "    0.10663458488957378,\n",
       "    0.10152681426601098,\n",
       "    0.10770590946405718,\n",
       "    0.08173275185852616,\n",
       "    0.08894930462510578,\n",
       "    0.08114758615692456,\n",
       "    0.08706060478510456,\n",
       "    0.07895468649772283,\n",
       "    0.06500041348503449,\n",
       "    0.08631198781552787,\n",
       "    0.060393039603350185,\n",
       "    0.06580812254879372,\n",
       "    0.06874129961245065,\n",
       "    0.06605564499412442,\n",
       "    0.06374614356046548,\n",
       "    0.05569521814693871,\n",
       "    0.05364543926717184,\n",
       "    0.06002055669104114,\n",
       "    0.05886823277693944,\n",
       "    0.06979551884534886,\n",
       "    0.03861547745967377,\n",
       "    0.05981023818941746,\n",
       "    0.04435911360937704,\n",
       "    0.05103104244688136,\n",
       "    0.0542595289817124,\n",
       "    0.04672673596104081,\n",
       "    0.049384027515642026,\n",
       "    0.04397239885464236,\n",
       "    0.03889754572754404,\n",
       "    0.03695301823041064,\n",
       "    0.04214864789547846,\n",
       "    0.03670370238948143,\n",
       "    0.038606461183265994,\n",
       "    0.05911574992452869,\n",
       "    0.03134147595354535],\n",
       "   [1.3440623221422237,\n",
       "    0.5515306900783132,\n",
       "    0.3490284794706774,\n",
       "    0.2787884105553773,\n",
       "    0.24113292364015554,\n",
       "    0.20683347987855086,\n",
       "    0.1677319593015515,\n",
       "    0.1560897307409323,\n",
       "    0.13173473672446562,\n",
       "    0.14721354448088583,\n",
       "    0.12737468109036854,\n",
       "    0.12506245719094294,\n",
       "    0.11755678630497035,\n",
       "    0.10324684751178818,\n",
       "    0.09381039385357628,\n",
       "    0.10505859631828571,\n",
       "    0.09453375229057807,\n",
       "    0.13176076770096795,\n",
       "    0.09104211476090616,\n",
       "    0.08355408398856526,\n",
       "    0.08110616354085624,\n",
       "    0.07455979449300382,\n",
       "    0.0769355570094073,\n",
       "    0.08129371603008621,\n",
       "    0.0680781135853431,\n",
       "    0.07250683325928246,\n",
       "    0.07084975031344433,\n",
       "    0.05777901007986506,\n",
       "    0.06607454704994778,\n",
       "    0.06969612351827285,\n",
       "    0.0631579363099066,\n",
       "    0.07056873952113317,\n",
       "    0.06494563572768432,\n",
       "    0.06109156057307095,\n",
       "    0.05367719747234939,\n",
       "    0.05896760606342771,\n",
       "    0.05900655354378689,\n",
       "    0.046639539368413044,\n",
       "    0.0675062158328304,\n",
       "    0.05482137726702756,\n",
       "    0.05316142779792395,\n",
       "    0.05501417160354928,\n",
       "    0.03489539020896472,\n",
       "    0.05580144053531284,\n",
       "    0.051723617538870406,\n",
       "    0.05025267736723739,\n",
       "    0.03804995924570903,\n",
       "    0.04657933622176188,\n",
       "    0.04937293044877682,\n",
       "    0.04986304332098219],\n",
       "   [1.3581450367470584,\n",
       "    0.5490093580943842,\n",
       "    0.34292099281718647,\n",
       "    0.29102713136623304,\n",
       "    0.22307969279238024,\n",
       "    0.19659392747766108,\n",
       "    0.17605334559688343,\n",
       "    0.1518296879474413,\n",
       "    0.15361986135928116,\n",
       "    0.14637505721048608,\n",
       "    0.13144883994306536,\n",
       "    0.11313938685974186,\n",
       "    0.12142327056924238,\n",
       "    0.11183644163941305,\n",
       "    0.09877326631488056,\n",
       "    0.08255516916770525,\n",
       "    0.10099802966589777,\n",
       "    0.07281107996130232,\n",
       "    0.10743074750703574,\n",
       "    0.07925417679735498,\n",
       "    0.08825815353743262,\n",
       "    0.07488981505567607,\n",
       "    0.06766246050753276,\n",
       "    0.06933453662238813,\n",
       "    0.07757651273735368,\n",
       "    0.06476008120200884,\n",
       "    0.06579574351168806,\n",
       "    0.07032351565563053,\n",
       "    0.06499350257923651,\n",
       "    0.04993038464607101,\n",
       "    0.07524116004440203,\n",
       "    0.04971555616461956,\n",
       "    0.05989704662170879,\n",
       "    0.06190329302688193,\n",
       "    0.0594795290967022,\n",
       "    0.06224284881987842,\n",
       "    0.05837170739810214,\n",
       "    0.05252358653334037,\n",
       "    0.05323945625188723,\n",
       "    0.04453494061807608,\n",
       "    0.04497396803984581,\n",
       "    0.054041027822850085,\n",
       "    0.03666504532973704,\n",
       "    0.04492778109434662,\n",
       "    0.04943685246154095,\n",
       "    0.05527844322961452,\n",
       "    0.043224653857250814,\n",
       "    0.06267943701299676,\n",
       "    0.04142063257509411,\n",
       "    0.037185913679121926]]},\n",
       " 'MNIST CNN on Non IID': {'hyperparams': {'C': 0.1,\n",
       "   'E': 1,\n",
       "   'K': 100,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.05,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[26.835443037974684,\n",
       "    53.79746835443038,\n",
       "    55.949367088607595,\n",
       "    65.56962025316456,\n",
       "    87.46835443037975,\n",
       "    82.15189873417721,\n",
       "    81.64556962025317,\n",
       "    81.89873417721519,\n",
       "    83.67088607594937,\n",
       "    92.15189873417721,\n",
       "    82.9113924050633,\n",
       "    93.0379746835443,\n",
       "    94.55696202531645,\n",
       "    95.82278481012658,\n",
       "    92.27848101265823,\n",
       "    92.40506329113924,\n",
       "    94.30379746835443,\n",
       "    95.82278481012658,\n",
       "    93.92405063291139,\n",
       "    96.20253164556962,\n",
       "    96.58227848101266,\n",
       "    95.9493670886076,\n",
       "    95.31645569620254,\n",
       "    96.58227848101266,\n",
       "    95.9493670886076,\n",
       "    93.41772151898734,\n",
       "    96.70886075949367,\n",
       "    96.58227848101266,\n",
       "    96.9620253164557,\n",
       "    94.0506329113924,\n",
       "    96.20253164556962,\n",
       "    97.0886075949367,\n",
       "    94.17721518987342,\n",
       "    95.56962025316456,\n",
       "    95.56962025316456,\n",
       "    97.34177215189874,\n",
       "    96.70886075949367,\n",
       "    97.59493670886076,\n",
       "    98.10126582278481,\n",
       "    98.10126582278481,\n",
       "    97.59493670886076,\n",
       "    98.35443037974683,\n",
       "    96.20253164556962,\n",
       "    93.0379746835443,\n",
       "    97.84810126582279,\n",
       "    98.73417721518987,\n",
       "    98.48101265822785,\n",
       "    98.10126582278481,\n",
       "    97.34177215189874,\n",
       "    98.35443037974683],\n",
       "   [18.354430379746834,\n",
       "    38.10126582278481,\n",
       "    53.164556962025316,\n",
       "    54.81012658227848,\n",
       "    78.35443037974683,\n",
       "    80.12658227848101,\n",
       "    84.81012658227849,\n",
       "    90.0,\n",
       "    88.48101265822785,\n",
       "    93.41772151898734,\n",
       "    90.37974683544304,\n",
       "    89.87341772151899,\n",
       "    89.49367088607595,\n",
       "    93.41772151898734,\n",
       "    90.75949367088607,\n",
       "    93.41772151898734,\n",
       "    94.81012658227849,\n",
       "    94.68354430379746,\n",
       "    93.0379746835443,\n",
       "    93.29113924050633,\n",
       "    94.68354430379746,\n",
       "    95.31645569620254,\n",
       "    92.53164556962025,\n",
       "    92.53164556962025,\n",
       "    96.32911392405063,\n",
       "    96.20253164556962,\n",
       "    97.21518987341773,\n",
       "    95.9493670886076,\n",
       "    96.58227848101266,\n",
       "    97.0886075949367,\n",
       "    97.21518987341773,\n",
       "    97.0886075949367,\n",
       "    97.21518987341773,\n",
       "    96.83544303797468,\n",
       "    97.34177215189874,\n",
       "    97.21518987341773,\n",
       "    96.70886075949367,\n",
       "    98.48101265822785,\n",
       "    98.35443037974683,\n",
       "    97.72151898734177,\n",
       "    98.35443037974683,\n",
       "    97.84810126582279,\n",
       "    98.48101265822785,\n",
       "    98.10126582278481,\n",
       "    98.48101265822785,\n",
       "    97.9746835443038,\n",
       "    97.72151898734177,\n",
       "    97.34177215189874,\n",
       "    97.84810126582279,\n",
       "    97.34177215189874],\n",
       "   [19.240506329113924,\n",
       "    17.088607594936708,\n",
       "    48.734177215189874,\n",
       "    61.64556962025316,\n",
       "    69.74683544303798,\n",
       "    84.81012658227849,\n",
       "    82.15189873417721,\n",
       "    84.17721518987342,\n",
       "    90.37974683544304,\n",
       "    76.45569620253164,\n",
       "    91.77215189873418,\n",
       "    91.0126582278481,\n",
       "    94.17721518987342,\n",
       "    93.41772151898734,\n",
       "    92.9113924050633,\n",
       "    94.0506329113924,\n",
       "    95.44303797468355,\n",
       "    94.43037974683544,\n",
       "    96.45569620253164,\n",
       "    95.0632911392405,\n",
       "    95.18987341772151,\n",
       "    95.44303797468355,\n",
       "    96.20253164556962,\n",
       "    95.82278481012658,\n",
       "    96.9620253164557,\n",
       "    96.83544303797468,\n",
       "    96.70886075949367,\n",
       "    97.21518987341773,\n",
       "    97.72151898734177,\n",
       "    97.0886075949367,\n",
       "    96.20253164556962,\n",
       "    96.45569620253164,\n",
       "    97.34177215189874,\n",
       "    97.46835443037975,\n",
       "    97.21518987341773,\n",
       "    97.72151898734177,\n",
       "    97.9746835443038,\n",
       "    97.21518987341773,\n",
       "    97.84810126582279,\n",
       "    97.46835443037975,\n",
       "    96.45569620253164,\n",
       "    95.44303797468355,\n",
       "    98.35443037974683,\n",
       "    98.22784810126582,\n",
       "    98.22784810126582,\n",
       "    97.84810126582279,\n",
       "    97.84810126582279,\n",
       "    97.59493670886076,\n",
       "    98.48101265822785,\n",
       "    98.60759493670886],\n",
       "   [28.860759493670887,\n",
       "    38.10126582278481,\n",
       "    46.20253164556962,\n",
       "    61.64556962025316,\n",
       "    77.34177215189874,\n",
       "    77.0886075949367,\n",
       "    82.27848101265823,\n",
       "    84.30379746835443,\n",
       "    87.0886075949367,\n",
       "    94.30379746835443,\n",
       "    93.67088607594937,\n",
       "    93.29113924050633,\n",
       "    86.07594936708861,\n",
       "    92.53164556962025,\n",
       "    92.9113924050633,\n",
       "    95.18987341772151,\n",
       "    96.32911392405063,\n",
       "    94.9367088607595,\n",
       "    94.17721518987342,\n",
       "    96.07594936708861,\n",
       "    95.9493670886076,\n",
       "    96.83544303797468,\n",
       "    95.0632911392405,\n",
       "    94.9367088607595,\n",
       "    96.58227848101266,\n",
       "    94.17721518987342,\n",
       "    96.70886075949367,\n",
       "    97.59493670886076,\n",
       "    97.46835443037975,\n",
       "    97.46835443037975,\n",
       "    95.82278481012658,\n",
       "    96.45569620253164,\n",
       "    96.70886075949367,\n",
       "    96.32911392405063,\n",
       "    97.34177215189874,\n",
       "    97.0886075949367,\n",
       "    97.21518987341773,\n",
       "    96.70886075949367,\n",
       "    97.34177215189874,\n",
       "    98.10126582278481,\n",
       "    97.34177215189874,\n",
       "    96.32911392405063,\n",
       "    97.84810126582279,\n",
       "    98.73417721518987,\n",
       "    98.35443037974683,\n",
       "    97.72151898734177,\n",
       "    97.9746835443038,\n",
       "    97.46835443037975,\n",
       "    98.35443037974683,\n",
       "    98.35443037974683],\n",
       "   [16.70886075949367,\n",
       "    24.17721518987342,\n",
       "    38.9873417721519,\n",
       "    51.392405063291136,\n",
       "    65.18987341772151,\n",
       "    78.73417721518987,\n",
       "    73.67088607594937,\n",
       "    62.53164556962025,\n",
       "    70.0,\n",
       "    79.74683544303798,\n",
       "    77.9746835443038,\n",
       "    86.45569620253164,\n",
       "    89.24050632911393,\n",
       "    84.55696202531645,\n",
       "    89.11392405063292,\n",
       "    77.34177215189874,\n",
       "    88.60759493670886,\n",
       "    92.0253164556962,\n",
       "    84.43037974683544,\n",
       "    86.07594936708861,\n",
       "    85.44303797468355,\n",
       "    82.15189873417721,\n",
       "    95.44303797468355,\n",
       "    89.87341772151899,\n",
       "    95.44303797468355,\n",
       "    93.16455696202532,\n",
       "    94.0506329113924,\n",
       "    92.0253164556962,\n",
       "    91.64556962025317,\n",
       "    85.9493670886076,\n",
       "    95.9493670886076,\n",
       "    95.18987341772151,\n",
       "    95.56962025316456,\n",
       "    95.69620253164557,\n",
       "    96.20253164556962,\n",
       "    96.70886075949367,\n",
       "    94.81012658227849,\n",
       "    92.65822784810126,\n",
       "    94.81012658227849,\n",
       "    97.21518987341773,\n",
       "    96.58227848101266,\n",
       "    96.9620253164557,\n",
       "    97.9746835443038,\n",
       "    96.07594936708861,\n",
       "    96.70886075949367,\n",
       "    97.0886075949367,\n",
       "    97.46835443037975,\n",
       "    94.55696202531645,\n",
       "    96.9620253164557,\n",
       "    96.58227848101266]],\n",
       "  'test_loss': [[2.217373553085327,\n",
       "    1.953511241531372,\n",
       "    1.3530123622894288,\n",
       "    1.1224855712890625,\n",
       "    0.7820776170730591,\n",
       "    0.6060308304786682,\n",
       "    0.5826836762428284,\n",
       "    0.5259273274898529,\n",
       "    0.5755107960700989,\n",
       "    0.36230703315734863,\n",
       "    0.4990488012313843,\n",
       "    0.2823302066087723,\n",
       "    0.23249050657749176,\n",
       "    0.20722182079553605,\n",
       "    0.2719706702709198,\n",
       "    0.236826713514328,\n",
       "    0.22289035942554475,\n",
       "    0.1561817893922329,\n",
       "    0.18176068112850188,\n",
       "    0.14416036890149117,\n",
       "    0.13263474312424658,\n",
       "    0.14351122019290924,\n",
       "    0.15064832091331481,\n",
       "    0.13505618782639503,\n",
       "    0.15909312739372253,\n",
       "    0.21635766764879227,\n",
       "    0.11125009226500988,\n",
       "    0.10415267666578293,\n",
       "    0.11947923138439655,\n",
       "    0.14269307921528815,\n",
       "    0.11644815369397402,\n",
       "    0.10396780254915357,\n",
       "    0.15947347458302974,\n",
       "    0.1299904538601637,\n",
       "    0.1283308613717556,\n",
       "    0.08650177572965621,\n",
       "    0.12416405505239964,\n",
       "    0.09330938657522202,\n",
       "    0.0892168793708086,\n",
       "    0.08822577052414417,\n",
       "    0.07995663224905729,\n",
       "    0.08170783113315702,\n",
       "    0.11144510329961776,\n",
       "    0.15390857654809953,\n",
       "    0.08494835439771414,\n",
       "    0.06910978295207024,\n",
       "    0.07197297655269504,\n",
       "    0.0767594253897667,\n",
       "    0.0838975662201643,\n",
       "    0.0768037924848497],\n",
       "   [2.2014097595214843,\n",
       "    1.9845489017486573,\n",
       "    1.4750117820739745,\n",
       "    1.2596212717056274,\n",
       "    0.856656977558136,\n",
       "    0.5860360295772552,\n",
       "    0.49131239676475524,\n",
       "    0.3817214783191681,\n",
       "    0.3966929011821747,\n",
       "    0.29229177434444426,\n",
       "    0.2961620071411133,\n",
       "    0.28242393877506256,\n",
       "    0.2866630905508995,\n",
       "    0.23892047177553177,\n",
       "    0.27852273697853086,\n",
       "    0.2106800861477852,\n",
       "    0.17648052466511727,\n",
       "    0.183214792406559,\n",
       "    0.18450938098430633,\n",
       "    0.1704238438308239,\n",
       "    0.1585337678551674,\n",
       "    0.16890360913276672,\n",
       "    0.18058836730718614,\n",
       "    0.195784426009655,\n",
       "    0.12865160562992095,\n",
       "    0.12335230291485787,\n",
       "    0.10605203388929367,\n",
       "    0.10956752931177616,\n",
       "    0.10691263743937016,\n",
       "    0.1031645177051425,\n",
       "    0.10049096106439828,\n",
       "    0.11032003034949303,\n",
       "    0.08958160314783455,\n",
       "    0.11406169594824314,\n",
       "    0.08306424090713263,\n",
       "    0.097536443041265,\n",
       "    0.10205729162693024,\n",
       "    0.09344386425763368,\n",
       "    0.07309835501685738,\n",
       "    0.07289275761693716,\n",
       "    0.07778666951954365,\n",
       "    0.07490268341302872,\n",
       "    0.06544001518413424,\n",
       "    0.06759098528772592,\n",
       "    0.060705235954374076,\n",
       "    0.06616258231252432,\n",
       "    0.07699210700392724,\n",
       "    0.0809206310801208,\n",
       "    0.06495315135642886,\n",
       "    0.06419542605094612],\n",
       "   [2.2759436630249024,\n",
       "    2.1044812644958495,\n",
       "    1.6070107336044313,\n",
       "    1.128536095237732,\n",
       "    0.9289631056785583,\n",
       "    0.568702561378479,\n",
       "    0.6128485594272614,\n",
       "    0.42452253296375275,\n",
       "    0.3782342525482178,\n",
       "    0.5462854736328125,\n",
       "    0.2959916233539581,\n",
       "    0.2660679519891739,\n",
       "    0.2379051836848259,\n",
       "    0.24281850552558898,\n",
       "    0.2106141463160515,\n",
       "    0.205451909327507,\n",
       "    0.17283368943333627,\n",
       "    0.17888925804495812,\n",
       "    0.15369848309755324,\n",
       "    0.17085910388231276,\n",
       "    0.1515695064008236,\n",
       "    0.1324551995933056,\n",
       "    0.14448436660170555,\n",
       "    0.14245482469797136,\n",
       "    0.12595736821591855,\n",
       "    0.11415978038012982,\n",
       "    0.11912281473875046,\n",
       "    0.10512652372121811,\n",
       "    0.09565238238573075,\n",
       "    0.10033983799815178,\n",
       "    0.11651965961456298,\n",
       "    0.11969263771921396,\n",
       "    0.09529733700454235,\n",
       "    0.08634371250942349,\n",
       "    0.09186452523469925,\n",
       "    0.0768561239168048,\n",
       "    0.07772966520860791,\n",
       "    0.09057188512682915,\n",
       "    0.0752547103792429,\n",
       "    0.09465536907464266,\n",
       "    0.10143389226645232,\n",
       "    0.13446631162166595,\n",
       "    0.06755995346680284,\n",
       "    0.06675117040276528,\n",
       "    0.07195207898318767,\n",
       "    0.07095374145060777,\n",
       "    0.07450040003508329,\n",
       "    0.0858269905269146,\n",
       "    0.0616582566998899,\n",
       "    0.06739881138950586],\n",
       "   [2.130936070251465,\n",
       "    1.8586596643447877,\n",
       "    1.5527242248535156,\n",
       "    1.1942550716400147,\n",
       "    0.8483009484291076,\n",
       "    0.7300530879020691,\n",
       "    0.5476480293273925,\n",
       "    0.4416256766319275,\n",
       "    0.3734112895011902,\n",
       "    0.2327955472946167,\n",
       "    0.23163275244235992,\n",
       "    0.24706159420013427,\n",
       "    0.3572045873641968,\n",
       "    0.21759245545864106,\n",
       "    0.20397430746555328,\n",
       "    0.1751326155245304,\n",
       "    0.14353815767765046,\n",
       "    0.15107497968673705,\n",
       "    0.15964662914276123,\n",
       "    0.12177877269387245,\n",
       "    0.12946505737900735,\n",
       "    0.12751495259404183,\n",
       "    0.14894964534044267,\n",
       "    0.15270412372350692,\n",
       "    0.1147876314520836,\n",
       "    0.17735084142684937,\n",
       "    0.10162485247552396,\n",
       "    0.10738879604339599,\n",
       "    0.09773307690918445,\n",
       "    0.09380925780385732,\n",
       "    0.1371425109744072,\n",
       "    0.1260951094418764,\n",
       "    0.10594778553843498,\n",
       "    0.1116250096231699,\n",
       "    0.08321701663881541,\n",
       "    0.08962515943944455,\n",
       "    0.08387166316658258,\n",
       "    0.08665429828464985,\n",
       "    0.07793934674263,\n",
       "    0.0675918232616037,\n",
       "    0.06895331148207187,\n",
       "    0.08631254763156175,\n",
       "    0.06695066503733396,\n",
       "    0.06378049840480089,\n",
       "    0.07103721869289875,\n",
       "    0.06695133957043291,\n",
       "    0.05631973070017993,\n",
       "    0.08887361730262637,\n",
       "    0.06804582293629646,\n",
       "    0.0582733031898737],\n",
       "   [2.28722933883667,\n",
       "    1.9272572595596313,\n",
       "    1.8637555643081665,\n",
       "    1.3282385856628418,\n",
       "    1.0866923718452453,\n",
       "    0.6439382639884949,\n",
       "    0.8208716226577759,\n",
       "    0.8698893449783325,\n",
       "    0.7036992312431335,\n",
       "    0.6273023029327393,\n",
       "    0.5749814997673035,\n",
       "    0.3377270082473755,\n",
       "    0.2819006608963013,\n",
       "    0.3516727767467499,\n",
       "    0.3196532428264618,\n",
       "    0.5229375678062439,\n",
       "    0.28312693314552306,\n",
       "    0.24665506024360656,\n",
       "    0.3367545965194702,\n",
       "    0.4042534329414368,\n",
       "    0.4008910208702087,\n",
       "    0.40845030002593996,\n",
       "    0.17834482880830765,\n",
       "    0.22964310364723206,\n",
       "    0.15510762109160423,\n",
       "    0.17774470195770264,\n",
       "    0.16829354457855225,\n",
       "    0.19369624532461166,\n",
       "    0.21228010942935943,\n",
       "    0.3573608067512512,\n",
       "    0.13985746157765389,\n",
       "    0.1523232946753502,\n",
       "    0.12953951109945774,\n",
       "    0.12919689614772797,\n",
       "    0.10824173821508884,\n",
       "    0.10825601578950882,\n",
       "    0.12379818071126938,\n",
       "    0.17567113408744336,\n",
       "    0.13319733006358148,\n",
       "    0.0805709080979228,\n",
       "    0.10778790918886662,\n",
       "    0.0899071628779173,\n",
       "    0.08085014485567808,\n",
       "    0.11445931652784347,\n",
       "    0.10591373765468598,\n",
       "    0.09697842626571655,\n",
       "    0.0781984402090311,\n",
       "    0.1335723430559039,\n",
       "    0.09206519958600402,\n",
       "    0.09135141397938132]],\n",
       "  'train_loss': [[0.4196474202064323,\n",
       "    0.3098697203779428,\n",
       "    0.16495267791365537,\n",
       "    0.10182996108949646,\n",
       "    0.11606734004899691,\n",
       "    0.06972808908854379,\n",
       "    0.08791824509525295,\n",
       "    0.06265522596128106,\n",
       "    0.118294372742541,\n",
       "    0.08451490305942305,\n",
       "    0.05103971622027288,\n",
       "    0.06085156621109149,\n",
       "    0.0540200573670209,\n",
       "    0.060345333646754776,\n",
       "    0.03664102589779702,\n",
       "    0.04299413354024035,\n",
       "    0.06354456591745701,\n",
       "    0.03605929884766558,\n",
       "    0.04200774812041123,\n",
       "    0.03533644834278746,\n",
       "    0.03203408415427835,\n",
       "    0.02693132108988716,\n",
       "    0.04964897387830994,\n",
       "    0.05183157784998158,\n",
       "    0.05142438878997836,\n",
       "    0.03405045402970988,\n",
       "    0.019394689166272912,\n",
       "    0.038172433600050036,\n",
       "    0.030628496680246135,\n",
       "    0.020232661676227656,\n",
       "    0.026077857395821503,\n",
       "    0.025086383574767102,\n",
       "    0.027611455577819216,\n",
       "    0.029276603625101157,\n",
       "    0.038280750421857565,\n",
       "    0.03387249871673525,\n",
       "    0.06216517789930862,\n",
       "    0.03126886564275365,\n",
       "    0.03552419572331716,\n",
       "    0.036198321605788876,\n",
       "    0.030047471607198402,\n",
       "    0.038904451331418545,\n",
       "    0.018282343974537273,\n",
       "    0.04535512596059789,\n",
       "    0.022124707236507526,\n",
       "    0.028499111576112755,\n",
       "    0.023612504809373366,\n",
       "    0.022765384483608632,\n",
       "    0.025449283962542278,\n",
       "    0.024504104333117956],\n",
       "   [0.4079450832386943,\n",
       "    0.3047936858725734,\n",
       "    0.17204872787078304,\n",
       "    0.1165094544646966,\n",
       "    0.12738994305130819,\n",
       "    0.05571215277829861,\n",
       "    0.06505193717168842,\n",
       "    0.07899900659073826,\n",
       "    0.08277965081511227,\n",
       "    0.06518090862477834,\n",
       "    0.07140110268774227,\n",
       "    0.03635608939690978,\n",
       "    0.057353917141019985,\n",
       "    0.06549028396285317,\n",
       "    0.068214653723806,\n",
       "    0.043678539906046754,\n",
       "    0.04642261001852906,\n",
       "    0.07252077843813878,\n",
       "    0.04308629170712024,\n",
       "    0.03107903307399169,\n",
       "    0.03926091208979195,\n",
       "    0.05619912219746552,\n",
       "    0.044013902423698334,\n",
       "    0.046290240996130286,\n",
       "    0.042577449574320365,\n",
       "    0.034758253350135285,\n",
       "    0.05810592373056049,\n",
       "    0.024380284153878478,\n",
       "    0.0380152595375543,\n",
       "    0.0325103471196596,\n",
       "    0.05585396531445781,\n",
       "    0.0282443028488845,\n",
       "    0.030119603264058603,\n",
       "    0.023054258112040968,\n",
       "    0.03555916795766204,\n",
       "    0.02928838761582201,\n",
       "    0.0416699125909523,\n",
       "    0.05044230644283174,\n",
       "    0.03255804409004563,\n",
       "    0.03055436647251819,\n",
       "    0.041205093654486345,\n",
       "    0.02198060230837465,\n",
       "    0.02284980956998555,\n",
       "    0.023312658124059527,\n",
       "    0.02315486544918053,\n",
       "    0.031301477413400725,\n",
       "    0.03319221105043095,\n",
       "    0.04519049448046035,\n",
       "    0.03616890932917436,\n",
       "    0.012908880099786066],\n",
       "   [0.5209968171512938,\n",
       "    0.28998086695983327,\n",
       "    0.1892904014361011,\n",
       "    0.15260597439111584,\n",
       "    0.1228818968815252,\n",
       "    0.07551263408695864,\n",
       "    0.08829856905568173,\n",
       "    0.04557606832486505,\n",
       "    0.07852414079859849,\n",
       "    0.04745800378741336,\n",
       "    0.08150809604175606,\n",
       "    0.062212479903372274,\n",
       "    0.05824712725655331,\n",
       "    0.07138195097654337,\n",
       "    0.045932301969454595,\n",
       "    0.05757930807388598,\n",
       "    0.06012492111429389,\n",
       "    0.06580955286054055,\n",
       "    0.04002380664787892,\n",
       "    0.07109360500048695,\n",
       "    0.04232365677435324,\n",
       "    0.03444849481802134,\n",
       "    0.057570475079535666,\n",
       "    0.04164449480743619,\n",
       "    0.04690486642385869,\n",
       "    0.03699047449070458,\n",
       "    0.028553272423824418,\n",
       "    0.040401601715744535,\n",
       "    0.04284893557247935,\n",
       "    0.03628380535452983,\n",
       "    0.036796428474473626,\n",
       "    0.02744435554784158,\n",
       "    0.029394290722801687,\n",
       "    0.03443949626039041,\n",
       "    0.04181378301326037,\n",
       "    0.04190370691077268,\n",
       "    0.022552641737438393,\n",
       "    0.029501296613579968,\n",
       "    0.03267900461199223,\n",
       "    0.022339626328849383,\n",
       "    0.03025488795691796,\n",
       "    0.028819553267441622,\n",
       "    0.02829432552751281,\n",
       "    0.03688948597086641,\n",
       "    0.04230834490212352,\n",
       "    0.024789403858245282,\n",
       "    0.03306441734396541,\n",
       "    0.019266571383592983,\n",
       "    0.028500684315674495,\n",
       "    0.05124354533180238],\n",
       "   [0.3264155213219727,\n",
       "    0.32531133609074664,\n",
       "    0.18430499576733042,\n",
       "    0.16165195190121973,\n",
       "    0.11348405196832205,\n",
       "    0.08466699262352546,\n",
       "    0.10773469711725284,\n",
       "    0.08413184276244821,\n",
       "    0.09886759135401224,\n",
       "    0.04976146056185902,\n",
       "    0.06603947322637163,\n",
       "    0.058369587997465555,\n",
       "    0.09772001672224026,\n",
       "    0.048446225393301276,\n",
       "    0.02620512857635605,\n",
       "    0.05214946723258569,\n",
       "    0.05060267953057603,\n",
       "    0.055861645138258684,\n",
       "    0.034467742342976664,\n",
       "    0.03963202282648816,\n",
       "    0.04798475626481713,\n",
       "    0.04086486621426209,\n",
       "    0.06333985480289302,\n",
       "    0.030572035074329727,\n",
       "    0.03402873269316994,\n",
       "    0.021855654870402426,\n",
       "    0.03993259595665551,\n",
       "    0.04429887395319277,\n",
       "    0.028568887752454187,\n",
       "    0.02704965314724036,\n",
       "    0.043983697114120805,\n",
       "    0.09183295614097312,\n",
       "    0.03248564694582872,\n",
       "    0.03907659944650055,\n",
       "    0.021551481821920813,\n",
       "    0.023489366311779208,\n",
       "    0.02586204158213381,\n",
       "    0.014293518333801339,\n",
       "    0.034706896513910186,\n",
       "    0.015761058879147163,\n",
       "    0.020494701905326845,\n",
       "    0.012847572489034087,\n",
       "    0.021553789889039027,\n",
       "    0.03217985564045563,\n",
       "    0.023979421598600566,\n",
       "    0.015937600346856193,\n",
       "    0.01929963005576737,\n",
       "    0.033184366352740115,\n",
       "    0.045724509928210755,\n",
       "    0.02917660248437055],\n",
       "   [0.5634467320815384,\n",
       "    0.36797774893238855,\n",
       "    0.296383958792873,\n",
       "    0.14490999584092007,\n",
       "    0.10835167571145657,\n",
       "    0.08426773006849468,\n",
       "    0.07779158400828592,\n",
       "    0.09389245061026505,\n",
       "    0.07407049919429126,\n",
       "    0.07947216045942998,\n",
       "    0.06496295810557554,\n",
       "    0.053748079831484954,\n",
       "    0.05066559633908481,\n",
       "    0.04149393816573991,\n",
       "    0.0449189755260624,\n",
       "    0.06445265772768077,\n",
       "    0.0744912206826325,\n",
       "    0.029700832691966515,\n",
       "    0.06168251321813889,\n",
       "    0.05141825799425864,\n",
       "    0.0414382677125675,\n",
       "    0.04493584627935719,\n",
       "    0.04549346833855024,\n",
       "    0.0397719994868686,\n",
       "    0.02763501874493026,\n",
       "    0.041663926826980405,\n",
       "    0.041313735099127676,\n",
       "    0.028800930301237905,\n",
       "    0.03435111520786945,\n",
       "    0.05002105490148414,\n",
       "    0.03691810265602616,\n",
       "    0.031622894461104015,\n",
       "    0.02927849387003543,\n",
       "    0.03457165713576448,\n",
       "    0.019180748312402143,\n",
       "    0.049658598685210144,\n",
       "    0.04465499896714628,\n",
       "    0.028541553504514712,\n",
       "    0.03634032095751013,\n",
       "    0.02158044994619349,\n",
       "    0.02917540245460496,\n",
       "    0.026203694903662266,\n",
       "    0.02074558627097597,\n",
       "    0.029312417600378414,\n",
       "    0.029548311710797564,\n",
       "    0.02811784303374597,\n",
       "    0.02165791651088739,\n",
       "    0.027856368143327724,\n",
       "    0.02948560263223134,\n",
       "    0.017247894372495166]]},\n",
       " 'MNIST MLP on IID': {'hyperparams': {'C': 0.1,\n",
       "   'E': 1,\n",
       "   'K': 100,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.05,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[86.83544303797468,\n",
       "    91.13924050632912,\n",
       "    92.27848101265823,\n",
       "    93.16455696202532,\n",
       "    94.30379746835443,\n",
       "    93.67088607594937,\n",
       "    94.0506329113924,\n",
       "    94.81012658227849,\n",
       "    94.81012658227849,\n",
       "    95.82278481012658,\n",
       "    95.18987341772151,\n",
       "    95.56962025316456,\n",
       "    96.20253164556962,\n",
       "    95.9493670886076,\n",
       "    95.18987341772151,\n",
       "    96.70886075949367,\n",
       "    96.20253164556962,\n",
       "    96.32911392405063,\n",
       "    96.9620253164557,\n",
       "    96.83544303797468,\n",
       "    96.45569620253164,\n",
       "    96.45569620253164,\n",
       "    96.83544303797468,\n",
       "    96.83544303797468,\n",
       "    96.32911392405063,\n",
       "    96.70886075949367,\n",
       "    97.0886075949367,\n",
       "    97.46835443037975,\n",
       "    97.34177215189874,\n",
       "    96.9620253164557,\n",
       "    97.34177215189874,\n",
       "    97.59493670886076,\n",
       "    97.46835443037975,\n",
       "    97.46835443037975,\n",
       "    97.21518987341773,\n",
       "    97.59493670886076,\n",
       "    97.59493670886076,\n",
       "    97.34177215189874,\n",
       "    97.72151898734177,\n",
       "    97.59493670886076,\n",
       "    97.34177215189874,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.46835443037975,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177,\n",
       "    97.46835443037975,\n",
       "    97.9746835443038],\n",
       "   [79.36708860759494,\n",
       "    91.26582278481013,\n",
       "    92.27848101265823,\n",
       "    93.29113924050633,\n",
       "    93.79746835443038,\n",
       "    94.0506329113924,\n",
       "    94.68354430379746,\n",
       "    94.81012658227849,\n",
       "    95.31645569620254,\n",
       "    95.69620253164557,\n",
       "    95.9493670886076,\n",
       "    95.56962025316456,\n",
       "    95.82278481012658,\n",
       "    96.45569620253164,\n",
       "    96.20253164556962,\n",
       "    96.9620253164557,\n",
       "    96.9620253164557,\n",
       "    96.9620253164557,\n",
       "    96.83544303797468,\n",
       "    96.83544303797468,\n",
       "    96.45569620253164,\n",
       "    96.45569620253164,\n",
       "    96.9620253164557,\n",
       "    97.46835443037975,\n",
       "    97.21518987341773,\n",
       "    97.21518987341773,\n",
       "    96.9620253164557,\n",
       "    96.9620253164557,\n",
       "    97.0886075949367,\n",
       "    96.70886075949367,\n",
       "    97.9746835443038,\n",
       "    97.0886075949367,\n",
       "    96.9620253164557,\n",
       "    96.83544303797468,\n",
       "    96.83544303797468,\n",
       "    97.34177215189874,\n",
       "    96.9620253164557,\n",
       "    97.21518987341773,\n",
       "    97.84810126582279,\n",
       "    97.46835443037975,\n",
       "    97.72151898734177,\n",
       "    97.46835443037975,\n",
       "    97.34177215189874,\n",
       "    97.59493670886076,\n",
       "    97.0886075949367,\n",
       "    97.34177215189874,\n",
       "    97.34177215189874,\n",
       "    97.59493670886076,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177],\n",
       "   [85.18987341772151,\n",
       "    91.26582278481013,\n",
       "    92.78481012658227,\n",
       "    92.78481012658227,\n",
       "    93.29113924050633,\n",
       "    93.79746835443038,\n",
       "    93.92405063291139,\n",
       "    94.43037974683544,\n",
       "    94.81012658227849,\n",
       "    95.18987341772151,\n",
       "    94.81012658227849,\n",
       "    95.18987341772151,\n",
       "    96.07594936708861,\n",
       "    95.44303797468355,\n",
       "    95.82278481012658,\n",
       "    95.9493670886076,\n",
       "    95.9493670886076,\n",
       "    96.45569620253164,\n",
       "    96.45569620253164,\n",
       "    96.20253164556962,\n",
       "    96.70886075949367,\n",
       "    96.32911392405063,\n",
       "    96.20253164556962,\n",
       "    96.07594936708861,\n",
       "    96.45569620253164,\n",
       "    96.70886075949367,\n",
       "    96.32911392405063,\n",
       "    96.70886075949367,\n",
       "    96.58227848101266,\n",
       "    96.58227848101266,\n",
       "    96.83544303797468,\n",
       "    97.0886075949367,\n",
       "    96.70886075949367,\n",
       "    96.70886075949367,\n",
       "    97.0886075949367,\n",
       "    97.21518987341773,\n",
       "    97.34177215189874,\n",
       "    96.83544303797468,\n",
       "    97.0886075949367,\n",
       "    97.21518987341773,\n",
       "    97.72151898734177,\n",
       "    97.72151898734177,\n",
       "    97.46835443037975,\n",
       "    97.59493670886076,\n",
       "    97.59493670886076,\n",
       "    97.21518987341773,\n",
       "    97.9746835443038,\n",
       "    97.72151898734177,\n",
       "    97.84810126582279,\n",
       "    96.9620253164557],\n",
       "   [79.87341772151899,\n",
       "    90.63291139240506,\n",
       "    92.15189873417721,\n",
       "    93.41772151898734,\n",
       "    93.54430379746836,\n",
       "    94.0506329113924,\n",
       "    94.68354430379746,\n",
       "    94.43037974683544,\n",
       "    95.18987341772151,\n",
       "    95.0632911392405,\n",
       "    95.0632911392405,\n",
       "    95.18987341772151,\n",
       "    95.44303797468355,\n",
       "    95.69620253164557,\n",
       "    96.20253164556962,\n",
       "    96.58227848101266,\n",
       "    96.20253164556962,\n",
       "    96.83544303797468,\n",
       "    96.07594936708861,\n",
       "    96.45569620253164,\n",
       "    96.45569620253164,\n",
       "    96.83544303797468,\n",
       "    96.70886075949367,\n",
       "    96.45569620253164,\n",
       "    96.58227848101266,\n",
       "    96.70886075949367,\n",
       "    96.70886075949367,\n",
       "    96.45569620253164,\n",
       "    96.58227848101266,\n",
       "    96.83544303797468,\n",
       "    96.70886075949367,\n",
       "    96.70886075949367,\n",
       "    96.58227848101266,\n",
       "    96.45569620253164,\n",
       "    96.32911392405063,\n",
       "    96.83544303797468,\n",
       "    96.83544303797468,\n",
       "    97.34177215189874,\n",
       "    97.46835443037975,\n",
       "    97.34177215189874,\n",
       "    96.83544303797468,\n",
       "    96.9620253164557,\n",
       "    97.21518987341773,\n",
       "    97.0886075949367,\n",
       "    97.59493670886076,\n",
       "    97.34177215189874,\n",
       "    96.83544303797468,\n",
       "    97.21518987341773,\n",
       "    96.70886075949367,\n",
       "    97.21518987341773],\n",
       "   [78.22784810126582,\n",
       "    91.13924050632912,\n",
       "    91.77215189873418,\n",
       "    92.40506329113924,\n",
       "    93.54430379746836,\n",
       "    93.92405063291139,\n",
       "    94.43037974683544,\n",
       "    95.0632911392405,\n",
       "    94.81012658227849,\n",
       "    95.44303797468355,\n",
       "    96.07594936708861,\n",
       "    95.9493670886076,\n",
       "    95.82278481012658,\n",
       "    96.07594936708861,\n",
       "    96.20253164556962,\n",
       "    95.82278481012658,\n",
       "    95.9493670886076,\n",
       "    96.32911392405063,\n",
       "    96.70886075949367,\n",
       "    96.20253164556962,\n",
       "    96.32911392405063,\n",
       "    96.70886075949367,\n",
       "    96.83544303797468,\n",
       "    96.58227848101266,\n",
       "    96.83544303797468,\n",
       "    96.45569620253164,\n",
       "    96.45569620253164,\n",
       "    97.0886075949367,\n",
       "    96.83544303797468,\n",
       "    96.70886075949367,\n",
       "    97.21518987341773,\n",
       "    97.0886075949367,\n",
       "    96.70886075949367,\n",
       "    96.83544303797468,\n",
       "    96.9620253164557,\n",
       "    97.21518987341773,\n",
       "    97.21518987341773,\n",
       "    97.46835443037975,\n",
       "    97.46835443037975,\n",
       "    97.0886075949367,\n",
       "    97.84810126582279,\n",
       "    97.34177215189874,\n",
       "    97.0886075949367,\n",
       "    97.34177215189874,\n",
       "    97.84810126582279,\n",
       "    97.72151898734177,\n",
       "    97.59493670886076,\n",
       "    97.72151898734177,\n",
       "    98.35443037974683,\n",
       "    97.46835443037975]],\n",
       "  'test_loss': [[0.49805764446258544,\n",
       "    0.3332531277179718,\n",
       "    0.2935159497976303,\n",
       "    0.26207057433128356,\n",
       "    0.23104312156438828,\n",
       "    0.2168479233264923,\n",
       "    0.20687448338270187,\n",
       "    0.18733771635890006,\n",
       "    0.18207277921438217,\n",
       "    0.16371589639782905,\n",
       "    0.1568047672152519,\n",
       "    0.1528218821942806,\n",
       "    0.1466065388083458,\n",
       "    0.14153832664638757,\n",
       "    0.13943285300135613,\n",
       "    0.13027697473764419,\n",
       "    0.1292018553853035,\n",
       "    0.12443883721828461,\n",
       "    0.122129354301095,\n",
       "    0.1170646784991026,\n",
       "    0.11389575001299382,\n",
       "    0.11328728461116552,\n",
       "    0.10988898066878319,\n",
       "    0.11230726568102836,\n",
       "    0.1061339310914278,\n",
       "    0.10605854682773351,\n",
       "    0.10198640804588795,\n",
       "    0.10145947700291873,\n",
       "    0.10089314333796501,\n",
       "    0.09907587258666754,\n",
       "    0.09707145674750209,\n",
       "    0.0960905120715499,\n",
       "    0.0934793411962688,\n",
       "    0.09433596368730068,\n",
       "    0.09276387220993638,\n",
       "    0.09066819164380431,\n",
       "    0.08933429824858904,\n",
       "    0.0865473704367876,\n",
       "    0.08716714001074434,\n",
       "    0.0884849911287427,\n",
       "    0.08669992902800441,\n",
       "    0.08751712655201555,\n",
       "    0.08440599626153708,\n",
       "    0.084526211867854,\n",
       "    0.08397886636815965,\n",
       "    0.08311478699706495,\n",
       "    0.0843236059077084,\n",
       "    0.0810472211971879,\n",
       "    0.08212542785704136,\n",
       "    0.08153676861040295],\n",
       "   [0.7053430003166199,\n",
       "    0.3301118603944778,\n",
       "    0.2839480504989624,\n",
       "    0.24479867657423018,\n",
       "    0.23503868029117583,\n",
       "    0.21262853090167044,\n",
       "    0.1981990668296814,\n",
       "    0.18094835118055344,\n",
       "    0.17326886450052262,\n",
       "    0.16584172211289405,\n",
       "    0.15545706419944763,\n",
       "    0.14868466563224791,\n",
       "    0.1383687826246023,\n",
       "    0.1362859202951193,\n",
       "    0.13624080364704133,\n",
       "    0.12562432704567908,\n",
       "    0.1240094483613968,\n",
       "    0.1243067316532135,\n",
       "    0.11624707961082459,\n",
       "    0.11598844638466835,\n",
       "    0.11142775605618954,\n",
       "    0.10752289531081916,\n",
       "    0.10573636512160302,\n",
       "    0.10379639009386302,\n",
       "    0.10079921499416232,\n",
       "    0.09996970590800047,\n",
       "    0.1020418119341135,\n",
       "    0.0987186746172607,\n",
       "    0.09519526625871658,\n",
       "    0.09479367218017579,\n",
       "    0.09349419427141548,\n",
       "    0.09075617480427027,\n",
       "    0.0914606620773673,\n",
       "    0.08950810422226786,\n",
       "    0.09161613881215454,\n",
       "    0.08908883215412497,\n",
       "    0.09085668825730682,\n",
       "    0.08885607931092382,\n",
       "    0.0835572897747159,\n",
       "    0.0843032371867448,\n",
       "    0.08154980384036899,\n",
       "    0.0825146819010377,\n",
       "    0.0833779157936573,\n",
       "    0.0831667580999434,\n",
       "    0.08136600058227778,\n",
       "    0.08148585864193737,\n",
       "    0.0811481947157532,\n",
       "    0.08034631362780928,\n",
       "    0.08035409716255963,\n",
       "    0.08047630443125964],\n",
       "   [0.49194167733192445,\n",
       "    0.340335516166687,\n",
       "    0.28582072701454164,\n",
       "    0.25969947028160095,\n",
       "    0.2347701176404953,\n",
       "    0.21151388691663742,\n",
       "    0.21533211008906364,\n",
       "    0.18948470851778984,\n",
       "    0.1787627997815609,\n",
       "    0.16764414522051813,\n",
       "    0.16413118390440942,\n",
       "    0.1504109440088272,\n",
       "    0.1426014115154743,\n",
       "    0.14025276728868485,\n",
       "    0.13772650930285454,\n",
       "    0.1297927959948778,\n",
       "    0.1287114863753319,\n",
       "    0.12281115840375423,\n",
       "    0.12201556874513626,\n",
       "    0.11639018191397191,\n",
       "    0.1137742966979742,\n",
       "    0.11216484271883964,\n",
       "    0.11064214417487384,\n",
       "    0.11325166945904494,\n",
       "    0.10822866665571929,\n",
       "    0.10747470775097609,\n",
       "    0.10114293575137853,\n",
       "    0.10235107781887054,\n",
       "    0.10233674166053533,\n",
       "    0.1033163470953703,\n",
       "    0.09897899504452944,\n",
       "    0.09395322927236557,\n",
       "    0.0958234839990735,\n",
       "    0.0937231192983687,\n",
       "    0.09296531066894531,\n",
       "    0.09183960123285652,\n",
       "    0.09034687232002615,\n",
       "    0.08679827376753092,\n",
       "    0.08817517316788435,\n",
       "    0.08836372503489257,\n",
       "    0.0860588132582605,\n",
       "    0.08332957462221384,\n",
       "    0.08385090053603053,\n",
       "    0.0829335178308189,\n",
       "    0.08509304054901004,\n",
       "    0.08472539183646441,\n",
       "    0.081152179999277,\n",
       "    0.08214754690863192,\n",
       "    0.07982300646528602,\n",
       "    0.07946144487969577],\n",
       "   [0.7017483261108398,\n",
       "    0.36089821422100066,\n",
       "    0.30206631355285646,\n",
       "    0.2725609332084656,\n",
       "    0.2491764368057251,\n",
       "    0.2165524209856987,\n",
       "    0.20810871667861938,\n",
       "    0.19003503941893576,\n",
       "    0.18456399272680282,\n",
       "    0.1777944332778454,\n",
       "    0.16237568415999412,\n",
       "    0.15691454458236695,\n",
       "    0.15370063629746436,\n",
       "    0.149083597356081,\n",
       "    0.14467785439789296,\n",
       "    0.13451348618865014,\n",
       "    0.13476863741576672,\n",
       "    0.12818081369102002,\n",
       "    0.12308272572904826,\n",
       "    0.12104859694242477,\n",
       "    0.11827283625602722,\n",
       "    0.12254272859543562,\n",
       "    0.12003829211443663,\n",
       "    0.11563144659772516,\n",
       "    0.10957840463221073,\n",
       "    0.10960882892757655,\n",
       "    0.10933135220110417,\n",
       "    0.10495697828046978,\n",
       "    0.10424770262017846,\n",
       "    0.10605968226790428,\n",
       "    0.10200141607373953,\n",
       "    0.09799834296703339,\n",
       "    0.09817276280745864,\n",
       "    0.09981591263264418,\n",
       "    0.09471363454982638,\n",
       "    0.09379825302436948,\n",
       "    0.0917204706043005,\n",
       "    0.09094124149233103,\n",
       "    0.09022203012332321,\n",
       "    0.09023408852927386,\n",
       "    0.08860011215731502,\n",
       "    0.08922572849318385,\n",
       "    0.08676515142694116,\n",
       "    0.08600165633242578,\n",
       "    0.08594489001296461,\n",
       "    0.0824132275044918,\n",
       "    0.08400628162268549,\n",
       "    0.08069656880274415,\n",
       "    0.08155075958147645,\n",
       "    0.07889425272196532],\n",
       "   [1.170987211227417,\n",
       "    0.3681942836761475,\n",
       "    0.28821304957866667,\n",
       "    0.26589914531707765,\n",
       "    0.2351594448506832,\n",
       "    0.21927165555953979,\n",
       "    0.1987162715256214,\n",
       "    0.19238061136603354,\n",
       "    0.1778106172978878,\n",
       "    0.17156607950925826,\n",
       "    0.1623590389728546,\n",
       "    0.16143330711126327,\n",
       "    0.15140593589246273,\n",
       "    0.14630946565270425,\n",
       "    0.14351116497516633,\n",
       "    0.13354012573510407,\n",
       "    0.1306213663995266,\n",
       "    0.13133077645897864,\n",
       "    0.12435626611411571,\n",
       "    0.1217724388629198,\n",
       "    0.12183607861995698,\n",
       "    0.11637000267207623,\n",
       "    0.11502958797216416,\n",
       "    0.11452229117006063,\n",
       "    0.11135672944188119,\n",
       "    0.10677461287230253,\n",
       "    0.11032262766063214,\n",
       "    0.10426537491008639,\n",
       "    0.10189876567944885,\n",
       "    0.10430890078023076,\n",
       "    0.10161891463771462,\n",
       "    0.09848663155511021,\n",
       "    0.09742163474261761,\n",
       "    0.09397452373132109,\n",
       "    0.09307204497382045,\n",
       "    0.09149515762478114,\n",
       "    0.09209740201681853,\n",
       "    0.09278455110490322,\n",
       "    0.09276100346744061,\n",
       "    0.09130212801024318,\n",
       "    0.0877922463145107,\n",
       "    0.08791512672752141,\n",
       "    0.0886164359278977,\n",
       "    0.08766713888496161,\n",
       "    0.08914024338312447,\n",
       "    0.08786835305951536,\n",
       "    0.08385646106153727,\n",
       "    0.08527418229132891,\n",
       "    0.08598040974847973,\n",
       "    0.08688955760896205]],\n",
       "  'train_loss': [[2.064366043383876,\n",
       "    0.654976336248219,\n",
       "    0.4791489203165596,\n",
       "    0.41099390789090345,\n",
       "    0.3715036113901685,\n",
       "    0.3610311398981139,\n",
       "    0.31768138154642656,\n",
       "    0.28723610650825626,\n",
       "    0.26927912907752527,\n",
       "    0.2580901266036865,\n",
       "    0.25594365218421444,\n",
       "    0.2392880474221116,\n",
       "    0.21303919274670383,\n",
       "    0.2041802409302909,\n",
       "    0.2382914678195569,\n",
       "    0.21419629082743388,\n",
       "    0.20367517288677237,\n",
       "    0.1754818968834782,\n",
       "    0.16941339129485034,\n",
       "    0.2022672595929665,\n",
       "    0.1576667768410213,\n",
       "    0.15689949984574922,\n",
       "    0.17355457724392181,\n",
       "    0.14867532180132303,\n",
       "    0.1550200507413441,\n",
       "    0.14734570167866573,\n",
       "    0.14599383725959342,\n",
       "    0.14265142518347906,\n",
       "    0.13265394600059757,\n",
       "    0.12818383828790197,\n",
       "    0.12118574198888384,\n",
       "    0.12858099310057394,\n",
       "    0.13213881389868526,\n",
       "    0.10152341216513985,\n",
       "    0.12391116245315059,\n",
       "    0.11654747670157424,\n",
       "    0.10147385176504031,\n",
       "    0.11602931331430835,\n",
       "    0.09649500517618434,\n",
       "    0.10586048808637619,\n",
       "    0.10626928435143781,\n",
       "    0.1145637029701417,\n",
       "    0.10066167941942694,\n",
       "    0.0864865446347782,\n",
       "    0.09652410772485989,\n",
       "    0.07915459188910365,\n",
       "    0.09986531706863994,\n",
       "    0.08609786220464835,\n",
       "    0.09104632280847,\n",
       "    0.08428664556014458],\n",
       "   [1.848532073199749,\n",
       "    0.6437276221408198,\n",
       "    0.515206663905022,\n",
       "    0.39794165383325886,\n",
       "    0.3694445473297188,\n",
       "    0.3297636625073695,\n",
       "    0.3197274010426675,\n",
       "    0.2923291519967218,\n",
       "    0.2656331227252182,\n",
       "    0.26636902229084325,\n",
       "    0.2501662803689639,\n",
       "    0.22163916411887233,\n",
       "    0.2165448634687345,\n",
       "    0.19555237353973404,\n",
       "    0.20278909569703196,\n",
       "    0.19922741198718236,\n",
       "    0.17254843739947925,\n",
       "    0.16764787160296693,\n",
       "    0.17219743977087393,\n",
       "    0.18738749346889866,\n",
       "    0.16377967720831899,\n",
       "    0.17115721936114522,\n",
       "    0.1709266318940596,\n",
       "    0.15520171603527463,\n",
       "    0.13089781525020955,\n",
       "    0.15528469878030593,\n",
       "    0.1638923978769647,\n",
       "    0.1276615945833085,\n",
       "    0.14150575439222543,\n",
       "    0.13261052633834575,\n",
       "    0.13883691007620655,\n",
       "    0.11994520591222682,\n",
       "    0.13850807710647736,\n",
       "    0.11536384657898453,\n",
       "    0.12222369001334299,\n",
       "    0.11552238497698757,\n",
       "    0.09017689215014495,\n",
       "    0.11218121524352076,\n",
       "    0.10698824163853715,\n",
       "    0.10113262158954359,\n",
       "    0.08617546905050402,\n",
       "    0.09497837058096288,\n",
       "    0.0914692809882399,\n",
       "    0.09504360949232551,\n",
       "    0.09562424882528528,\n",
       "    0.08424583061149557,\n",
       "    0.07668521485371457,\n",
       "    0.08781952030980998,\n",
       "    0.09079102396567275,\n",
       "    0.10231998543713416],\n",
       "   [1.7731188861529035,\n",
       "    0.6007693772700925,\n",
       "    0.48377230801464366,\n",
       "    0.3897394067700952,\n",
       "    0.4009536421174805,\n",
       "    0.3141290694995163,\n",
       "    0.3255107696548415,\n",
       "    0.29311850403707157,\n",
       "    0.28645028597675265,\n",
       "    0.2595515376050025,\n",
       "    0.2472896198295833,\n",
       "    0.22096145407898193,\n",
       "    0.2059393325979666,\n",
       "    0.19869183236267418,\n",
       "    0.21228352681015772,\n",
       "    0.1965523311886742,\n",
       "    0.159409713595572,\n",
       "    0.17321590897588368,\n",
       "    0.19436503225724058,\n",
       "    0.1629523717254051,\n",
       "    0.1907482078906226,\n",
       "    0.13250729503944364,\n",
       "    0.16429436059169045,\n",
       "    0.15136333242592323,\n",
       "    0.157348974221483,\n",
       "    0.14424884382014475,\n",
       "    0.12212169870773022,\n",
       "    0.12213860057468992,\n",
       "    0.14273370456658693,\n",
       "    0.13656600886878245,\n",
       "    0.14209030763983416,\n",
       "    0.10332037487528092,\n",
       "    0.11990741419635013,\n",
       "    0.10616783530756946,\n",
       "    0.1177049328381448,\n",
       "    0.11218800828132466,\n",
       "    0.09474922386667459,\n",
       "    0.1196001416563619,\n",
       "    0.12305042658282521,\n",
       "    0.10950735554084531,\n",
       "    0.1091387610770956,\n",
       "    0.08386973524822679,\n",
       "    0.10088336519664154,\n",
       "    0.10184724574787349,\n",
       "    0.08503531489225377,\n",
       "    0.09003232339838481,\n",
       "    0.07942479363446182,\n",
       "    0.10422031541432566,\n",
       "    0.0836076216531607,\n",
       "    0.08544049779957277],\n",
       "   [2.214691508362691,\n",
       "    0.6612935758319993,\n",
       "    0.5030659523140639,\n",
       "    0.41013109639286993,\n",
       "    0.3810815696876186,\n",
       "    0.3354536826722324,\n",
       "    0.3341100820790356,\n",
       "    0.2934379356325857,\n",
       "    0.25828206257661807,\n",
       "    0.2510397886562471,\n",
       "    0.23789395394211166,\n",
       "    0.22877574535241973,\n",
       "    0.22714864541504842,\n",
       "    0.22477299642089443,\n",
       "    0.22732284186407928,\n",
       "    0.18729993427482744,\n",
       "    0.17292143605086796,\n",
       "    0.17949902608146656,\n",
       "    0.19612821545568293,\n",
       "    0.1957277782227417,\n",
       "    0.1639231976045509,\n",
       "    0.15391944829403656,\n",
       "    0.1556771242399312,\n",
       "    0.14773750735233385,\n",
       "    0.15970340976443065,\n",
       "    0.12940786658844444,\n",
       "    0.14333307681343285,\n",
       "    0.15335329391147143,\n",
       "    0.1304588859871728,\n",
       "    0.11544881542853544,\n",
       "    0.14452815142343753,\n",
       "    0.1403873737177734,\n",
       "    0.13401552335068118,\n",
       "    0.13077040397174036,\n",
       "    0.1211914206686197,\n",
       "    0.13363805684687882,\n",
       "    0.09668875968107993,\n",
       "    0.10252362471748104,\n",
       "    0.12056127120522434,\n",
       "    0.10708088346073055,\n",
       "    0.11862440345585734,\n",
       "    0.11929986849160439,\n",
       "    0.11082962879697637,\n",
       "    0.11630306591507784,\n",
       "    0.1084414120997826,\n",
       "    0.11213232898599623,\n",
       "    0.09750113242309452,\n",
       "    0.09443984586985607,\n",
       "    0.09591672914776914,\n",
       "    0.09713561157615914],\n",
       "   [2.5695690658191843,\n",
       "    0.7969057423900813,\n",
       "    0.5000834044162183,\n",
       "    0.43569713029234364,\n",
       "    0.3958568634923237,\n",
       "    0.3780982314104525,\n",
       "    0.31530249245620023,\n",
       "    0.2923006136785261,\n",
       "    0.31026110346002195,\n",
       "    0.24147445939248424,\n",
       "    0.25749780125042887,\n",
       "    0.21633334754190098,\n",
       "    0.2253911450342275,\n",
       "    0.24246674937312487,\n",
       "    0.2249063268875276,\n",
       "    0.21140096109826118,\n",
       "    0.16927360933293434,\n",
       "    0.2066188319370849,\n",
       "    0.1929633777325701,\n",
       "    0.18087739420162202,\n",
       "    0.181977902840008,\n",
       "    0.16357899022623315,\n",
       "    0.1524522728243998,\n",
       "    0.14083940957081115,\n",
       "    0.16079842197437147,\n",
       "    0.14737464236241066,\n",
       "    0.1503066036840513,\n",
       "    0.1231738360415329,\n",
       "    0.1427017962277508,\n",
       "    0.12174504199443617,\n",
       "    0.13111398330215404,\n",
       "    0.11707706673735326,\n",
       "    0.12337783783606333,\n",
       "    0.12445750424677196,\n",
       "    0.11838773743438653,\n",
       "    0.12223842143772343,\n",
       "    0.1008725395400688,\n",
       "    0.12598695011788855,\n",
       "    0.09912835061200895,\n",
       "    0.10575407228025142,\n",
       "    0.1075563128560801,\n",
       "    0.10082117717995667,\n",
       "    0.09584764953278258,\n",
       "    0.09950670408367539,\n",
       "    0.10363345960049627,\n",
       "    0.07716170062243086,\n",
       "    0.09691236281971213,\n",
       "    0.0797621070749301,\n",
       "    0.09880268857421469,\n",
       "    0.0890414297604002]]},\n",
       " 'MNIST MLP on Non IID': {'hyperparams': {'C': 0.1,\n",
       "   'E': 1,\n",
       "   'K': 100,\n",
       "   'batch_size': 10,\n",
       "   'lr': 0.05,\n",
       "   'rounds': 50},\n",
       "  'test_accuracy': [[32.53164556962025,\n",
       "    30.126582278481013,\n",
       "    37.9746835443038,\n",
       "    53.037974683544306,\n",
       "    75.44303797468355,\n",
       "    76.83544303797468,\n",
       "    64.43037974683544,\n",
       "    80.50632911392405,\n",
       "    88.86075949367088,\n",
       "    85.44303797468355,\n",
       "    77.0886075949367,\n",
       "    84.55696202531645,\n",
       "    81.13924050632912,\n",
       "    90.25316455696202,\n",
       "    87.59493670886076,\n",
       "    85.31645569620254,\n",
       "    87.0886075949367,\n",
       "    89.87341772151899,\n",
       "    86.32911392405063,\n",
       "    89.24050632911393,\n",
       "    91.13924050632912,\n",
       "    85.0632911392405,\n",
       "    87.34177215189874,\n",
       "    91.64556962025317,\n",
       "    90.63291139240506,\n",
       "    90.25316455696202,\n",
       "    85.56962025316456,\n",
       "    84.81012658227849,\n",
       "    88.86075949367088,\n",
       "    89.87341772151899,\n",
       "    86.07594936708861,\n",
       "    90.88607594936708,\n",
       "    93.41772151898734,\n",
       "    93.41772151898734,\n",
       "    93.16455696202532,\n",
       "    93.0379746835443,\n",
       "    93.16455696202532,\n",
       "    92.78481012658227,\n",
       "    91.89873417721519,\n",
       "    93.41772151898734,\n",
       "    92.40506329113924,\n",
       "    92.15189873417721,\n",
       "    90.25316455696202,\n",
       "    90.50632911392405,\n",
       "    87.34177215189874,\n",
       "    92.65822784810126,\n",
       "    91.13924050632912,\n",
       "    93.79746835443038,\n",
       "    93.54430379746836,\n",
       "    93.92405063291139],\n",
       "   [41.0126582278481,\n",
       "    46.075949367088604,\n",
       "    46.075949367088604,\n",
       "    56.58227848101266,\n",
       "    54.177215189873415,\n",
       "    80.88607594936708,\n",
       "    67.34177215189874,\n",
       "    64.17721518987342,\n",
       "    76.83544303797468,\n",
       "    85.31645569620254,\n",
       "    83.29113924050633,\n",
       "    87.9746835443038,\n",
       "    86.07594936708861,\n",
       "    87.0886075949367,\n",
       "    88.48101265822785,\n",
       "    84.68354430379746,\n",
       "    89.36708860759494,\n",
       "    85.56962025316456,\n",
       "    84.68354430379746,\n",
       "    90.75949367088607,\n",
       "    85.82278481012658,\n",
       "    78.73417721518987,\n",
       "    91.0126582278481,\n",
       "    86.32911392405063,\n",
       "    91.77215189873418,\n",
       "    87.46835443037975,\n",
       "    89.11392405063292,\n",
       "    87.0886075949367,\n",
       "    89.36708860759494,\n",
       "    91.13924050632912,\n",
       "    93.29113924050633,\n",
       "    91.77215189873418,\n",
       "    93.29113924050633,\n",
       "    91.13924050632912,\n",
       "    93.54430379746836,\n",
       "    91.77215189873418,\n",
       "    87.84810126582279,\n",
       "    92.65822784810126,\n",
       "    93.16455696202532,\n",
       "    94.17721518987342,\n",
       "    93.41772151898734,\n",
       "    88.60759493670886,\n",
       "    87.21518987341773,\n",
       "    93.79746835443038,\n",
       "    90.63291139240506,\n",
       "    94.9367088607595,\n",
       "    94.0506329113924,\n",
       "    94.17721518987342,\n",
       "    90.75949367088607,\n",
       "    91.64556962025317],\n",
       "   [34.68354430379747,\n",
       "    43.79746835443038,\n",
       "    58.607594936708864,\n",
       "    60.12658227848101,\n",
       "    66.32911392405063,\n",
       "    71.77215189873418,\n",
       "    77.84810126582279,\n",
       "    81.64556962025317,\n",
       "    78.9873417721519,\n",
       "    85.18987341772151,\n",
       "    85.82278481012658,\n",
       "    88.60759493670886,\n",
       "    88.60759493670886,\n",
       "    80.37974683544304,\n",
       "    86.07594936708861,\n",
       "    85.18987341772151,\n",
       "    83.29113924050633,\n",
       "    87.84810126582279,\n",
       "    90.25316455696202,\n",
       "    84.55696202531645,\n",
       "    88.60759493670886,\n",
       "    88.73417721518987,\n",
       "    86.70886075949367,\n",
       "    85.18987341772151,\n",
       "    88.10126582278481,\n",
       "    86.32911392405063,\n",
       "    91.0126582278481,\n",
       "    92.65822784810126,\n",
       "    88.35443037974683,\n",
       "    90.0,\n",
       "    91.13924050632912,\n",
       "    90.75949367088607,\n",
       "    86.32911392405063,\n",
       "    88.10126582278481,\n",
       "    92.78481012658227,\n",
       "    92.15189873417721,\n",
       "    90.37974683544304,\n",
       "    91.39240506329114,\n",
       "    91.51898734177215,\n",
       "    89.36708860759494,\n",
       "    92.78481012658227,\n",
       "    86.83544303797468,\n",
       "    92.27848101265823,\n",
       "    93.16455696202532,\n",
       "    94.17721518987342,\n",
       "    91.39240506329114,\n",
       "    91.64556962025317,\n",
       "    94.43037974683544,\n",
       "    91.77215189873418,\n",
       "    86.45569620253164],\n",
       "   [39.11392405063291,\n",
       "    47.59493670886076,\n",
       "    56.075949367088604,\n",
       "    64.30379746835443,\n",
       "    62.91139240506329,\n",
       "    67.21518987341773,\n",
       "    70.88607594936708,\n",
       "    71.89873417721519,\n",
       "    79.62025316455696,\n",
       "    86.07594936708861,\n",
       "    71.77215189873418,\n",
       "    81.77215189873418,\n",
       "    85.31645569620254,\n",
       "    85.56962025316456,\n",
       "    80.25316455696202,\n",
       "    86.20253164556962,\n",
       "    87.84810126582279,\n",
       "    89.11392405063292,\n",
       "    87.84810126582279,\n",
       "    84.9367088607595,\n",
       "    81.26582278481013,\n",
       "    80.0,\n",
       "    88.10126582278481,\n",
       "    88.48101265822785,\n",
       "    83.54430379746836,\n",
       "    85.44303797468355,\n",
       "    85.9493670886076,\n",
       "    90.25316455696202,\n",
       "    92.0253164556962,\n",
       "    86.9620253164557,\n",
       "    89.49367088607595,\n",
       "    92.9113924050633,\n",
       "    93.54430379746836,\n",
       "    94.17721518987342,\n",
       "    91.77215189873418,\n",
       "    89.11392405063292,\n",
       "    89.62025316455696,\n",
       "    89.87341772151899,\n",
       "    91.77215189873418,\n",
       "    90.75949367088607,\n",
       "    92.0253164556962,\n",
       "    91.26582278481013,\n",
       "    92.27848101265823,\n",
       "    91.77215189873418,\n",
       "    92.53164556962025,\n",
       "    93.16455696202532,\n",
       "    92.65822784810126,\n",
       "    91.13924050632912,\n",
       "    94.9367088607595,\n",
       "    91.89873417721519],\n",
       "   [26.582278481012658,\n",
       "    27.468354430379748,\n",
       "    44.81012658227848,\n",
       "    57.46835443037975,\n",
       "    80.0,\n",
       "    78.9873417721519,\n",
       "    84.55696202531645,\n",
       "    82.15189873417721,\n",
       "    80.37974683544304,\n",
       "    84.68354430379746,\n",
       "    88.35443037974683,\n",
       "    87.34177215189874,\n",
       "    81.51898734177215,\n",
       "    83.0379746835443,\n",
       "    86.70886075949367,\n",
       "    87.0886075949367,\n",
       "    87.34177215189874,\n",
       "    89.87341772151899,\n",
       "    89.87341772151899,\n",
       "    85.9493670886076,\n",
       "    82.78481012658227,\n",
       "    85.0632911392405,\n",
       "    90.25316455696202,\n",
       "    91.51898734177215,\n",
       "    92.65822784810126,\n",
       "    90.12658227848101,\n",
       "    91.64556962025317,\n",
       "    89.74683544303798,\n",
       "    92.9113924050633,\n",
       "    90.50632911392405,\n",
       "    86.58227848101266,\n",
       "    90.12658227848101,\n",
       "    89.62025316455696,\n",
       "    88.86075949367088,\n",
       "    92.15189873417721,\n",
       "    93.54430379746836,\n",
       "    89.87341772151899,\n",
       "    93.92405063291139,\n",
       "    91.13924050632912,\n",
       "    92.40506329113924,\n",
       "    92.27848101265823,\n",
       "    94.17721518987342,\n",
       "    90.75949367088607,\n",
       "    94.0506329113924,\n",
       "    92.15189873417721,\n",
       "    94.81012658227849,\n",
       "    89.24050632911393,\n",
       "    91.0126582278481,\n",
       "    93.92405063291139,\n",
       "    94.43037974683544]],\n",
       "  'test_loss': [[3.677287072753906,\n",
       "    2.7348230377197265,\n",
       "    1.9448327215194703,\n",
       "    1.6685313539505005,\n",
       "    1.0334750496864318,\n",
       "    0.885903286933899,\n",
       "    1.0457126329421997,\n",
       "    0.633909103679657,\n",
       "    0.4735992395401001,\n",
       "    0.5355409042358399,\n",
       "    0.6047776937484741,\n",
       "    0.4906560262203217,\n",
       "    0.5467221325397491,\n",
       "    0.3924775702476501,\n",
       "    0.38992178592681886,\n",
       "    0.44345913071632387,\n",
       "    0.3992010188102722,\n",
       "    0.35816345281600953,\n",
       "    0.3810288015842438,\n",
       "    0.33796886551380156,\n",
       "    0.29099441595077513,\n",
       "    0.408169811296463,\n",
       "    0.3699511250972748,\n",
       "    0.2792588369369507,\n",
       "    0.30740589215755465,\n",
       "    0.30161294779777525,\n",
       "    0.40451962642669675,\n",
       "    0.4430542849063873,\n",
       "    0.3373450494766235,\n",
       "    0.31251289491653444,\n",
       "    0.36138238210678103,\n",
       "    0.2645296790719032,\n",
       "    0.2284509971499443,\n",
       "    0.2198372720003128,\n",
       "    0.2135722158193588,\n",
       "    0.22943497675657273,\n",
       "    0.24304220246076583,\n",
       "    0.24520754061937333,\n",
       "    0.27318435302972793,\n",
       "    0.20974283430576324,\n",
       "    0.2223783972978592,\n",
       "    0.239695188164711,\n",
       "    0.28861781237125395,\n",
       "    0.24608939274549485,\n",
       "    0.3138449136972427,\n",
       "    0.22144591116905213,\n",
       "    0.259057790017128,\n",
       "    0.19570188422203064,\n",
       "    0.2016576311945915,\n",
       "    0.2089678740978241],\n",
       "   [3.3438369976043703,\n",
       "    2.2782751708984375,\n",
       "    2.086877816772461,\n",
       "    1.5585272953033447,\n",
       "    1.463604019165039,\n",
       "    0.7599476272583008,\n",
       "    0.8959668175697326,\n",
       "    1.0032099063873292,\n",
       "    0.7188924603462219,\n",
       "    0.5927343065738678,\n",
       "    0.5847313838481903,\n",
       "    0.44440405440330505,\n",
       "    0.4344054527759552,\n",
       "    0.4507769452095032,\n",
       "    0.4186205993413925,\n",
       "    0.4041080870628357,\n",
       "    0.3385467926979065,\n",
       "    0.4634151960372925,\n",
       "    0.4298215102672577,\n",
       "    0.3416271826028824,\n",
       "    0.3766048236846924,\n",
       "    0.500234927868843,\n",
       "    0.3162377352714539,\n",
       "    0.37563761382102967,\n",
       "    0.27754240517616274,\n",
       "    0.3444897537946701,\n",
       "    0.3146643996715546,\n",
       "    0.36619575881958005,\n",
       "    0.3034738986730576,\n",
       "    0.2766062401771545,\n",
       "    0.23837153688669205,\n",
       "    0.28446435852050783,\n",
       "    0.24581406967639924,\n",
       "    0.31658461565971374,\n",
       "    0.2433712390422821,\n",
       "    0.24926642377376557,\n",
       "    0.32737721753120425,\n",
       "    0.23771112270355224,\n",
       "    0.24382736973762512,\n",
       "    0.19870531643629075,\n",
       "    0.22932115582227708,\n",
       "    0.3183042320728302,\n",
       "    0.33796706624031064,\n",
       "    0.21633964416980744,\n",
       "    0.278837943482399,\n",
       "    0.19680507485866547,\n",
       "    0.19829039556980133,\n",
       "    0.20601004498004913,\n",
       "    0.2656889541506767,\n",
       "    0.27232448205947873],\n",
       "   [3.631305512237549,\n",
       "    2.2712590671539306,\n",
       "    1.5742763484954834,\n",
       "    1.292013027381897,\n",
       "    1.1083072932243347,\n",
       "    1.050527379512787,\n",
       "    0.6929712644577026,\n",
       "    0.5925341455936431,\n",
       "    0.6292245113372803,\n",
       "    0.4968575939655304,\n",
       "    0.4941325075626373,\n",
       "    0.41483147354125977,\n",
       "    0.3957400230169296,\n",
       "    0.5654610295772553,\n",
       "    0.42021030945777893,\n",
       "    0.46217696895599364,\n",
       "    0.46012529969215393,\n",
       "    0.3550598331689835,\n",
       "    0.32679884366989137,\n",
       "    0.46614811487197877,\n",
       "    0.3578828434944153,\n",
       "    0.31941619930267334,\n",
       "    0.35645808246135713,\n",
       "    0.3872157781600952,\n",
       "    0.34680884783267973,\n",
       "    0.3562274311304092,\n",
       "    0.30233308346271515,\n",
       "    0.27487010136842727,\n",
       "    0.3254622858762741,\n",
       "    0.2964820805072784,\n",
       "    0.28268638268709184,\n",
       "    0.3012963322877884,\n",
       "    0.384690126991272,\n",
       "    0.3597283584833145,\n",
       "    0.283768619966507,\n",
       "    0.2744236865758896,\n",
       "    0.3058409938454628,\n",
       "    0.2647569302082062,\n",
       "    0.2869440145730972,\n",
       "    0.3374683049678803,\n",
       "    0.23138061448335648,\n",
       "    0.37321012724637986,\n",
       "    0.2497524875164032,\n",
       "    0.21497165446281433,\n",
       "    0.19961041485071182,\n",
       "    0.2570505169391632,\n",
       "    0.2596577206611633,\n",
       "    0.20789285321235657,\n",
       "    0.24342744138240816,\n",
       "    0.37389525499343873],\n",
       "   [3.2909350662231445,\n",
       "    2.2208485752105713,\n",
       "    1.7598010242462159,\n",
       "    1.2825667627334594,\n",
       "    1.284844972038269,\n",
       "    1.023639475440979,\n",
       "    0.8891430168151856,\n",
       "    0.8887679330825806,\n",
       "    0.6495383643627167,\n",
       "    0.5142155762195587,\n",
       "    0.8208827144622802,\n",
       "    0.5454058010578156,\n",
       "    0.514128768825531,\n",
       "    0.5073729854822159,\n",
       "    0.5619438058853149,\n",
       "    0.414986899805069,\n",
       "    0.389473437833786,\n",
       "    0.34769612481594087,\n",
       "    0.3628176012516022,\n",
       "    0.4186922202587128,\n",
       "    0.5183098846435547,\n",
       "    0.53304751329422,\n",
       "    0.37529370756149294,\n",
       "    0.3533329252243042,\n",
       "    0.5049617127418518,\n",
       "    0.407831885099411,\n",
       "    0.4113723979473114,\n",
       "    0.31857609746456145,\n",
       "    0.264336910200119,\n",
       "    0.3696457153558731,\n",
       "    0.29711701357364656,\n",
       "    0.25557054386138917,\n",
       "    0.24893758285045625,\n",
       "    0.2527181974411011,\n",
       "    0.3043374898076057,\n",
       "    0.3510389470100403,\n",
       "    0.32543603897094725,\n",
       "    0.2991255266666412,\n",
       "    0.26120203399658204,\n",
       "    0.28138315896987914,\n",
       "    0.27022124252319335,\n",
       "    0.28175626537799836,\n",
       "    0.2349861554145813,\n",
       "    0.2559066539287567,\n",
       "    0.2430802743434906,\n",
       "    0.23350242412090302,\n",
       "    0.24127021318674088,\n",
       "    0.24316507451534272,\n",
       "    0.1930629203557968,\n",
       "    0.25604727370738983],\n",
       "   [3.604203038787842,\n",
       "    2.541797610473633,\n",
       "    1.9387291290283204,\n",
       "    1.3549510971069336,\n",
       "    0.8219722210884094,\n",
       "    0.717413161277771,\n",
       "    0.5904168768882752,\n",
       "    0.6239899981021881,\n",
       "    0.6422950017929077,\n",
       "    0.5237984688282012,\n",
       "    0.4637072330951691,\n",
       "    0.42264033403396606,\n",
       "    0.5215376942634583,\n",
       "    0.47920137519836425,\n",
       "    0.4169616331577301,\n",
       "    0.41488124399185183,\n",
       "    0.3982603190898895,\n",
       "    0.35363331809043885,\n",
       "    0.33461425709724424,\n",
       "    0.40566821355819704,\n",
       "    0.4890353343486786,\n",
       "    0.40109106986522675,\n",
       "    0.304252930521965,\n",
       "    0.29557145317792893,\n",
       "    0.2697843942165375,\n",
       "    0.2960836194038391,\n",
       "    0.2917079434633255,\n",
       "    0.2951731989741325,\n",
       "    0.26437909163236617,\n",
       "    0.284001822578907,\n",
       "    0.37514135003089905,\n",
       "    0.2786656496286392,\n",
       "    0.29243734793663023,\n",
       "    0.30468023149967194,\n",
       "    0.2565060262918472,\n",
       "    0.22949982919692993,\n",
       "    0.3035702865123749,\n",
       "    0.22397854565382003,\n",
       "    0.2558168291091919,\n",
       "    0.23759220006465911,\n",
       "    0.23785115745663643,\n",
       "    0.20676478308439256,\n",
       "    0.26662543094158175,\n",
       "    0.20649029829502105,\n",
       "    0.22642798417806625,\n",
       "    0.18728484072685242,\n",
       "    0.29784030275344847,\n",
       "    0.26033839626312255,\n",
       "    0.21859735162258148,\n",
       "    0.1854393012881279]],\n",
       "  'train_loss': [[0.822747981663491,\n",
       "    0.2722056680474285,\n",
       "    0.17431495646608783,\n",
       "    0.17245574761928242,\n",
       "    0.1644562432943773,\n",
       "    0.10786541418895204,\n",
       "    0.09395054776211018,\n",
       "    0.06864557275648622,\n",
       "    0.10131555130676542,\n",
       "    0.11318734935485479,\n",
       "    0.1375771587382102,\n",
       "    0.10902827782012084,\n",
       "    0.07066657191821227,\n",
       "    0.07605625890370477,\n",
       "    0.07985396800966119,\n",
       "    0.05918313294657916,\n",
       "    0.0703528730301531,\n",
       "    0.07087050560829766,\n",
       "    0.10238450844551353,\n",
       "    0.04849124029586542,\n",
       "    0.07439319284148667,\n",
       "    0.08278113420599159,\n",
       "    0.0533800150746356,\n",
       "    0.04910610266900184,\n",
       "    0.0666661844496762,\n",
       "    0.06565404551262569,\n",
       "    0.053954833520568665,\n",
       "    0.058889558934965856,\n",
       "    0.06410034197033081,\n",
       "    0.051036417172052394,\n",
       "    0.06764927124659731,\n",
       "    0.0595967790264846,\n",
       "    0.07058678004935498,\n",
       "    0.06376031974419674,\n",
       "    0.04840693644432302,\n",
       "    0.06426657954289833,\n",
       "    0.08051136879483684,\n",
       "    0.05484793409390325,\n",
       "    0.07133629795839434,\n",
       "    0.06814500433909568,\n",
       "    0.04911263530305196,\n",
       "    0.05135199837263258,\n",
       "    0.04328762991740888,\n",
       "    0.03482005175653133,\n",
       "    0.04328046570961628,\n",
       "    0.04313219148767606,\n",
       "    0.05076482900980446,\n",
       "    0.043930797646317264,\n",
       "    0.07055052963366659,\n",
       "    0.04880610786327791],\n",
       "   [0.5052773641161274,\n",
       "    0.19310703181720365,\n",
       "    0.14843281636076575,\n",
       "    0.15648165416169318,\n",
       "    0.09666752030512724,\n",
       "    0.15307868347393544,\n",
       "    0.23813360617838164,\n",
       "    0.11349581391953585,\n",
       "    0.11791616777121783,\n",
       "    0.13191942911057217,\n",
       "    0.11540648326401423,\n",
       "    0.07333668764654047,\n",
       "    0.12785198027155967,\n",
       "    0.09264035244929725,\n",
       "    0.06488429485917041,\n",
       "    0.06624371325320141,\n",
       "    0.10107430762734415,\n",
       "    0.09150694630595504,\n",
       "    0.06136962771125169,\n",
       "    0.04584403958086895,\n",
       "    0.06018090696734363,\n",
       "    0.05498431310703448,\n",
       "    0.06261254312704759,\n",
       "    0.05791786532768091,\n",
       "    0.08944801919838632,\n",
       "    0.043042161651433694,\n",
       "    0.04765675651608526,\n",
       "    0.0793070693467767,\n",
       "    0.06666771827453696,\n",
       "    0.08191780760095298,\n",
       "    0.07951876654561146,\n",
       "    0.047041660395331156,\n",
       "    0.04082308929254888,\n",
       "    0.046304169505491474,\n",
       "    0.052011968455338856,\n",
       "    0.07842058536692674,\n",
       "    0.05937296581213227,\n",
       "    0.048710618645302496,\n",
       "    0.04869252461918223,\n",
       "    0.0327458738196625,\n",
       "    0.06846487284584593,\n",
       "    0.040488005856381806,\n",
       "    0.05855213874367928,\n",
       "    0.03660367042169617,\n",
       "    0.029955075101759588,\n",
       "    0.06894967491536097,\n",
       "    0.06528247415532357,\n",
       "    0.0314334924750015,\n",
       "    0.05821539801688534,\n",
       "    0.04903631531291393],\n",
       "   [0.7204184527680152,\n",
       "    0.2877601985327719,\n",
       "    0.17849182609133124,\n",
       "    0.1481915243620467,\n",
       "    0.11973217463611216,\n",
       "    0.1362150459621705,\n",
       "    0.11809963908168356,\n",
       "    0.0845453062879619,\n",
       "    0.13501208294710718,\n",
       "    0.13105507838240255,\n",
       "    0.0811789129564374,\n",
       "    0.09554532281675468,\n",
       "    0.10737997659967069,\n",
       "    0.08362279224674618,\n",
       "    0.07017126754365038,\n",
       "    0.09407464912110301,\n",
       "    0.056436398146755294,\n",
       "    0.09883157555156609,\n",
       "    0.03691262111658631,\n",
       "    0.10037775714016561,\n",
       "    0.06945051329069883,\n",
       "    0.03856526062827423,\n",
       "    0.05296961985154345,\n",
       "    0.09124323404386132,\n",
       "    0.0599836111410635,\n",
       "    0.04579116801760892,\n",
       "    0.045020498129401856,\n",
       "    0.07772044336752058,\n",
       "    0.046415726445925426,\n",
       "    0.05126995546259574,\n",
       "    0.05511290281234171,\n",
       "    0.05664438270849692,\n",
       "    0.06684159036270841,\n",
       "    0.048827552837890656,\n",
       "    0.06657831509485818,\n",
       "    0.05917401064752993,\n",
       "    0.04284980720515345,\n",
       "    0.05464606398722545,\n",
       "    0.08227014465872343,\n",
       "    0.044730836973873624,\n",
       "    0.05376760735310996,\n",
       "    0.03832089827110431,\n",
       "    0.04630365954686112,\n",
       "    0.06372235752826175,\n",
       "    0.050197174127323815,\n",
       "    0.03402756911740028,\n",
       "    0.039786223545523476,\n",
       "    0.04148523373724987,\n",
       "    0.045642169588244116,\n",
       "    0.054438647004702335],\n",
       "   [0.5449419675196817,\n",
       "    0.14009624774437512,\n",
       "    0.16481709908466238,\n",
       "    0.1461960868382783,\n",
       "    0.11078000554049205,\n",
       "    0.14373136254510063,\n",
       "    0.09730165598095937,\n",
       "    0.12540141657064133,\n",
       "    0.1052485708093059,\n",
       "    0.10076175466982326,\n",
       "    0.09517183818027963,\n",
       "    0.13254497829195014,\n",
       "    0.10322131018534379,\n",
       "    0.08628020364924775,\n",
       "    0.0946952902191803,\n",
       "    0.08542126067147515,\n",
       "    0.07192909194675015,\n",
       "    0.07657226467366247,\n",
       "    0.06897083331104417,\n",
       "    0.07122723269798142,\n",
       "    0.10704178931387139,\n",
       "    0.07051780126733508,\n",
       "    0.058382729033968794,\n",
       "    0.05614414453546336,\n",
       "    0.0671768393319879,\n",
       "    0.04631461034100236,\n",
       "    0.03985285689741298,\n",
       "    0.050228981765753536,\n",
       "    0.045519702717486205,\n",
       "    0.06529781579215124,\n",
       "    0.06178345834479736,\n",
       "    0.05305167612103332,\n",
       "    0.034311931961143696,\n",
       "    0.03255661080070543,\n",
       "    0.04313563432481714,\n",
       "    0.04662807205992674,\n",
       "    0.04998557707508621,\n",
       "    0.06645455128125984,\n",
       "    0.0413420153665092,\n",
       "    0.027271736186419183,\n",
       "    0.04712848954778953,\n",
       "    0.05337770327371364,\n",
       "    0.03498732157794923,\n",
       "    0.0702360310985087,\n",
       "    0.031963893000809165,\n",
       "    0.05376841647658619,\n",
       "    0.03884720303004021,\n",
       "    0.03238028618777876,\n",
       "    0.042259822864482405,\n",
       "    0.060754717341211906],\n",
       "   [0.6592727293462076,\n",
       "    0.286749053776932,\n",
       "    0.1775202387695393,\n",
       "    0.19947387516585874,\n",
       "    0.10895791269045732,\n",
       "    0.12483645048608424,\n",
       "    0.11420275230503345,\n",
       "    0.06814921083875948,\n",
       "    0.14820815376555402,\n",
       "    0.0678150713123341,\n",
       "    0.14793412520939836,\n",
       "    0.08402373635582384,\n",
       "    0.06933593143742126,\n",
       "    0.08270726295397557,\n",
       "    0.10808331414722487,\n",
       "    0.09133134953840454,\n",
       "    0.053627257103465734,\n",
       "    0.060562310690415865,\n",
       "    0.09906705660901634,\n",
       "    0.07248887680315724,\n",
       "    0.07498128184411934,\n",
       "    0.04783060121607908,\n",
       "    0.05348125386628403,\n",
       "    0.07398557107728862,\n",
       "    0.07774432178994176,\n",
       "    0.08446270324857932,\n",
       "    0.057110801815039546,\n",
       "    0.040253902048691455,\n",
       "    0.055086001884363044,\n",
       "    0.07945759799022806,\n",
       "    0.07861164229489395,\n",
       "    0.0635823436992905,\n",
       "    0.049787005302174905,\n",
       "    0.05374273509579097,\n",
       "    0.047473623166215284,\n",
       "    0.06902765511012945,\n",
       "    0.04880967552842169,\n",
       "    0.06974788756609542,\n",
       "    0.048909157112380704,\n",
       "    0.05965006792127421,\n",
       "    0.04667611406100545,\n",
       "    0.02971607883552422,\n",
       "    0.028163004123077633,\n",
       "    0.056637948177673626,\n",
       "    0.04159640394120742,\n",
       "    0.031891047923824516,\n",
       "    0.02653603755276625,\n",
       "    0.045377450749101114,\n",
       "    0.0796171330363336,\n",
       "    0.06538975747116031]]}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open(path + 'Local_Round_FedAvg_1.pkl', 'rb') as file:\n",
    "  log_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "se_04JMaVJPg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.24050632911393, 99.24050632911393, 99.62025316455696, 99.36708860759494, 99.24050632911393]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['MNIST CNN on IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "5sv0rv-G4Sqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98.35443037974683, 97.34177215189874, 98.60759493670886, 98.35443037974683, 96.58227848101266]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['MNIST CNN on Non IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "b2a2_Az-4nal"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97.9746835443038, 97.72151898734177, 96.9620253164557, 97.21518987341773, 97.46835443037975]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['MNIST MLP on IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "YoRqZyvD4p2K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93.92405063291139, 91.64556962025317, 86.45569620253164, 91.89873417721519, 94.43037974683544]\n"
     ]
    }
   ],
   "source": [
    "print([test_acc[-1] for test_acc in log_dict['MNIST MLP on Non IID']['test_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "B87eGKJnAHIh"
   },
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "FederatedAveraging",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "QSGD",
   "language": "python",
   "name": "qsgd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
